{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059fdb12",
   "metadata": {
    "id": "059fdb12"
   },
   "source": [
    "# TinyGPT\n",
    "\n",
    "**Author: Abraham R.**\n",
    "\n",
    "The following notebook is an example of a really tiny GPT based model called TinyGPT.\n",
    "You'll review the GPT architecture (transformer decoder) and implement the following tasks:\n",
    "\n",
    "## TinyGPT Architecture\n",
    "\n",
    "Tailored for the [NLP-II course](https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/CEIA-LLMIAG) as we deal with architectures and theory, this model consists of a **Mixture of Experts GPT**, equivalent to models like:\n",
    "- DeepSeek\n",
    "- Mistral\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Using TinyGPT you need to implement the following modifications:\n",
    "\n",
    "\n",
    "## Inference: Modify the generate function to:\n",
    "- Greedy decoding (pick max probability token).\n",
    "- Temperature sampling.\n",
    "- top-k or top-p sampling.\n",
    "\n",
    "### References\n",
    "- [huggingface generate](https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
    "\n",
    "## Architecture:\n",
    "- Make TinyGPT a Mixture of Experts (MoE) of at least 2 experts.\n",
    "\n",
    "## What to expect?\n",
    "\n",
    "- You'll manage to understand a depth implementation of a GPT model.\n",
    "- Implement a MoE Layer to create a state-of-the art GPT model.\n",
    "- Explore decoding algorithms for text generation.\n",
    "\n",
    "\n",
    "### NOTE\n",
    "\n",
    "Tokenization is out of scope, we'll use a simple yet ineffective character-based tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "nVM5p13MJw32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2620,
     "status": "ok",
     "timestamp": 1755380454912,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "nVM5p13MJw32",
    "outputId": "2f9fef29-9f6a-4f81-dd1e-7903188ed7a2"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#%cd /content/drive/MyDrive/PLN_II\n",
    "#!ls\n",
    "\n",
    "# COMPATIBILIDAD NVIDIA GTX-970\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f06f210b",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1755380454915,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "f06f210b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Type\n",
    "import httpx\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainer import Trainer\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2f067",
   "metadata": {
    "id": "f7b2f067"
   },
   "source": [
    "## Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afc77182",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1755380455430,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "afc77182",
    "outputId": "5b749e52-eb0d-4517-e77f-1c66b8be0a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "Second Citizen:\n",
      "Would you proceed especially against Caius Marcius?\n",
      "\n",
      "All:\n",
      "Against him first: he's a very dog to the commonalty.\n",
      "\n",
      "Second Citizen:\n",
      "Consider you what services he has done for his country?\n",
      "\n",
      "First Citizen:\n",
      "Very well; and could be content to give him good\n",
      "report fort, but that he pays himself with being proud.\n",
      "\n",
      "Second Citizen:\n",
      "Nay, but speak not maliciously.\n",
      "\n",
      "First Citizen:\n",
      "I say unto you, what he hath done famously, he did\n",
      "it to that end: though soft-conscienced men can be\n",
      "content to say it was for his country he did it to\n",
      "please his mother and to be partly proud; which he\n",
      "is, even till the altitude of his virtue.\n",
      "\n",
      "Second Citizen:\n",
      "What he cannot help in his nature, you account a\n",
      "vice in him. You must in no way say he is covetous.\n",
      "\n",
      "First Citizen:\n",
      "If I must not, I need not be barren of accusations;\n",
      "he hath faults, with surplus, to tire in repetition.\n",
      "What shouts are these? The other side o' the city\n",
      "is risen: why stay we prating here? to the Capitol!\n",
      "\n",
      "All:\n",
      "Come, come.\n",
      "\n",
      "First Citizen:\n",
      "Soft! who comes here?\n",
      "\n",
      "Second Citizen:\n",
      "Worthy Menenius Agrippa; one that hath always loved\n",
      "the people.\n",
      "\n",
      "First Citizen:\n",
      "He's one honest enough: would all the rest were so!\n",
      "\n",
      "MENENIUS:\n",
      "What work's, my countrymen, in hand? where go you\n",
      "With bats and clubs? The matter? speak, I pray you.\n",
      "\n",
      "First Citizen:\n",
      "Our business is not unknown to the senate; they have\n",
      "had inkling this fortnight what we intend to do,\n",
      "which now we'll show 'em in deeds. They say poor\n",
      "suitors have strong breaths: they shall know we\n",
      "have strong arms too.\n",
      "\n",
      "MENENIUS:\n",
      "Why, masters, my good friends, mine honest neighbours,\n",
      "Will you undo yourselves?\n",
      "\n",
      "First Citizen:\n",
      "We cannot, sir, we are undone already.\n",
      "\n",
      "MENENIUS:\n",
      "I tell you, friends, most charitable care\n",
      "Have the patricians of you. For your wants,\n",
      "Your suffering in this dearth, you may as well\n",
      "Strike at the heaven with your staves as lift them\n",
      "Against the Roman state, whose course will on\n",
      "The way it takes, cracking ten thousand curbs\n",
      "Of more strong link asunder than can ever\n",
      "Appear in your impediment. For the dearth,\n",
      "The gods, not the patricians, make it, and\n",
      "Your knees to them, not arms, must help. Alack,\n",
      "You are transported by calamity\n",
      "Thither where more attends you, and you slander\n",
      "The helms o' the state, who care for you like fathers,\n",
      "When you curse them as enemies.\n",
      "\n",
      "First Citizen:\n",
      "Care for us! True, indeed! They ne'er cared for us\n",
      "yet: suffer us to famish, and their store-houses\n",
      "crammed with grain; make edicts for usury, to\n",
      "support usurers; repeal daily any wholesome act\n",
      "established against the rich, and provide more\n",
      "piercing statutes daily, to chain up and restrain\n",
      "the poor. If the wars eat us not up, they will; and\n",
      "there's all the love they bear us.\n",
      "\n",
      "MENENIUS:\n",
      "Either you must\n",
      "Confess yourselves wondrous malicious,\n",
      "Or be accused of folly. I shall tell you\n",
      "A pretty tale: it may be you have heard it;\n",
      "But, since it serves my purpose, I will venture\n",
      "To stale 't a little more.\n",
      "\n",
      "First Citizen:\n",
      "Well, I'll hear it, sir: yet you must not think to\n",
      "fob off our disgrace with a tale: but, an 't please\n",
      "you, deliver.\n",
      "\n",
      "MENENIUS:\n",
      "There was a time when all the body's members\n",
      "Rebell'd against the belly, thus accused it:\n",
      "That only like a gulf it did remain\n",
      "I' the midst o' the body, idle and unactive,\n",
      "Still cupboarding the viand, never bearing\n",
      "Like labour with the rest, where the other instruments\n",
      "Did see and hear, devise, instruct, walk, feel,\n",
      "And, mutually participate, did minister\n",
      "Unto the appetite and affection common\n",
      "Of the whole body. The belly answer'd--\n",
      "\n",
      "First Citizen:\n",
      "Well, sir, what answer made the belly?\n",
      "\n",
      "MENENIUS:\n",
      "Sir, I shall tell you. With a kind of smile,\n",
      "Which ne'er came from the lungs, but even thus--\n",
      "For, look you, I may make the belly smile\n",
      "As well as speak--it tauntingly replied\n",
      "To the discontented members, the mutinous parts\n",
      "That envied his receipt; even so most fitly\n",
      "As you malign our senators for that\n",
      "They are not such as you.\n",
      "\n",
      "First Citizen:\n",
      "Your belly's answer? What!\n",
      "The kingly-crowned head, the vigilant eye,\n",
      "The counsellor heart, the arm our soldier,\n",
      "Our steed the leg, the tongue our trumpeter.\n",
      "With other muniments and petty helps\n",
      "In this our fabric, if that they--\n",
      "\n",
      "MENENIUS:\n",
      "What then?\n",
      "'Fore me, this fellow speaks! What then? what then?\n",
      "\n",
      "First Citizen:\n",
      "Should by the cormorant belly be restrain'd,\n",
      "Who is the sink o' the body,--\n",
      "\n",
      "MENENIUS:\n",
      "Well, what then?\n",
      "\n",
      "First Citizen:\n",
      "The former agents, if they did complain,\n",
      "What could the belly answer?\n",
      "\n",
      "MENENIUS:\n",
      "I will tell you\n",
      "If you'll bestow a small--of what you have little--\n",
      "Patience awhile, you'll hear the belly's answer.\n",
      "\n",
      "First Citizen:\n",
      "Ye're long about it.\n",
      "\n",
      "MENENIUS:\n",
      "Note me this, good friend;\n",
      "Your most grave belly was deliberate,\n",
      "Not rash like his accusers, and thus answer'd:\n",
      "'True is it, my incorporate friends,' quoth he,\n",
      "'That I receive the general food at first,\n",
      "Which you do live upon; and fit it is,\n",
      "Because I am the store-house and the shop\n",
      "Of the whole body: but, if you do remember,\n",
      "I send it through the rivers of your blood,\n",
      "Even to the court, the heart, to the seat o' the brain;\n",
      "And, through the cranks and offices of man,\n",
      "The strongest nerves and small inferior veins\n",
      "From me receive that natural competency\n",
      "Whereby they live: and though that all at once,\n",
      "You, my good friends,'--this says the belly, mark me,--\n",
      "\n",
      "First Citizen:\n",
      "Ay, sir; well, well.\n",
      "\n",
      "MENENIUS:\n",
      "'Though all at once cannot\n",
      "See what I do deliver out to each,\n",
      "Yet I can make my audit up, that all\n",
      "From me do back receive the flour of all,\n",
      "And leave me but the bran.' What say you to't?\n",
      "\n",
      "First Citizen:\n",
      "It was an answer: how apply you this?\n",
      "\n",
      "MENENIUS:\n",
      "The senators of Rome are this good belly,\n",
      "And you the mutinous members; for examine\n",
      "Their counsels and their cares, digest things rightly\n",
      "Touching the weal o' the common, you shall find\n",
      "No public benefit which you receive\n",
      "But it proceeds or comes from them to you\n",
      "And no way from yourselves. What do you think,\n",
      "You, the great toe of this assembly?\n",
      "\n",
      "First Citizen:\n",
      "I the great toe! why the great toe?\n",
      "\n",
      "MENENIUS:\n",
      "For that, being one o' the lowest, basest, poorest,\n",
      "Of this most wise rebellion, thou go'st foremost:\n",
      "Thou rascal, that art worst in blood to run,\n",
      "Lead'st first to win some vantage.\n",
      "But make you ready your stiff bats and clubs:\n",
      "Rome and her rats are at the point of battle;\n",
      "The one side must have bale.\n",
      "Hail, noble Marcius!\n",
      "\n",
      "MARCIUS:\n",
      "Thanks. What's the matter, you dissentious rogues,\n",
      "That, rubbing the poor itch of your opinion,\n",
      "Make yourselves scabs?\n",
      "\n",
      "First Citizen:\n",
      "We have ever your good word.\n",
      "\n",
      "MARCIUS:\n",
      "He that will give good words to thee will flatter\n",
      "Beneath abhorring. What would you have, you curs,\n",
      "That like nor peace nor war? the one affrights you,\n",
      "The other makes you proud. He that trusts to you,\n",
      "Where he should find you lions, finds you hares;\n",
      "Where foxes, geese: you are no surer, no,\n",
      "Than is the coal of fire upon the ice,\n",
      "Or hailstone in the sun. Your virtue is\n",
      "To make him worthy whose offence subdues him\n",
      "And curse that justice did it.\n",
      "Who deserves greatness\n",
      "Deserves your hate; and your affections are\n",
      "A sick man's appetite, who desires most that\n",
      "Which would increase his evil. He that depends\n",
      "Upon your favours swims with fins of lead\n",
      "And hews down oaks with rushes. Hang ye! Trust Ye?\n",
      "With every minute you do change a mind,\n",
      "And call him noble that was now your hate,\n",
      "Him vile that was your garland. What's the matter,\n",
      "That in these several places of the city\n",
      "You cry against the noble senate, who,\n",
      "Under the gods, keep you in awe, which else\n",
      "Would feed on one another? What's their seeking?\n",
      "\n",
      "MENENIUS:\n",
      "For corn at their own rates; whereof, they say,\n",
      "The city is well stored.\n",
      "\n",
      "MARCIUS:\n",
      "Hang 'em! They say!\n",
      "They'll sit by the fire, and presume to know\n",
      "What's done i' the Capitol; who's like to rise,\n",
      "Who thrives and who declines; side factions\n",
      "and give out\n",
      "Conjectural marriages; making parties strong\n",
      "And feebling such as stand not in their liking\n",
      "Below their cobbled shoes. They say there's\n",
      "grain enough!\n",
      "Would the nobility lay aside their ruth,\n",
      "And let me use my sword, I'll make a quarry\n",
      "With thousands of these quarter'd slaves, as high\n",
      "As I could pick my lance.\n",
      "\n",
      "MENENIUS:\n",
      "Nay, these are almost thoroughly persuaded;\n",
      "For though abundantly they lack discretion,\n",
      "Yet are they passing cowardly. But, I beseech you,\n",
      "What says the other troop?\n",
      "\n",
      "MARCIUS:\n",
      "They are dissolved: hang 'em!\n",
      "They said they were an-hungry; sigh'd forth proverbs,\n",
      "That hunger broke stone walls, that dogs must eat,\n",
      "That meat was made for mouths, that the gods sent not\n",
      "Corn for the rich men only: with these shreds\n",
      "They vented their complainings; which being answer'd,\n",
      "And a petition granted them, a strange one--\n",
      "To break the heart of generosity,\n",
      "And make bold power look pale--they threw their caps\n",
      "As they would hang them on the horns o' the moon,\n",
      "Shouting their emulation.\n",
      "\n",
      "MENENIUS:\n",
      "What is granted them?\n",
      "\n",
      "MARCIUS:\n",
      "Five tribunes to defend their vulgar wisdoms,\n",
      "Of their own choice: one's Junius Brutus,\n",
      "Sicinius Velutus, and I know not--'Sdeath!\n",
      "The rabble should have first unroof'd the city,\n",
      "Ere so prevail'd with me: it will in time\n",
      "Win upon power and throw forth greater themes\n",
      "For insurrection's arguing.\n",
      "\n",
      "MENENIUS:\n",
      "This is strange.\n",
      "\n",
      "MARCIUS:\n",
      "Go, get you home, you fragments!\n",
      "\n",
      "Messenger:\n",
      "Where's Caius Marcius?\n",
      "\n",
      "MARCIUS:\n",
      "Here: what's the matter?\n",
      "\n",
      "Messenger:\n",
      "The news is, sir, the Volsces are in arms.\n",
      "\n",
      "MARCIUS:\n",
      "I am glad on 't: then we shall ha' means to vent\n",
      "Our musty superfluity. See, our best elders.\n",
      "\n",
      "First Senator:\n",
      "Marcius, 'tis true that you have lately told us;\n",
      "The Volsces are in arms.\n",
      "\n",
      "MARCIUS:\n",
      "They have a leader,\n",
      "Tullus Aufidius, that will put you to 't.\n",
      "I sin in envying his nobility,\n",
      "And were I any thing but what I am,\n",
      "I would wish me only he.\n",
      "\n",
      "COMINIUS:\n",
      "You have fought together.\n",
      "\n",
      "MARCIUS:\n",
      "Were half to half the world by the ears and he.\n",
      "Upon my party, I'ld revolt to make\n",
      "Only my wars with him: he is a lion\n",
      "That I am proud to hunt.\n",
      "\n",
      "First Senator:\n",
      "Then, worthy Marcius,\n",
      "Attend upon Cominius to these wars.\n",
      "\n",
      "COMINIUS:\n",
      "It is your former promise.\n",
      "\n",
      "MARCIUS:\n",
      "Sir, it is;\n",
      "And I am constant. Titus Lartius, thou\n",
      "Shalt see me once more strike at Tullus' face.\n",
      "What, art thou stiff? stand'st out?\n",
      "\n",
      "TITUS:\n",
      "No, Caius Marcius;\n",
      "I'll lean upon one crutch and fight with t'other,\n",
      "Ere stay behind this business.\n",
      "\n",
      "MENENIUS:\n",
      "O, true-bred!\n",
      "\n",
      "First Senator:\n",
      "Your company to the Capitol; where, I know,\n",
      "Our greatest friends attend us.\n",
      "\n",
      "TITUS:\n",
      "\n",
      "COMINIUS:\n",
      "Noble Marcius!\n",
      "\n",
      "First Senator:\n",
      "\n",
      "MARCIUS:\n",
      "Nay, let them follow:\n",
      "The Volsces have much corn; take these rats thither\n",
      "To gnaw their garners. Worshipful mutiners,\n",
      "Your valour puts well forth: pray, follow.\n",
      "\n",
      "SICINIUS:\n",
      "Was ever man so proud as is this Marcius?\n",
      "\n",
      "BRUTUS:\n",
      "He has no equal.\n",
      "\n",
      "SICINIUS:\n",
      "When we were chosen tribunes for the people,--\n",
      "\n",
      "BRUTUS:\n",
      "Mark'd you his lip and eyes?\n",
      "\n",
      "SICINIUS:\n",
      "Nay. but his taunts.\n",
      "\n",
      "BRUTUS:\n",
      "Being moved, he will not spare to gird the gods.\n",
      "\n",
      "SICINIUS:\n",
      "Be-mock the modest moon.\n",
      "\n",
      "BRUTUS:\n",
      "The present wars devour him: he is grown\n",
      "Too proud to be so valiant.\n",
      "\n",
      "SICINIUS:\n",
      "Such a nature,\n",
      "Tickled with good success, disdains the shadow\n",
      "Which he treads on at noon: but I do wonder\n",
      "His insolence can brook to be commanded\n",
      "Under Cominius.\n",
      "\n",
      "BRUTUS:\n",
      "Fame, at the which he aims,\n",
      "In whom already he's well graced, can not\n",
      "Better be held nor more attain'd than by\n",
      "A place below the first: for what miscarries\n",
      "Shall be the general's fault, though he perform\n",
      "To the utmost of a man, and giddy censure\n",
      "Will then cry out of Marcius 'O if he\n",
      "Had borne the business!'\n",
      "\n",
      "SICINIUS:\n",
      "Besides, if things go well,\n",
      "Opinion that so sticks on Marcius shall\n",
      "Of his demerits rob Cominius.\n",
      "\n",
      "BRUTUS:\n",
      "Come:\n",
      "Half all Cominius' honours are to Marcius.\n",
      "Though Marcius earned them not, and all his faults\n",
      "To Marcius shall be honours, though indeed\n",
      "In aught he merit not.\n",
      "\n",
      "SICINIUS:\n",
      "Let's hence, and hear\n",
      "How the dispatch is made, and in what fashion,\n",
      "More than his singularity, he goes\n",
      "Upon this present action.\n",
      "\n",
      "BRUTUS:\n",
      "Lets along.\n",
      "\n",
      "First Senator:\n",
      "So, your opinion is, Aufidius,\n",
      "That they of Rome are entered in our counsels\n",
      "And know how we proceed.\n",
      "\n",
      "AUFIDIUS:\n",
      "Is it not yours?\n",
      "What ever have been thought on in this state,\n",
      "That could be brought to bodily act ere Rome\n",
      "Had circumvention? 'Tis not four days gone\n",
      "Since I heard thence; these are the words: I think\n",
      "I have the letter here; yes, here it is.\n",
      "'They have press'd a power, but it is not known\n",
      "Whether for east or west: the dearth is great;\n",
      "The people mutinous; and it is rumour'd,\n",
      "Cominius, Marcius your old enemy,\n",
      "Who is of Rome worse hated than of you,\n",
      "And Titus Lartius, a most valiant Roman,\n",
      "These three lead on this preparation\n",
      "Whither 'tis bent: most likely 'tis for you:\n",
      "Consider of it.'\n",
      "\n",
      "First Senator:\n",
      "Our army's in the field\n",
      "We never yet made doubt but Rome was ready\n",
      "To answer us.\n",
      "\n",
      "AUFIDIUS:\n",
      "Nor did you think it folly\n",
      "To keep your great pretences veil'd till when\n",
      "They needs must show themselves; which\n",
      "in the hatching,\n",
      "It seem'd, appear'd to Rome. By the discovery.\n",
      "We shall be shorten'd in our aim, which was\n",
      "To take in many towns ere almost Rome\n",
      "Should know we were afoot.\n",
      "\n",
      "Second Senator:\n",
      "Noble Aufidius,\n",
      "Take your commission; hie you to your bands:\n",
      "Let us alone to guard Corioli:\n",
      "If they set down before 's, for the remove\n",
      "Bring your army; but, I think, you'll find\n",
      "They've not prepared for us.\n",
      "\n",
      "AUFIDIUS:\n",
      "O, doubt not that;\n",
      "I speak from certainties. Nay, more,\n",
      "Some parcels of their power are forth already,\n",
      "And only hitherward. I leave your honours.\n",
      "If we and Caius Marcius chance to meet,\n",
      "'Tis sworn between us we shall ever strike\n",
      "Till one can do no more.\n",
      "\n",
      "All:\n",
      "The gods assist you!\n",
      "\n",
      "AUFIDIUS:\n",
      "And keep your honours safe!\n",
      "\n",
      "First Senator:\n",
      "Farewell.\n",
      "\n",
      "Second Senator:\n",
      "Farewell.\n",
      "\n",
      "All:\n",
      "Farewell.\n",
      "\n",
      "VOLUMNIA:\n",
      "I pray you, daughter, sing; or express yourself in a\n",
      "more comfortable sort: if my son were my husband, I\n",
      "should freelier rejoice in that absence wherein he\n",
      "won honour than in the embracements of his bed where\n",
      "he would show most love. When yet he was but\n",
      "tender-bodied and the only son of my womb, when\n",
      "youth with comeliness plucked all gaze his way, when\n",
      "for a day of kings' entreaties a mother should not\n",
      "sell him an hour from her beholding, I, considering\n",
      "how honour would become such a person. that it was\n",
      "no better than picture-like to hang by the wall, if\n",
      "renown made it not stir, was pleased to let him seek\n",
      "danger where he was like to find fame. To a cruel\n",
      "war I sent him; from whence he returned, his brows\n",
      "bound with oak. I tell thee, daughter, I sprang not\n",
      "more in joy at first hearing he was a man-child\n",
      "than now in first seeing he had proved himself a\n",
      "man.\n",
      "\n",
      "VIRGILIA:\n",
      "But had he died in the business, madam; how then?\n",
      "\n",
      "VOLUMNIA:\n",
      "Then his good report should have been my son; I\n",
      "therein would have found issue. Hear me profess\n",
      "sincerely: had I a dozen sons, each in my love\n",
      "alike and none less dear than thine and my good\n",
      "Marcius, I had rather had eleven die nobly for their\n",
      "country than one voluptuously surfeit out of action.\n",
      "\n",
      "Gentlewoman:\n",
      "Madam, the Lady Valeria is come to visit you.\n",
      "\n",
      "VIRGILIA:\n",
      "Beseech you, give me leave to retire myself.\n",
      "\n",
      "VOLUMNIA:\n",
      "Indeed, you shall not.\n",
      "Methinks I hear hither your husband's drum,\n",
      "See him pluck Aufidius down by the hair,\n",
      "As children from a bear, the Volsces shunning him:\n",
      "Methinks I see him stamp thus, and call thus:\n",
      "'Come on, you cowards! you were got in fear,\n",
      "Though you were born in Rome:' his bloody brow\n",
      "With his mail'd hand then wiping, forth he goes,\n",
      "Like to a harvest-man that's task'd to mow\n",
      "Or all or lose his hire.\n",
      "\n",
      "VIRGILIA:\n",
      "His bloody brow! O Jupiter, no blood!\n",
      "\n",
      "VOLUMNIA:\n",
      "Away, you fool! it more becomes a man\n",
      "Than gilt his trophy: the breasts of Hecuba,\n",
      "When she did suckle Hector, look'd not lovelier\n",
      "Than Hector's forehead when it spit forth blood\n",
      "At Grecian sword, contemning. Tell Valeria,\n",
      "We are fit to bid her welcome.\n",
      "\n",
      "VIRGILIA:\n",
      "Heavens bless my lord from fell Aufidius!\n",
      "\n",
      "VOLUMNIA:\n",
      "He'll beat Aufidius 'head below his knee\n",
      "And tread upon his neck.\n",
      "\n",
      "VALERIA:\n",
      "My ladies both, good day to you.\n",
      "\n",
      "VOLUMNIA:\n",
      "Sweet madam.\n",
      "\n",
      "VIRGILIA:\n",
      "I am glad to see your ladyship.\n",
      "\n",
      "VALERIA:\n",
      "How do you both? you are manifest house-keepers.\n",
      "What are you sewing here? A fine spot, in good\n",
      "faith. How does your little son?\n",
      "\n",
      "VIRGILIA:\n",
      "I thank your ladyship; well, good madam.\n",
      "\n",
      "VOLUMNIA:\n",
      "He had rather see the swords, and hear a drum, than\n",
      "look upon his school-master.\n",
      "\n",
      "VALERIA:\n",
      "O' my word, the father's son: I'll swear,'tis a\n",
      "very pretty boy. O' my troth, I looked upon him o'\n",
      "Wednesday half an hour together: has such a\n",
      "confirmed countenance. I saw him run after a gilded\n",
      "butterfly: and when he caught it, he let it go\n",
      "again; and after it again; and over and over he\n",
      "comes, and again; catched it again; or whether his\n",
      "fall enraged him, or how 'twas, he did so set his\n",
      "teeth and tear it; O, I warrant it, how he mammocked\n",
      "it!\n",
      "\n",
      "VOLUMNIA:\n",
      "One on 's father's moods.\n",
      "\n",
      "VALERIA:\n",
      "Indeed, la, 'tis a noble child.\n",
      "\n",
      "VIRGILIA:\n",
      "A crack, madam.\n",
      "\n",
      "VALERIA:\n",
      "Come, lay aside your stitchery; I must have you play\n",
      "the idle husewife with me this afternoon.\n",
      "\n",
      "VIRGILIA:\n",
      "No, good madam; I will not out of doors.\n",
      "\n",
      "VALERIA:\n",
      "Not out of doors!\n",
      "\n",
      "VOLUMNIA:\n",
      "She shall, she shall.\n",
      "\n",
      "VIRGILIA:\n",
      "Indeed, no, by your patience; I'll not over the\n",
      "threshold till my lord return from the wars.\n",
      "\n",
      "VALERIA:\n",
      "Fie, you confine yourself most unreasonably: come,\n",
      "you must go visit the good lady that lies in.\n",
      "\n",
      "VIRGILIA:\n",
      "I will wish her speedy strength, and visit her with\n",
      "my prayers; but I cannot go thither.\n",
      "\n",
      "VOLUMNIA:\n",
      "Why, I pray you?\n",
      "\n",
      "VIRGILIA:\n",
      "'Tis not to save labour, nor that I want love.\n",
      "\n",
      "VALERIA:\n",
      "You would be another Penelope: yet, they say, all\n",
      "the yarn she spun in Ulysses' absence did but fill\n",
      "Ithaca full of moths. Come; I would your cambric\n",
      "were sensible as your finger, that you might leave\n",
      "pricking it for pity. Come, you shall go with us.\n",
      "\n",
      "VIRGILIA:\n",
      "No, good madam, pardon me; indeed, I will not forth.\n",
      "\n",
      "VALERIA:\n",
      "In truth, la, go with me; and I'll tell you\n",
      "excellent news of your husband.\n",
      "\n",
      "VIRGILIA:\n",
      "O, good madam, there can be none yet.\n",
      "\n",
      "VALERIA:\n",
      "Verily, I do not jest with you; there came news from\n",
      "him last night.\n",
      "\n",
      "VIRGILIA:\n",
      "Indeed, madam?\n",
      "\n",
      "VALERIA:\n",
      "In earnest, it's true; I heard a senator speak it.\n",
      "Thus it is: the Volsces have an army forth; against\n",
      "whom Cominius the general is gone, with one part of\n",
      "our Roman power: your lord and Titus Lartius are set\n",
      "down before their city Corioli; they nothing doubt\n",
      "prevailing and to make it brief wars. This is true,\n",
      "on mine honour; and so, I pray, go with us.\n",
      "\n",
      "VIRGILIA:\n",
      "Give me excuse, good madam; I will obey you in every\n",
      "thing hereafter.\n",
      "\n",
      "VOLUMNIA:\n",
      "Let her alone, lady: as she is now, she will but\n",
      "disease our better mirth.\n",
      "\n",
      "VALERIA:\n",
      "In troth, I think she would. Fare you well, then.\n",
      "Come, good sweet lady. Prithee, Virgilia, turn thy\n",
      "solemness out o' door. and go along with us.\n",
      "\n",
      "VIRGILIA:\n",
      "No, at a word, madam; indeed, I must not. I wish\n",
      "you much mirth.\n",
      "\n",
      "VALERIA:\n",
      "Well, then, farewell.\n",
      "\n",
      "MARCIUS:\n",
      "Yonder comes news. A wager they have met.\n",
      "\n",
      "LARTIUS:\n",
      "My horse to yours, no.\n",
      "\n",
      "MARCIUS:\n",
      "'Tis done.\n",
      "\n",
      "LARTIUS:\n",
      "Agreed.\n",
      "\n",
      "MARCIUS:\n",
      "Say, has our general met the enemy?\n",
      "\n",
      "Messenger:\n",
      "They lie in view; but have not spoke as yet.\n",
      "\n",
      "LARTIUS:\n",
      "So, the good horse is mine.\n",
      "\n",
      "MARCIUS:\n",
      "I'll buy him of you.\n",
      "\n",
      "LARTIUS:\n",
      "No, I'll nor sell nor give him: lend you him I will\n",
      "For half a hundred years. Summon the town.\n",
      "\n",
      "MARCIUS:\n",
      "How far off lie these armies?\n",
      "\n",
      "Messenger:\n",
      "Within this mile and half.\n",
      "\n",
      "MARCIUS:\n",
      "Then shall we hear their 'larum, and they ours.\n",
      "Now, Mars, I prithee, make us quick in work,\n",
      "That we with smoking swords may march from hence,\n",
      "To help our fielded friends! Come, blow thy blast.\n",
      "Tutus Aufidius, is he within your walls?\n",
      "\n",
      "First Senator:\n",
      "No, nor a man that fears you less than he,\n",
      "That's lesser than a little.\n",
      "Hark! our drums\n",
      "Are bringing forth our youth. We'll break our walls,\n",
      "Rather than they shall pound us up: our gates,\n",
      "Which yet seem shut, we, have but pinn'd with rushes;\n",
      "They'll open of themselves.\n",
      "Hark you. far off!\n",
      "There is Aufidius; list, what work he makes\n",
      "Amongst your cloven army.\n",
      "\n",
      "MARCIUS:\n",
      "O, they are at it!\n",
      "\n",
      "LARTIUS:\n",
      "Their noise be our instruction. Ladders, ho!\n",
      "\n",
      "MARCIUS:\n",
      "They fear us not, but issue forth their city.\n",
      "Now put your shields before your hearts, and fight\n",
      "With hearts more proof than shields. Advance,\n",
      "brave Titus:\n",
      "They do disdain us much beyond our thoughts,\n",
      "Which makes me sweat with wrath. Come on, my fellows:\n",
      "He that retires I'll take him for a Volsce,\n",
      "And he shall feel mine edge.\n",
      "\n",
      "MARCIUS:\n",
      "All the contagion of the south light on you,\n",
      "You shames of Rome! you herd of--Boils and plagues\n",
      "Plaster you o'er, that you may be abhorr'd\n",
      "Further than seen and one infect another\n",
      "Against the wind a mile! You souls of geese,\n",
      "That bear the shapes of men, how have you run\n",
      "From slaves that apes would beat! Pluto and hell!\n",
      "All hurt behind; backs red, and faces pale\n",
      "With flight and agued fear! Mend and charge home,\n",
      "Or, by the fires of heaven, I'll leave the foe\n",
      "And make my wars on you: look to't: come on;\n",
      "If you'll stand fast, we'll beat them to their wives,\n",
      "As they us to our trenches followed.\n",
      "So, now the gates are ope: now prove good seconds:\n",
      "'Tis for the followers fortune widens them,\n",
      "Not for the fliers: mark me, and do the like.\n",
      "\n",
      "First Soldier:\n",
      "Fool-hardiness; not I.\n",
      "\n",
      "Second Soldier:\n",
      "Nor I.\n",
      "\n",
      "First Soldier:\n",
      "See, they have shut him in.\n",
      "\n",
      "All:\n",
      "To the pot, I warrant him.\n",
      "\n",
      "LARTIUS:\n",
      "What is become of Marcius?\n",
      "\n",
      "All:\n",
      "Slain, sir, doubtless.\n",
      "\n",
      "First Soldier:\n",
      "Following the fliers at the very heels,\n",
      "With them he enters; who, upon the sudden,\n",
      "Clapp'd to their gates: he is himself alone,\n",
      "To answer all the city.\n",
      "\n",
      "LARTIUS:\n",
      "O noble fellow!\n",
      "Who sensibly outdares his senseless sword,\n",
      "And, when it bows, stands up. Thou art left, Marcius:\n",
      "A carbuncle entire, as big as thou art,\n",
      "Were not so rich a jewel. Thou wast a soldier\n",
      "Even to Cato's wish, not fierce and terrible\n",
      "Only in strokes; but, with thy grim looks and\n",
      "The thunder-like percussion of thy sounds,\n",
      "Thou madst thine enemies shake, as if the world\n",
      "Were feverous and did tremble.\n",
      "\n",
      "First Soldier:\n",
      "Look, sir.\n",
      "\n",
      "LARTIUS:\n",
      "O,'tis Marcius!\n",
      "Let's fetch him off, or make remain alike.\n",
      "\n",
      "First Roman:\n",
      "This will I carry to Rome.\n",
      "\n",
      "Second Roman:\n",
      "And I this.\n",
      "\n",
      "Third Roman:\n",
      "A murrain on't! I took this for silver.\n",
      "\n",
      "MARCIUS:\n",
      "See here these movers that do prize their hours\n",
      "At a crack'd drachm! Cushions, leaden spoons,\n",
      "Irons of a doit, doublets that hangmen would\n",
      "Bury with those that wore them, these base slaves,\n",
      "Ere yet the fight be done, pack up: down with them!\n",
      "And hark, what noise the general makes! To him!\n",
      "There is the man of my soul's hate, Aufidius,\n",
      "Piercing our Romans: then, valiant Titus, take\n",
      "Convenient numbers to make good the city;\n",
      "Whilst I, with those that have the spirit, will haste\n",
      "To help Cominius.\n",
      "\n",
      "LARTIUS:\n",
      "Worthy sir, thou bleed'st;\n",
      "Thy exercise hath been too violent for\n",
      "A second course of fight.\n",
      "\n",
      "MARCIUS:\n",
      "Sir, praise me not;\n",
      "My work hath yet not warm'd me: fare you well:\n",
      "The blood I drop is rather physical\n",
      "Than dangerous to me: to Aufidius thus\n",
      "I will appear, and fight.\n",
      "\n",
      "LARTIUS:\n",
      "Now the fair goddess, Fortune,\n",
      "Fall deep in love with thee; and her great charms\n",
      "Misguide thy opposers' swords! Bold gentleman,\n",
      "Prosperity be thy page!\n",
      "\n",
      "MARCIUS:\n",
      "Thy friend no less\n",
      "Than those she placeth highest! So, farewell.\n",
      "\n",
      "LARTIUS:\n",
      "Thou worthiest Marcius!\n",
      "Go, sound thy trumpet in the market-place;\n",
      "Call thither all the officers o' the town,\n",
      "Where they shall know our mind: away!\n",
      "\n",
      "COMINIUS:\n",
      "Breathe you, my friends: well fought;\n",
      "we are come off\n",
      "Like Romans, neither foolish in our stands,\n",
      "Nor cowardly in retire: believe me, sirs,\n",
      "We shall be charged again. Whiles we have struck,\n",
      "By interims and conveying gusts we have heard\n",
      "The charges of our friends. Ye Roman gods!\n",
      "Lead their successes as we wish our own,\n",
      "That both our powers, with smiling\n",
      "fronts encountering,\n",
      "May give you thankful sacrifice.\n",
      "Thy news?\n",
      "\n",
      "Messenger:\n",
      "The citizens of Corioli have issued,\n",
      "And given to Lartius and to Marcius battle:\n",
      "I saw our party to their trenches driven,\n",
      "And then I came away.\n",
      "\n",
      "COMINIUS:\n",
      "Though thou speak'st truth,\n",
      "Methinks thou speak'st not well.\n",
      "How long is't since?\n",
      "\n",
      "Messenger:\n",
      "Above an hour, my lord.\n",
      "\n",
      "COMINIUS:\n",
      "'Tis not a mile; briefly we heard their drums:\n",
      "How couldst thou in a mile confound an hour,\n",
      "And bring thy news so late?\n",
      "\n",
      "Messenger:\n",
      "Spies of the Volsces\n",
      "Held me in chase, that I was forced to wheel\n",
      "Three or four miles about, else had I, sir,\n",
      "Half an hour since brought my report.\n",
      "\n",
      "COMINIUS:\n",
      "Who's yonder,\n",
      "That does appear as he were flay'd? O gods\n",
      "He has the stamp of Marcius; and I have\n",
      "Before-time seen him thus.\n",
      "\n",
      "MARCIUS:\n",
      "\n",
      "COMINIUS:\n",
      "The shepherd knows not thunder from a tabour\n",
      "More than I know the sound of Marcius' tongue\n",
      "From every meaner man.\n",
      "\n",
      "MARCIUS:\n",
      "Come I too late?\n",
      "\n",
      "COMINIUS:\n",
      "Ay, if you come not in the blood of others,\n",
      "But mantled in your own.\n",
      "\n",
      "MARCIUS:\n",
      "O, let me clip ye\n",
      "In arms as sound as when I woo'd, in heart\n",
      "As merry as when our nuptial day was done,\n",
      "And tapers burn'd to bedward!\n",
      "\n",
      "COMINIUS:\n",
      "Flower of warriors,\n",
      "How is it with Titus Lartius?\n",
      "\n",
      "MARCIUS:\n",
      "As with a man busied about decrees:\n",
      "Condemning some to death, and some to exile;\n",
      "Ransoming him, or pitying, threatening the other;\n",
      "Holding Corioli in the name of Rome,\n",
      "Even like a fawning greyhound in the leash,\n",
      "To let him slip at will.\n",
      "\n",
      "COMINIUS:\n",
      "Where is that slave\n",
      "Which told me they had beat you to your trenches?\n",
      "Where is he? call him hither.\n",
      "\n",
      "MARCIUS:\n",
      "Let him alone;\n",
      "He did inform the truth: but for our gentlemen,\n",
      "The common file--a plague! tribunes for them!--\n",
      "The mouse ne'er shunn'd the cat as they did budge\n",
      "From rascals worse than they.\n",
      "\n",
      "COMINIUS:\n",
      "But how prevail'd you?\n",
      "\n",
      "MARCIUS:\n",
      "Will the time serve to tell? I do not think.\n",
      "Where is the enemy? are you lords o' the field?\n",
      "If not, why cease you till you are so?\n",
      "\n",
      "COMINIUS:\n",
      "Marcius,\n",
      "We have at disadvantage fought and did\n",
      "Retire to win our purpose.\n",
      "\n",
      "MARCIUS:\n",
      "How lies their battle? know you on which side\n",
      "They have placed their men of trust?\n",
      "\n",
      "COMINIUS:\n",
      "As I guess, Marcius,\n",
      "Their bands i' the vaward are the Antiates,\n",
      "Of their best trust; o'er them Aufidius,\n",
      "Their very heart of hope.\n",
      "\n",
      "MARCIUS:\n",
      "I do beseech you,\n",
      "By all the battles wherein we have fought,\n",
      "By the blood we have shed together, by the vows\n",
      "We have made to endure friends, that you directly\n",
      "Set me against Aufidius and his Antiates;\n",
      "And that you not delay the present, but,\n",
      "Filling the air with swords advanced and darts,\n",
      "We prove this very hour.\n",
      "\n",
      "COMINIUS:\n",
      "Though I could wish\n",
      "You were conducted to a gentle bath\n",
      "And balms applied to, you, yet dare I never\n",
      "Deny your asking: take your choice of those\n",
      "That best can aid your action.\n",
      "\n",
      "MARCIUS:\n",
      "Those are they\n",
      "That most are willing. If any such be here--\n",
      "As it were sin to doubt--that love this painting\n",
      "Wherein you see me smear'd; if any fear\n",
      "Lesser his person than an ill report;\n",
      "If any think brave death outweighs bad life\n",
      "And that his country's dearer than himself;\n",
      "Let him alone, or so many so minded,\n",
      "Wave thus, to express his disposition,\n",
      "And follow Marcius.\n",
      "O, me alone! make you a sword of me?\n",
      "If these shows be not outward, which of you\n",
      "But is four Volsces? none of you but is\n",
      "Able to bear against the great Aufidius\n",
      "A shield as hard as his. A certain number,\n",
      "Though thanks to all, must I select\n",
      "from all: the rest\n",
      "Shall bear the business in some other fight,\n",
      "As cause will be obey'd. Please you to march;\n",
      "And four shall quickly draw out my command,\n",
      "Which men are best inclined.\n",
      "\n",
      "COMINIUS:\n",
      "March on, my fellows:\n",
      "Make good this ostentation, and you shall\n",
      "Divide in all with us.\n",
      "\n",
      "LARTIUS:\n",
      "So, let the ports be guarded: keep your duties,\n",
      "As I have set them down. If I do send, dispatch\n",
      "Those centuries to our aid: the rest will serve\n",
      "For a short holding: if we lose the field,\n",
      "We cannot keep the town.\n",
      "\n",
      "Lieutenant:\n",
      "Fear not our care, sir.\n",
      "\n",
      "LARTIUS:\n",
      "Hence, and shut your gates upon's.\n",
      "Our guider, come; to the Roman camp conduct us.\n",
      "\n",
      "MARCIUS:\n",
      "I'll fight with none but thee; for I do hate thee\n",
      "Worse than a promise-breaker.\n",
      "\n",
      "AUFIDIUS:\n",
      "We hate alike:\n",
      "Not Afric owns a serpent I abhor\n",
      "More than thy fame and envy. Fix thy foot.\n",
      "\n",
      "MARCIUS:\n",
      "Let the first budger die the other's slave,\n",
      "And the gods doom him after!\n",
      "\n",
      "AUFIDIUS:\n",
      "If I fly, Marcius,\n",
      "Holloa me like a hare.\n",
      "\n",
      "MARCIUS:\n",
      "Within these three hours, Tullus,\n",
      "Alone I fought in your Corioli walls,\n",
      "And made what work I pleased: 'tis not my blood\n",
      "Wherein thou seest me mask'd; for thy revenge\n",
      "Wrench up thy power to the highest.\n",
      "\n",
      "AUFIDIUS:\n",
      "Wert thou the Hector\n",
      "That was the whip of your bragg'd progeny,\n",
      "Thou shouldst not scape me here.\n",
      "Officious, and not valiant, you have shamed me\n",
      "In your condemned seconds.\n",
      "\n",
      "COMINIUS:\n",
      "If I should tell thee o'er this thy day's work,\n",
      "Thou'ldst not believe thy deeds: but I'll report it\n",
      "Where senators shall mingle tears with smiles,\n",
      "Where great patricians shall attend and shrug,\n",
      "I' the end admire, where ladies shall be frighted,\n",
      "And, gladly quaked, hear more; where the\n",
      "dull tribunes,\n",
      "That, with the fusty plebeians, hate thine honours,\n",
      "Shall say against their hearts 'We thank the gods\n",
      "Our Rome hath such a soldier.'\n",
      "Yet camest thou to a morsel of this feast,\n",
      "Having fully dined before.\n",
      "\n",
      "LARTIUS:\n",
      "O general,\n",
      "Here is the steed, we the caparison:\n",
      "Hadst thou beheld--\n",
      "\n",
      "MARCIUS:\n",
      "Pray now, no more: my mother,\n",
      "Who has a charter to extol her blood,\n",
      "When she does praise me grieves me. I have done\n",
      "As you have done; that's what I can; induced\n",
      "As you have been; that's for my country:\n",
      "He that has but effected his good will\n",
      "Hath overta'en mine act.\n",
      "\n",
      "COMINIUS:\n",
      "You shall not be\n",
      "The grave of your deserving; Rome must know\n",
      "The value of her own: 'twere a concealment\n",
      "Worse than a theft, no less than a traducement,\n",
      "To hide your doings; and to silence that,\n",
      "Which, to the spire and top of praises vouch'd,\n",
      "Would seem but modest: therefore, I beseech you\n",
      "In sign of what you are, not to reward\n",
      "What you have done--before our army hear me.\n",
      "\n",
      "MARCIUS:\n",
      "I have some wounds upon me, and they smart\n",
      "To hear themselves remember'd.\n",
      "\n",
      "COMINIUS:\n",
      "Should they not,\n",
      "Well might they fester 'gainst ingratitude,\n",
      "And tent themselves with death. Of all the horses,\n",
      "Whereof we have ta'en good and good store, of all\n",
      "The treasure in this field achieved and city,\n",
      "We render you the tenth, to be ta'en forth,\n",
      "Before the common distribution, at\n",
      "Your only choice.\n",
      "\n",
      "MARCIUS:\n",
      "I thank you, general;\n",
      "But cannot make my heart consent to take\n",
      "A bribe to pay my sword: I do refuse it;\n",
      "And stand upon my common part with those\n",
      "That have beheld the doing.\n",
      "\n",
      "MARCIUS:\n",
      "May these same instruments, which you profane,\n",
      "Never sound more! when drums and trumpets shall\n",
      "I' the field prove flatterers, let courts and cities be\n",
      "Made all of false-faced soothing!\n",
      "When steel grows soft as the parasite's silk,\n",
      "Let him be made a coverture for the wars!\n",
      "No more, I say! For that I have not wash'd\n",
      "My nose that bled, or foil'd some debile wretch.--\n",
      "Which, without note, here's many else have done,--\n",
      "You shout me forth\n",
      "In acclamations hyperbolical;\n",
      "As if I loved my little should be dieted\n",
      "In praises sauced with lies.\n",
      "\n",
      "COMINIUS:\n",
      "Too modest are you;\n",
      "More cruel to your good report than grateful\n",
      "To us that give you truly: by your patience,\n",
      "If 'gainst yourself you be incensed, we'll put you,\n",
      "Like one that means his proper harm, in manacles,\n",
      "Then reason safely with you. Therefore, be it known,\n",
      "As to us, to all the world, that Caius Marcius\n",
      "Wears this war's garland: in token of the which,\n",
      "My noble steed, known to the camp, I give him,\n",
      "With all his trim belonging; and from this time,\n",
      "For what he did before Corioli, call him,\n",
      "With all the applause and clamour of the host,\n",
      "CAIUS MARCIUS CORIOLANUS! Bear\n",
      "The addition nobly ever!\n",
      "\n",
      "All:\n",
      "Caius Marcius Coriolanus!\n",
      "\n",
      "CORIOLANUS:\n",
      "I will go wash;\n",
      "And when my face is fair, you shall perceive\n",
      "Whether I blush or no: howbeit, I thank you.\n",
      "I mean to stride your steed, and at all times\n",
      "To undercrest your good addition\n",
      "To the fairness of my power.\n",
      "\n",
      "COMINIUS:\n",
      "So, to our tent;\n",
      "Where, ere we do repose us, we will write\n",
      "To Rome of our success. You, Titus Lartius,\n",
      "Must to Corioli back: send us to Rome\n",
      "The best, with whom we may articulate,\n",
      "For their own good and ours.\n",
      "\n",
      "LARTIUS:\n",
      "I shall, my lord.\n",
      "\n",
      "CORIOLANUS:\n",
      "The gods begin to mock me. I, that now\n",
      "Refused most princely gifts, am bound to beg\n",
      "Of my lord general.\n",
      "\n",
      "COMINIUS:\n",
      "Take't; 'tis yours. What is't?\n",
      "\n",
      "CORIOLANUS:\n",
      "I sometime lay here in Corioli\n",
      "At a poor man's house; he used me kindly:\n",
      "He cried to me; I saw him prisoner;\n",
      "But then Aufidius was within my view,\n",
      "And wrath o'erwhelm'd my pity: I request you\n",
      "To give my poor host freedom.\n",
      "\n",
      "COMINIUS:\n",
      "O, well begg'd!\n",
      "Were he the butcher of my son, he should\n",
      "Be free as is the wind. Deliver him, Titus.\n",
      "\n",
      "LARTIUS:\n",
      "Marcius, his name?\n",
      "\n",
      "CORIOLANUS:\n",
      "By Jupiter! forgot.\n",
      "I am weary; yea, my memory is tired.\n",
      "Have we no wine here?\n",
      "\n",
      "COMINIUS:\n",
      "Go we to our tent:\n",
      "The blood upon your visage dries; 'tis time\n",
      "It should be look'd to: come.\n",
      "\n",
      "AUFIDIUS:\n",
      "The town is ta'en!\n",
      "\n",
      "First Soldier:\n",
      "'Twill be deliver'd back on good condition.\n",
      "\n",
      "AUFIDIUS:\n",
      "Condition!\n",
      "I would I were a Roman; for I cannot,\n",
      "Being a Volsce, be that I am. Condition!\n",
      "What good condition can a treaty find\n",
      "I' the part that is at mercy? Five times, Marcius,\n",
      "I have fought with thee: so often hast thou beat me,\n",
      "And wouldst do so, I think, should we encounter\n",
      "As often as we eat. By the elements,\n",
      "If e'er again I meet him beard to beard,\n",
      "He's mine, or I am his: mine emulation\n",
      "Hath not that honour in't it had; for where\n",
      "I thought to crush him in an equal force,\n",
      "True sword to sword, I'll potch at him some way\n",
      "Or wrath or craft may get him.\n",
      "\n",
      "First Soldier:\n",
      "He's the devil.\n",
      "\n",
      "AUFIDIUS:\n",
      "Bolder, though not so subtle. My valour's poison'd\n",
      "With only suffering stain by him; for him\n",
      "Shall fly out of itself: nor sleep nor sanctuary,\n",
      "Being naked, sick, nor fane nor Capitol,\n",
      "The prayers of priests nor times of sacrifice,\n",
      "Embarquements all of fury, shall lift up\n",
      "Their rotten privilege and custom 'gainst\n",
      "My hate to Marcius: where I find him, were it\n",
      "At home, upon my brother's guard, even there,\n",
      "Against the hospitable canon, would I\n",
      "Wash my fierce hand in's heart. Go you to the city;\n",
      "Learn how 'tis held; and what they are that must\n",
      "Be hostages for Rome.\n",
      "\n",
      "First Soldier:\n",
      "Will not you go?\n",
      "\n",
      "AUFIDIUS:\n",
      "I am attended at the cypress grove: I pray you--\n",
      "'Tis south the city mills--bring me word thither\n",
      "How the world goes, that to the pace of it\n",
      "I may spur on my journey.\n",
      "\n",
      "First Soldier:\n",
      "I shall, sir.\n",
      "\n",
      "MENENIUS:\n",
      "The augurer tells me we shall have news to-night.\n",
      "\n",
      "BRUTUS:\n",
      "Good or bad?\n",
      "\n",
      "MENENIUS:\n",
      "Not according to the prayer of the people, for they\n",
      "love not Marcius.\n",
      "\n",
      "SICINIUS:\n",
      "Nature teaches beasts to know their friends.\n",
      "\n",
      "MENENIUS:\n",
      "Pray you, who does the wolf love?\n",
      "\n",
      "SICINIUS:\n",
      "The lamb.\n",
      "\n",
      "MENENIUS:\n",
      "Ay, to devour him; as the hungry plebeians would the\n",
      "noble Marcius.\n",
      "\n",
      "BRUTUS:\n",
      "He's a lamb indeed, that baes like a bear.\n",
      "\n",
      "MENENIUS:\n",
      "He's a bear indeed, that lives like a lamb. You two\n",
      "are old men: tell me one thing that I shall ask you.\n",
      "\n",
      "Both:\n",
      "Well, sir.\n",
      "\n",
      "MENENIUS:\n",
      "In what enormity is Marcius poor in, that you two\n",
      "have not in abundance?\n",
      "\n",
      "BRUTUS:\n",
      "He's poor in no one fault, but stored with all.\n",
      "\n",
      "SICINIUS:\n",
      "Especially in pride.\n",
      "\n",
      "BRUTUS:\n",
      "And topping all others in boasting.\n",
      "\n",
      "MENENIUS:\n",
      "This is strange now: do you two know how you are\n",
      "censured here in the city, I mean of us o' the\n",
      "right-hand file? do you?\n",
      "\n",
      "Both:\n",
      "Why, how are we censured?\n",
      "\n",
      "MENENIUS:\n",
      "Because you talk of pride now,--will you not be angry?\n",
      "\n",
      "Both:\n",
      "Well, well, sir, well.\n",
      "\n",
      "MENENIUS:\n",
      "Why, 'tis no great matter; for a very little thief of\n",
      "occasion will rob you of a great deal of patience:\n",
      "give your dispositions the reins, and be angry at\n",
      "your pleasures; at the least if you take it as a\n",
      "pleasure to you in being so. You blame Marcius for\n",
      "being proud?\n",
      "\n",
      "BRUTUS:\n",
      "We do it not alone, sir.\n",
      "\n",
      "MENENIUS:\n",
      "I know you can do very little alone; for your helps\n",
      "are many, or else your actions would grow wondrous\n",
      "single: your abilities are too infant-like for\n",
      "doing much alone. You talk of pride: O that you\n",
      "could turn your eyes toward the napes of your necks,\n",
      "and make but an interior survey of your good selves!\n",
      "O that you could!\n",
      "\n",
      "BRUTUS:\n",
      "What then, sir?\n",
      "\n",
      "MENENIUS:\n",
      "Why, then you should discover a brace of unmeriting,\n",
      "proud, violent, testy magistrates, alias fools, as\n",
      "any in Rome.\n",
      "\n",
      "SICINIUS:\n",
      "Menenius, you are known well enough too.\n",
      "\n",
      "MENENIUS:\n",
      "I am known to be a humorous patrician, and one that\n",
      "loves a cup of hot wine with not a drop of allaying\n",
      "Tiber in't; said to be something imperfect in\n",
      "favouring the first complaint; hasty and tinder-like\n",
      "upon too trivial motion; one that converses more\n",
      "with the buttock of the night than with the forehead\n",
      "of the morning: what I think I utter, and spend my\n",
      "malice in my breath. Meeting two such wealsmen as\n",
      "you are--I cannot call you Lycurguses--if the drink\n",
      "you give me touch my palate adversely, I make a\n",
      "crooked face at it. I can't say your worships have\n",
      "delivered the matter well, when I find the ass in\n",
      "compound with the major part of your syllables: and\n",
      "though I must be content to bear with those that say\n",
      "you are reverend grave men, yet they lie deadly that\n",
      "tell you you have good faces. If you see this in\n",
      "the map of my microcosm, follows it that I am known\n",
      "well enough too? what barm can your bisson\n",
      "conspectuities glean out of this character, if I be\n",
      "known well enough too?\n",
      "\n",
      "BRUTUS:\n",
      "Come, sir, come, we know you well enough.\n",
      "\n",
      "MENENIUS:\n",
      "You know neither me, yourselves nor any thing. You\n",
      "are ambitious for poor knaves' caps and legs: you\n",
      "wear out a good wholesome forenoon in hearing a\n",
      "cause between an orange wife and a fosset-seller;\n",
      "and then rejourn the controversy of three pence to a\n",
      "second day of audience. When you are hearing a\n",
      "matter between party and party, if you chance to be\n",
      "pinched with the colic, you make faces like\n",
      "mummers; set up the bloody flag against all\n",
      "patience; and, in roaring for a chamber-pot,\n",
      "dismiss the controversy bleeding the more entangled\n",
      "by your hearing: all the peace you make in their\n",
      "cause is, calling both the parties knaves. You are\n",
      "a pair of strange ones.\n",
      "\n",
      "BRUTUS:\n",
      "Come, come, you are well understood to be a\n",
      "perfecter giber for the table than a necessary\n",
      "bencher in the Capitol.\n",
      "\n",
      "MENENIUS:\n",
      "Our very priests must become mockers, if they shall\n",
      "encounter such ridiculous subjects as you are. When\n",
      "you speak best unto the purpose, it is not worth the\n",
      "wagging of your beards; and your beards deserve not\n",
      "so honourable a grave as to stuff a botcher's\n",
      "cushion, or to be entombed in an ass's pack-\n",
      "saddle. Yet you must be saying, Marcius is proud;\n",
      "who in a cheap estimation, is worth predecessors\n",
      "since Deucalion, though peradventure some of the\n",
      "best of 'em were hereditary hangmen. God-den to\n",
      "your worships: more of your conversation would\n",
      "infect my brain, being the herdsmen of the beastly\n",
      "plebeians: I will be bold to take my leave of you.\n",
      "How now, my as fair as noble ladies,--and the moon,\n",
      "were she earthly, no nobler,--whither do you follow\n",
      "your eyes so fast?\n",
      "\n",
      "VOLUMNIA:\n",
      "Honourable Menenius, my boy Marcius approaches; for\n",
      "the love of Juno, let's go.\n",
      "\n",
      "MENENIUS:\n",
      "Ha! Marcius coming home!\n",
      "\n",
      "VOLUMNIA:\n",
      "Ay, worthy Menenius; and with most prosperous\n",
      "approbation.\n",
      "\n",
      "MENENIUS:\n",
      "Take my cap, Jupiter, and I thank thee. Hoo!\n",
      "Marcius coming home!\n",
      "\n",
      "VOLUMNIA:\n",
      "Nay,'tis true.\n",
      "\n",
      "VOLUMNIA:\n",
      "Look, here's a letter from him: the state hath\n",
      "another, his wife another; and, I think, there's one\n",
      "at home for you.\n",
      "\n",
      "MENENIUS:\n",
      "I will make my very house reel tonight: a letter for\n",
      "me!\n",
      "\n",
      "VIRGILIA:\n",
      "Yes, certain, there's a letter for you; I saw't.\n",
      "\n",
      "MENENIUS:\n",
      "A letter for me! it gives me an estate of seven\n",
      "years' health; in which time I will make a lip at\n",
      "the physician: the most sovereign prescription in\n",
      "Galen is but empiricutic, and, to this preservative,\n",
      "of no better report than a horse-drench. Is he\n",
      "not wounded? he was wont to come home wounded.\n",
      "\n",
      "VIRGILIA:\n",
      "O, no, no, no.\n",
      "\n",
      "VOLUMNIA:\n",
      "O, he is wounded; I thank the gods for't.\n",
      "\n",
      "MENENIUS:\n",
      "So do I too, if it be not too much: brings a'\n",
      "victory in his pocket? the wounds become him.\n",
      "\n",
      "VOLUMNIA:\n",
      "On's brows: Menenius, he comes the third time home\n",
      "with the oaken garland.\n",
      "\n",
      "MENENIUS:\n",
      "Has he disciplined Aufidius soundly?\n",
      "\n",
      "VOLUMNIA:\n",
      "Titus Lartius writes, they fought together, but\n",
      "Aufidius got off.\n",
      "\n",
      "MENENIUS:\n",
      "And 'twas time for him too, I'll warrant him that:\n",
      "an he had stayed by him, I would not have been so\n",
      "fidiused for all the chests in Corioli, and the gold\n",
      "that's in them. Is the senate possessed of this?\n",
      "\n",
      "VOLUMNIA:\n",
      "Good ladies, let's go. Yes, yes, yes; the senate\n",
      "has letters from the general, wherein he gives my\n",
      "son the whole name of the war: he hath in this\n",
      "action outdone his former deeds doubly\n",
      "\n",
      "VALERIA:\n",
      "In troth, there's wondrous things spoke of him.\n",
      "\n",
      "MENENIUS:\n",
      "Wondrous! ay, I warrant you, and not without his\n",
      "true purchasing.\n",
      "\n",
      "VIRGILIA:\n",
      "The gods grant them true!\n",
      "\n",
      "VOLUMNIA:\n",
      "True! pow, wow.\n",
      "\n",
      "MENENIUS:\n",
      "True! I'll be sworn they are true.\n",
      "Where is he wounded?\n",
      "God save your good worships! Marcius is coming\n",
      "home: he has more cause to be proud. Where is he wounded?\n",
      "\n",
      "VOLUMNIA:\n",
      "I' the shoulder and i' the left arm there will be\n",
      "large cicatrices to show the people, when he shall\n",
      "stand for his place. He received in the repulse of\n",
      "Tarquin seven hurts i' the body.\n",
      "\n",
      "MENENIUS:\n",
      "One i' the neck, and two i' the thigh,--there's\n",
      "nine that I know.\n",
      "\n",
      "VOLUMNIA:\n",
      "He had, before this last expedition, twenty-five\n",
      "wounds upon him.\n",
      "\n",
      "MENENIUS:\n",
      "Now it's twenty-seven: every gash was an enemy's grave.\n",
      "Hark! the trumpets.\n",
      "\n",
      "VOLUMNIA:\n",
      "These are the ushers of Marcius: before him he\n",
      "carries noise, and behind him he leaves tears:\n",
      "Death, that dark spirit, in 's nervy arm doth lie;\n",
      "Which, being advanced, declines, and then men die.\n",
      "\n",
      "Herald:\n",
      "Know, Rome, that all alone Marcius did fight\n",
      "Within Corioli gates: where he hath won,\n",
      "With fame, a name to Caius Marcius; these\n",
      "In honour follows Coriolanus.\n",
      "Welcome to Rome, renowned Coriolanus!\n",
      "\n",
      "All:\n",
      "Welcome to Rome, renowned Coriolanus!\n",
      "\n",
      "CORIOLANUS:\n",
      "No more of this; it does offend my heart:\n",
      "Pray now, no more.\n",
      "\n",
      "COMINIUS:\n",
      "Look, sir, your mother!\n",
      "\n",
      "CORIOLANUS:\n",
      "O,\n",
      "You have, I know, petition'd all the gods\n",
      "For my prosperity!\n",
      "\n",
      "VOLUMNIA:\n",
      "Nay, my good soldier, up;\n",
      "My gentle Marcius, worthy Caius, and\n",
      "By deed-achieving honour newly named,--\n",
      "What is it?--Coriolanus must I call thee?--\n",
      "But O, thy wife!\n",
      "\n",
      "CORIOLANUS:\n",
      "My gracious silence, hail!\n",
      "Wouldst thou have laugh'd had I come coffin'd home,\n",
      "That weep'st to see me triumph? Ay, my dear,\n",
      "Such eyes the widows in Corioli wear,\n",
      "And mothers that lack sons.\n",
      "\n",
      "MENENIUS:\n",
      "Now, the gods crown thee!\n",
      "\n",
      "CORIOLANUS:\n",
      "And live you yet?\n",
      "O my sweet lady, pardon.\n",
      "\n",
      "VOLUMNIA:\n",
      "I know not where to turn: O, welcome home:\n",
      "And welcome, general: and ye're welcome all.\n",
      "\n",
      "MENENIUS:\n",
      "A hundred thousand welcomes. I could weep\n",
      "And I could laugh, I am light and heavy. Welcome.\n",
      "A curse begin at very root on's heart,\n",
      "That is not glad to see thee! You are three\n",
      "That Rome should dote on: yet, by the faith of men,\n",
      "We have some old crab-trees here\n",
      "at home that will not\n",
      "Be grafted to your relish. Yet welcome, warriors:\n",
      "We call a nettle but a nettle and\n",
      "The faults of fools but folly.\n",
      "\n",
      "COMINIUS:\n",
      "Ever right.\n",
      "\n",
      "CORIOLANUS:\n",
      "Menenius ever, ever.\n",
      "\n",
      "Herald:\n",
      "Give way there, and go on!\n",
      "\n",
      "CORIOLANUS:\n",
      "\n",
      "VOLUMNIA:\n",
      "I have lived\n",
      "To see inherited my very wishes\n",
      "And the buildings of my fancy: only\n",
      "There's one thing wanting, which I doubt not but\n",
      "Our Rome will cast upon thee.\n",
      "\n",
      "CORIOLANUS:\n",
      "Know, good mother,\n",
      "I had rather be their servant in my way,\n",
      "Than sway with them in theirs.\n",
      "\n",
      "COMINIUS:\n",
      "On, to the Capitol!\n",
      "\n",
      "BRUTUS:\n",
      "All tongues speak of him, and the bleared sights\n",
      "Are spectacled to see him: your prattling nurse\n",
      "Into a rapture lets her baby cry\n",
      "While she chats him: the kitchen malkin pins\n",
      "Her richest lockram 'bout her reechy neck,\n",
      "Clambering the walls to eye him: stalls, bulks, windows,\n",
      "Are smother'd up, leads fill'd, and ridges horsed\n",
      "With variable complexions, all agreeing\n",
      "In earnestness to see him: seld-shown flamens\n",
      "Do press among the popular throngs and puff\n",
      "To win a vulgar station: or veil'd dames\n",
      "Commit the war of white and damask in\n",
      "Their nicely-gawded cheeks to the wanton spoil\n",
      "Of Phoebus' burning kisses: such a pother\n",
      "As if that whatsoever god who leads him\n",
      "Were slily crept into his human powers\n",
      "And gave him graceful posture.\n",
      "\n",
      "SICINIUS:\n",
      "On the sudden,\n",
      "I warrant him consul.\n",
      "\n",
      "BRUTUS:\n",
      "Then our office may,\n",
      "During his power, go sleep.\n",
      "\n",
      "SICINIUS:\n",
      "He cannot temperately transport his honours\n",
      "From where he should begin and end, but will\n",
      "Lose those he hath won.\n",
      "\n",
      "BRUTUS:\n",
      "In that there's comfort.\n",
      "\n",
      "SICINIUS:\n",
      "Doubt not\n",
      "The commoners, for whom we stand, but they\n",
      "Upon their ancient malice will forget\n",
      "With the least cause these his new honours, which\n",
      "That he will give them make I as little question\n",
      "As he is proud to do't.\n",
      "\n",
      "BRUTUS:\n",
      "I heard him swear,\n",
      "Were he to stand for consul, never would he\n",
      "Appear i' the market-place nor on him put\n",
      "The napless vesture of humility;\n",
      "Nor showing, as the manner is, his wounds\n",
      "To the people, beg their stinking breaths.\n",
      "\n",
      "SICINIUS:\n",
      "'Tis right.\n",
      "\n",
      "BRUTUS:\n",
      "It was his word: O, he would miss it rather\n",
      "Than carry it but by the suit of the gentry to him,\n",
      "And the desire of the nobles.\n",
      "\n",
      "SICINIUS:\n",
      "I wish no better\n",
      "Than have him hold that purpose and to put it\n",
      "In execution.\n",
      "\n",
      "BRUTUS:\n",
      "'Tis most like he will.\n",
      "\n",
      "SICINIUS:\n",
      "It shall be to him then as our good wills,\n",
      "A sure destruction.\n",
      "\n",
      "BRUTUS:\n",
      "So it must fall out\n",
      "To him or our authorities. For an end,\n",
      "We must suggest the people in what hatred\n",
      "He still hath held them; that to's power he would\n",
      "Have made them mules, silenced their pleaders and\n",
      "Dispropertied their freedoms, holding them,\n",
      "In human action and capacity,\n",
      "Of no more soul nor fitness for the world\n",
      "Than camels in the war, who have their provand\n",
      "Only for bearing burdens, and sore blows\n",
      "For sinking under them.\n",
      "\n",
      "SICINIUS:\n",
      "This, as you say, suggested\n",
      "At some time when his soaring insolence\n",
      "Shall touch the people--which time shall not want,\n",
      "If he be put upon 't; and that's as easy\n",
      "As to set dogs on sheep--will be his fire\n",
      "To kindle their dry stubble; and their blaze\n",
      "Shall darken him for ever.\n",
      "\n",
      "BRUTUS:\n",
      "What's the matter?\n",
      "\n",
      "Messenger:\n",
      "You are sent for to the Capitol. 'Tis thought\n",
      "That Marcius shall be consul:\n",
      "I have seen the dumb men throng to see him and\n",
      "The blind to bear him speak: matrons flung gloves,\n",
      "Ladies and maids their scarfs and handkerchers,\n",
      "Upon him as he pass'd: the nobles bended,\n",
      "As to Jove's statue, and the commons made\n",
      "A shower and thunder with their caps and shouts:\n",
      "I never saw the like.\n",
      "\n",
      "BRUTUS:\n",
      "Let's to the Capitol;\n",
      "And carry with us ears and eyes for the time,\n",
      "But hearts for the event.\n",
      "\n",
      "SICINIUS:\n",
      "Have with you.\n",
      "\n",
      "First Officer:\n",
      "Come, come, they are almost here. How many stand\n",
      "for consulships?\n",
      "\n",
      "Second Officer:\n",
      "Three, they say: but 'tis thought of every one\n",
      "Coriolanus will carry it.\n",
      "\n",
      "First Officer:\n",
      "That's a brave fellow; but he's vengeance proud, and\n",
      "loves not the common people.\n",
      "\n",
      "Second Officer:\n",
      "Faith, there had been many great men that have\n",
      "flattered the people, who ne'er loved them; and there\n",
      "be many that they have loved, they know not\n",
      "wherefore: so that, if they love they know not why,\n",
      "they hate upon no better a ground: therefore, for\n",
      "Coriolanus neither to care whether they love or hate\n",
      "him manifests the true knowledge he has in their\n",
      "disposition; and out of his noble carelessness lets\n",
      "them plainly see't.\n",
      "\n",
      "First Officer:\n",
      "If he did not care whether he had their love or no,\n",
      "he waved indifferently 'twixt doing them neither\n",
      "good nor harm: but he seeks their hate with greater\n",
      "devotion than can render it him; and leaves\n",
      "nothing undone that may fully discover him their\n",
      "opposite. Now, to seem to affect the malice and\n",
      "displeasure of the people is as bad as that which he\n",
      "dislikes, to flatter them for their love.\n",
      "\n",
      "Second Officer:\n",
      "He hath deserved worthily of his country: and his\n",
      "ascent is not by such easy degrees as those who,\n",
      "having been supple and courteous to the people,\n",
      "bonneted, without any further deed to have them at\n",
      "an into their estimation and report: but he hath so\n",
      "planted his honours in their eyes, and his actions\n",
      "in their hearts, that for their tongues to be\n",
      "silent, and not confess so much, were a kind of\n",
      "ingrateful injury; to report otherwise, were a\n",
      "malice, that, giving itself the lie, would pluck\n",
      "reproof and rebuke from every ear that heard it.\n",
      "\n",
      "First Officer:\n",
      "No more of him; he is a worthy man: make way, they\n",
      "are coming.\n",
      "\n",
      "MENENIUS:\n",
      "Having determined of the Volsces and\n",
      "To send for Titus Lartius, it remains,\n",
      "As the main point of this our after-meeting,\n",
      "To gratify his noble service that\n",
      "Hath thus stood for his country: therefore,\n",
      "please you,\n",
      "Most reverend and grave elders, to desire\n",
      "The present consul, and last general\n",
      "In our well-found successes, to report\n",
      "A little of that worthy work perform'd\n",
      "By Caius Marcius Coriolanus, whom\n",
      "We met here both to thank and to remember\n",
      "With honours like himself.\n",
      "\n",
      "First Senator:\n",
      "Speak, good Cominius:\n",
      "Leave nothing out for length, and make us think\n",
      "Rather our state's defective for requital\n",
      "Than we to stretch it out.\n",
      "Masters o' the people,\n",
      "We do request your kindest ears, and after,\n",
      "Your loving motion toward the common body,\n",
      "To yield what passes here.\n",
      "\n",
      "SICINIUS:\n",
      "We are convented\n",
      "Upon a pleasing treaty, and have hearts\n",
      "Inclinable to honour and advance\n",
      "The theme of our assembly.\n",
      "\n",
      "BRUTUS:\n",
      "Which the rather\n",
      "We shall be blest to do, if he remember\n",
      "A kinder value of the people than\n",
      "He hath hereto prized them at.\n",
      "\n",
      "MENENIUS:\n",
      "That's off, that's off;\n",
      "I would you rather had been silent. Please you\n",
      "To hear Cominius speak?\n",
      "\n",
      "BRUTUS:\n",
      "Most willingly;\n",
      "But yet my caution was more pertinent\n",
      "Than the rebuke you give it.\n",
      "\n",
      "MENENIUS:\n",
      "He loves your people\n",
      "But tie him not to be their bedfellow.\n",
      "Worthy Cominius, speak.\n",
      "Nay, keep your place.\n",
      "\n",
      "First Senator:\n",
      "Sit, Coriolanus; never shame to hear\n",
      "What you have nobly done.\n",
      "\n",
      "CORIOLANUS:\n",
      "Your horror's pardon:\n",
      "I had rather have my wounds to heal again\n",
      "Than hear say how I got them.\n",
      "\n",
      "BRUTUS:\n",
      "Sir, I hope\n",
      "My words disbench'd you not.\n",
      "\n",
      "CORIOLANUS:\n",
      "No, sir: yet oft,\n",
      "When blows have made me stay, I fled from words.\n",
      "You soothed not, therefore hurt not: but\n",
      "your people,\n",
      "I love them as they weigh.\n",
      "\n",
      "MENENIUS:\n",
      "Pray now, sit down.\n",
      "\n",
      "CORIOLANUS:\n",
      "I had rather have one scratch my head i' the sun\n",
      "When the alarum were struck than idly sit\n",
      "To hear my nothings monster'd.\n",
      "\n",
      "MENENIUS:\n",
      "Masters of the people,\n",
      "Your multiplying spawn how can he flatter--\n",
      "That's thousand to one good one--when you now see\n",
      "He had rather venture all his limbs for honour\n",
      "Than one on's ears to hear it? Proceed, Cominius.\n",
      "\n",
      "COMINIUS:\n",
      "I shall lack voice: the deeds of Coriolanus\n",
      "Should not be utter'd feebly. It is held\n",
      "That valour is the chiefest virtue, and\n",
      "Most dignifies the haver: if it be,\n",
      "The man I speak of cannot in the world\n",
      "Be singly counterpoised. At sixteen years,\n",
      "When Tarquin made a head for Rome, he fought\n",
      "Beyond the mark of others: our then dictator,\n",
      "Whom with all praise I point at, saw him fight,\n",
      "When with his Amazonian chin he drove\n",
      "The bristled lips before him: be bestrid\n",
      "An o'er-press'd Roman and i' the consul's view\n",
      "Slew three opposers: Tarquin's self he met,\n",
      "And struck him on his knee: in that day's feats,\n",
      "When he might act the woman in the scene,\n",
      "He proved best man i' the field, and for his meed\n",
      "Was brow-bound with the oak. His pupil age\n",
      "Man-enter'd thus, he waxed like a sea,\n",
      "And in the brunt of seventeen battles since\n",
      "He lurch'd all swords of the garland. For this last,\n",
      "Before and in Corioli, let me say,\n",
      "I cannot speak him home: he stopp'd the fliers;\n",
      "And by his rare example made the coward\n",
      "Turn terror into sport: as weeds before\n",
      "A vessel under sail, so men obey'd\n",
      "And fell below his stem: his sword, death's stamp,\n",
      "Where it did mark, it took; from face to foot\n",
      "He was a thing of blood, whose every motion\n",
      "Was timed with dying cries: alone he enter'd\n",
      "The mortal gate of the city, which he painted\n",
      "With shunless destiny; aidless came off,\n",
      "And with a sudden reinforcement struck\n",
      "Corioli like a planet: now all's his:\n",
      "When, by and by, the din of war gan pierce\n",
      "His ready sense; then straight his doubled spirit\n",
      "Re-quicken'd what in flesh was fatigate,\n",
      "And to the battle came he; where he did\n",
      "Run reeking o'er the lives of men, as if\n",
      "'Twere a perpetual spoil: and till we call'd\n",
      "Both field and city ours, he never stood\n",
      "To ease his breast with panting.\n",
      "\n",
      "MENENIUS:\n",
      "Worthy man!\n",
      "\n",
      "First Senator:\n",
      "He cannot but with measure fit the honours\n",
      "Which we devise him.\n",
      "\n",
      "COMINIUS:\n",
      "Our spoils he kick'd at,\n",
      "And look'd upon things precious as they were\n",
      "The common muck of the world: he covets less\n",
      "Than misery itself would give; rewards\n",
      "His deeds with doing them, and is content\n",
      "To spend the time to end it.\n",
      "\n",
      "MENENIUS:\n",
      "He's right noble:\n",
      "Let him be call'd for.\n",
      "\n",
      "First Senator:\n",
      "Call Coriolanus.\n",
      "\n",
      "Officer:\n",
      "He doth appear.\n",
      "\n",
      "MENENIUS:\n",
      "The senate, Coriolanus, are well pleased\n",
      "To make thee consul.\n",
      "\n",
      "CORIOLANUS:\n",
      "I do owe them still\n",
      "My life and services.\n",
      "\n",
      "MENENIUS:\n",
      "It then remains\n",
      "That you do speak to the people.\n",
      "\n",
      "CORIOLANUS:\n",
      "I do beseech you,\n",
      "Let me o'erleap that custom, for I cannot\n",
      "Put on the gown, stand naked and entreat them,\n",
      "For my wounds' sake, to give their suffrage: please you\n",
      "That I may pass this doing.\n",
      "\n",
      "SICINIUS:\n",
      "Sir, the people\n",
      "Must have their voices; neither will they bate\n",
      "One jot of ceremony.\n",
      "\n",
      "MENENIUS:\n",
      "Put them not to't:\n",
      "Pray you, go fit you to the custom and\n",
      "Take to you, as your predecessors have,\n",
      "Your honour with your form.\n",
      "\n",
      "CORIOLANUS:\n",
      "It is apart\n",
      "That I shall blush in acting, and might well\n",
      "Be taken from the people.\n",
      "\n",
      "BRUTUS:\n",
      "Mark you that?\n",
      "\n",
      "CORIOLANUS:\n",
      "To brag unto them, thus I did, and thus;\n",
      "Show them the unaching scars which I should hide,\n",
      "As if I had received them for the hire\n",
      "Of their breath only!\n",
      "\n",
      "MENENIUS:\n",
      "Do not stand upon't.\n",
      "We recommend to you, tribunes of the people,\n",
      "Our purpose to them: and to our noble consul\n",
      "Wish we all joy and honour.\n",
      "\n",
      "Senators:\n",
      "To Coriolanus come all joy and honour!\n",
      "\n",
      "BRUTUS:\n",
      "You see how he intends to use the people.\n",
      "\n",
      "SICINIUS:\n",
      "May they perceive's intent! He will require them,\n",
      "As if he did contemn what he requested\n",
      "Should be in them to give.\n",
      "\n",
      "BRUTUS:\n",
      "Come, we'll inform them\n",
      "Of our proceedings here: on the marketplace,\n",
      "I know, they do attend us.\n",
      "\n",
      "First Citizen:\n",
      "Once, if he do require our voices, we ought not to deny him.\n",
      "\n",
      "Second Citizen:\n",
      "We may, sir, if we will.\n",
      "\n",
      "Third Citizen:\n",
      "We have power in ourselves to do it, but it is a\n",
      "power that we have no power to do; for if he show us\n",
      "his wounds and tell us his deeds, we are to put our\n",
      "tongues into those wounds and speak for them; so, if\n",
      "he tell us his noble deeds, we must also tell him\n",
      "our noble acceptance of them. Ingratitude is\n",
      "monstrous, and for the multitude to be ingrateful,\n",
      "were to make a monster of the multitude: of the\n",
      "which we being members, should bring ourselves to be\n",
      "monstrous members.\n",
      "\n",
      "First Citizen:\n",
      "And to make us no better thought of, a little help\n",
      "will serve; for once we stood up about the corn, he\n",
      "himself stuck not to call us the many-headed multitude.\n",
      "\n",
      "Third Citizen:\n",
      "We have been called so of many; not that our heads\n",
      "are some brown, some black, some auburn, some bald,\n",
      "but that our wits are so diversely coloured: and\n",
      "truly I think if all our wits were to issue out of\n",
      "one skull, they would fly east, west, north, south,\n",
      "and their consent of one direct way should be at\n",
      "once to all the points o' the compass.\n",
      "\n",
      "Second Citizen:\n",
      "Think you so? Which way do you judge my wit would\n",
      "fly?\n",
      "\n",
      "Third Citizen:\n",
      "Nay, your wit will not so soon out as another man's\n",
      "will;'tis strongly wedged up in a block-head, but\n",
      "if it were at liberty, 'twould, sure, southward.\n",
      "\n",
      "Second Citizen:\n",
      "Why that way?\n",
      "\n",
      "Third Citizen:\n",
      "To lose itself in a fog, where being three parts\n",
      "melted away with rotten dews, the fourth would return\n",
      "for conscience sake, to help to get thee a wife.\n",
      "\n",
      "Second Citizen:\n",
      "You are never without your tricks: you may, you may.\n",
      "\n",
      "Third Citizen:\n",
      "Are you all resolved to give your voices? But\n",
      "that's no matter, the greater part carries it. I\n",
      "say, if he would incline to the people, there was\n",
      "never a worthier man.\n",
      "Here he comes, and in the gown of humility: mark his\n",
      "behavior. We are not to stay all together, but to\n",
      "come by him where he stands, by ones, by twos, and\n",
      "by threes. He's to make his requests by\n",
      "particulars; wherein every one of us has a single\n",
      "honour, in giving him our own voices with our own\n",
      "tongues: therefore follow me, and I direct you how\n",
      "you shall go by him.\n",
      "\n",
      "All:\n",
      "Content, content.\n",
      "\n",
      "MENENIUS:\n",
      "O sir, you are not right: have you not known\n",
      "The worthiest men have done't?\n",
      "\n",
      "CORIOLANUS:\n",
      "What must I say?\n",
      "'I Pray, sir'--Plague upon't! I cannot bring\n",
      "My tongue to such a pace:--'Look, sir, my wounds!\n",
      "I got them in my country's service, when\n",
      "Some certain of your brethren roar'd and ran\n",
      "From the noise of our own drums.'\n",
      "\n",
      "MENENIUS:\n",
      "O me, the gods!\n",
      "You must not speak of that: you must desire them\n",
      "To think upon you.\n",
      "\n",
      "CORIOLANUS:\n",
      "Think upon me! hang 'em!\n",
      "I would they would forget me, like the virtues\n",
      "Which our divines lose by 'em.\n",
      "\n",
      "MENENIUS:\n",
      "You'll mar all:\n",
      "I'll leave you: pray you, speak to 'em, I pray you,\n",
      "In wholesome manner.\n",
      "\n",
      "CORIOLANUS:\n",
      "Bid them wash their faces\n",
      "And keep their teeth clean.\n",
      "So, here comes a brace.\n",
      "You know the cause, air, of my standing here.\n",
      "\n",
      "Third Citizen:\n",
      "We do, sir; tell us what hath brought you to't.\n",
      "\n",
      "CORIOLANUS:\n",
      "Mine own desert.\n",
      "\n",
      "Second Citizen:\n",
      "Your own desert!\n",
      "\n",
      "CORIOLANUS:\n",
      "Ay, but not mine own desire.\n",
      "\n",
      "Third Citizen:\n",
      "How not your own desire?\n",
      "\n",
      "CORIOLANUS:\n",
      "No, sir,'twas never my desire yet to trouble the\n",
      "poor with begging.\n",
      "\n",
      "Third Citizen:\n",
      "You must think, if we give you any thing, we hope to\n",
      "gain by you.\n",
      "\n",
      "CORIOLANUS:\n",
      "Well then, I pray, your price o' the consulship?\n",
      "\n",
      "First Citizen:\n",
      "The price is to ask it kindly.\n",
      "\n",
      "CORIOLANUS:\n",
      "Kindly! Sir, I pray, let me ha't: I have wounds to\n",
      "show you, which shall be yours in private. Your\n",
      "good voice, sir; what say you?\n",
      "\n",
      "Second Citizen:\n",
      "You shall ha' it, worthy sir.\n",
      "\n",
      "CORIOLANUS:\n",
      "A match, sir. There's in all two worthy voices\n",
      "begged. I have your alms: adieu.\n",
      "\n",
      "Third Citizen:\n",
      "But this is something odd.\n",
      "\n",
      "Second Citizen:\n",
      "An 'twere to give again,--but 'tis no matter.\n",
      "\n",
      "CORIOLANUS:\n",
      "Pray you now, if it may stand with the tune of your\n",
      "voices that I may be consul, I have here the\n",
      "customary gown.\n",
      "\n",
      "Fourth Citizen:\n",
      "You have deserved nobly of your country, and you\n",
      "have not deserved nobly.\n",
      "\n",
      "CORIOLANUS:\n",
      "Your enigma?\n",
      "\n",
      "Fourth Citizen:\n",
      "You have been a scourge to her enemies, you have\n",
      "been a rod to her friends; you have not indeed loved\n",
      "the common people.\n",
      "\n",
      "CORIOLANUS:\n",
      "You should account me the more virtuous that I have\n",
      "not been common in my love. I will, sir, flatter my\n",
      "sworn brother, the people, to earn a dearer\n",
      "estimation of them; 'tis a condition they account\n",
      "gentle: and since the wisdom of their choice is\n",
      "rather to have my hat than my heart, I will practise\n",
      "the insinuating nod and be off to them most\n",
      "counterfeitly; that is, sir, I will counterfeit the\n",
      "bewitchment of some popular man and give it\n",
      "bountiful to the desirers. Therefore, beseech you,\n",
      "I may be consul.\n",
      "\n",
      "Fifth Citizen:\n",
      "We hope to find you our friend; and therefore give\n",
      "you our voices heartily.\n",
      "\n",
      "Fourth Citizen:\n",
      "You have received many wounds for your country.\n",
      "\n",
      "CORIOLANUS:\n",
      "I will not seal your knowledge with showing them. I\n",
      "will make much of your voices, and so trouble you no further.\n",
      "\n",
      "Both Citizens:\n",
      "The gods give you joy, sir, heartily!\n",
      "\n",
      "CORIOLANUS:\n",
      "Most sweet voices!\n",
      "Better it is to die, better to starve,\n",
      "Than crave the hire which first we do deserve.\n",
      "Why in this woolvish toge should I stand here,\n",
      "To beg of Hob and Dick, that do appear,\n",
      "Their needless vouches? Custom calls me to't:\n",
      "What custom wills, in all things should we do't,\n",
      "The dust on antique time would lie unswept,\n",
      "And mountainous error be too highly heapt\n",
      "For truth to o'er-peer. Rather than fool it so,\n",
      "Let the high office and the honour go\n",
      "To one that would do thus. I am half through;\n",
      "The one part suffer'd, the other will I do.\n",
      "Here come more voices.\n",
      "Your voices: for your voices I have fought;\n",
      "Watch'd for your voices; for Your voices bear\n",
      "Of wounds two dozen odd; battles thrice six\n",
      "I have seen and heard of; for your voices have\n",
      "Done many things, some less, some more your voices:\n",
      "Indeed I would be consul.\n",
      "\n",
      "Sixth Citizen:\n",
      "He has done nobly, and cannot go without any honest\n",
      "man's voice.\n",
      "\n",
      "Seventh Citizen:\n",
      "Therefore let him be consul: the gods give him joy,\n",
      "and make him good friend to the people!\n",
      "\n",
      "All Citizens:\n",
      "Amen, amen. God save thee, noble consul!\n",
      "\n",
      "CORIOLANUS:\n",
      "Worthy voices!\n",
      "\n",
      "MENENIUS:\n",
      "You have stood your limitation; and the tribunes\n",
      "Endue you with the people's voice: remains\n",
      "That, in the official marks invested, you\n",
      "Anon do meet the senate.\n",
      "\n",
      "CORIOLANUS:\n",
      "Is this done?\n",
      "\n",
      "SICINIUS:\n",
      "The custom of request you have discharged:\n",
      "The people do admit you, and are summon'd\n",
      "To meet anon, upon your approbation.\n",
      "\n",
      "CORIOLANUS:\n",
      "Where? at the senate-house?\n",
      "\n",
      "SICINIUS:\n",
      "There, Coriolanus.\n",
      "\n",
      "CORIOLANUS:\n",
      "May I change these garments?\n",
      "\n",
      "SICINIUS:\n",
      "You may, sir.\n",
      "\n",
      "CORIOLANUS:\n",
      "That I'll straight do; and, knowing myself again,\n",
      "Repair to the senate-house.\n",
      "\n",
      "MENENIUS:\n",
      "I'll keep you company. Will you along?\n",
      "\n",
      "BRUTUS:\n",
      "We stay here for the people.\n",
      "\n",
      "SICINIUS:\n",
      "Fare you well.\n",
      "He has it now, and by his looks methink\n",
      "'Tis warm at 's heart.\n",
      "\n",
      "BRUTUS:\n",
      "With a proud heart he wore his humble weeds.\n",
      "will you dismiss the people?\n",
      "\n",
      "SICINIUS:\n",
      "How now, my masters! have you chose this man?\n",
      "\n",
      "First Citizen:\n",
      "He has our voices, sir.\n",
      "\n",
      "BRUTUS:\n",
      "We pray the gods he may deserve your loves.\n",
      "\n",
      "Second Citizen:\n",
      "Amen, sir: to my poor unworthy notice,\n",
      "He mock'd us when he begg'd our voices.\n",
      "\n",
      "Third Citizen:\n",
      "Certainly\n",
      "He flouted us downright.\n",
      "\n",
      "First Citizen:\n",
      "No,'tis his kind of speech: he did not mock us.\n",
      "\n",
      "Second Citizen:\n",
      "Not one amongst us, save yourself, but says\n",
      "He used us scornfully: he should have show'd us\n",
      "His marks of merit, wounds received for's country.\n",
      "\n",
      "SICINIUS:\n",
      "Why, so he did, I am sure.\n",
      "\n",
      "Citizens:\n",
      "No, no; no man saw 'em.\n",
      "\n",
      "Third Citizen:\n",
      "He said he had wounds, which he could show\n",
      "in private;\n",
      "And with his hat, thus waving it in scorn,\n",
      "'I would be consul,' says he: 'aged custom,\n",
      "But by your voices, will not so permit me;\n",
      "Your voices therefore.' When we granted that,\n",
      "Here was 'I thank you for your voices: thank you:\n",
      "Your most sweet voices: now you have left\n",
      "your voices,\n",
      "I have no further with you.' Was not this mockery?\n",
      "\n",
      "SICINIUS:\n",
      "Why either were you ignorant to see't,\n",
      "Or, seeing it, of such childish friendliness\n",
      "To yield your voices?\n",
      "\n",
      "BRUTUS:\n",
      "Could you not have told him\n",
      "As you were lesson'd, when he had no power,\n",
      "But was a petty servant to the state,\n",
      "He was your enemy, ever spake against\n",
      "Your liberties and the charters that you bear\n",
      "I' the body of the weal; and now, arriving\n",
      "A place of potency and sway o' the state,\n",
      "If he should still malignantly remain\n",
      "Fast foe to the plebeii, your voices might\n",
      "Be curses to yourselves? You should have said\n",
      "That as his worthy deeds did claim no less\n",
      "Than what he stood for, so his gracious nature\n",
      "Would think upon you for your voices and\n",
      "Translate his malice towards you into love,\n",
      "Standing your friendly lord.\n",
      "\n",
      "SICINIUS:\n",
      "Thus to have said,\n",
      "As you were fore-advised, had touch'd his spirit\n",
      "And tried his inclination; from him pluck'd\n",
      "Either his gracious promise, which you might,\n",
      "As cause had call'd you up, have held him to\n",
      "Or else it would have gall'd his surly nature,\n",
      "Which easily endures not article\n",
      "Tying him to aught; so putting him to rage,\n",
      "You should have ta'en the advantage of his choler\n",
      "And pass'd him unelected.\n",
      "\n",
      "BRUTUS:\n",
      "Did you perceive\n",
      "He did solicit you in free contempt\n",
      "When he did need your loves, and do you think\n",
      "That his contempt shall not be bruising to you,\n",
      "When he hath power to crush? Why, had your bodies\n",
      "No heart among you? or had you tongues to cry\n",
      "Against the rectorship of judgment?\n",
      "\n",
      "SICINIUS:\n",
      "Have you\n",
      "Ere now denied the asker? and now again\n",
      "Of him that did not ask, but mock, bestow\n",
      "Your sued-for tongues?\n",
      "\n",
      "Third Citizen:\n",
      "He's not confirm'd; we may deny him yet.\n",
      "\n",
      "Second Citizen:\n",
      "And will deny him:\n",
      "I'll have five hundred voices of that sound.\n",
      "\n",
      "First Citizen:\n",
      "I twice five hundred and their friends to piece 'em.\n",
      "\n",
      "BRUTUS:\n",
      "Get you hence instantly, and tell those friends,\n",
      "They have chose a consul that will from them take\n",
      "Their liberties; make them of no more voice\n",
      "Than dogs that are as often beat for barking\n",
      "As therefore kept to do so.\n",
      "\n",
      "SICINIUS:\n",
      "Let them assemble,\n",
      "And on a safer judgment all revoke\n",
      "Your ignorant election; enforce his pride,\n",
      "And his old hate unto you; besides, forget not\n",
      "With what contempt he wore the humble weed,\n",
      "How in his suit he scorn'd you; but your loves,\n",
      "Thinking upon his services, took from you\n",
      "The apprehension of his present portance,\n",
      "Which most gibingly, ungravely, he did fashion\n",
      "After the inveterate hate he bears you.\n",
      "\n",
      "BRUTUS:\n",
      "Lay\n",
      "A fault on us, your tribunes; that we laboured,\n",
      "No impediment between, but that you must\n",
      "Cast your election on him.\n",
      "\n",
      "SICINIUS:\n",
      "Say, you chose him\n",
      "More after our commandment than as guided\n",
      "By your own true affections, and that your minds,\n",
      "Preoccupied with what you rather must do\n",
      "Than what you should, made you against the grain\n",
      "To voice him consul: lay the fault on us.\n",
      "\n",
      "BRUTUS:\n",
      "Ay, spare us not. Say we read lectures to you.\n",
      "How youngly he began to serve his country,\n",
      "How long continued, and what stock he springs of,\n",
      "The noble house o' the Marcians, from whence came\n",
      "That Ancus Marcius, Numa's daughter's son,\n",
      "Who, after great Hostilius, here was king;\n",
      "Of the same house Publius and Quintus were,\n",
      "That our beat water brought by conduits hither;\n",
      "And  \n",
      "Twice being  \n",
      "Was his great ancestor.\n",
      "\n",
      "SICINIUS:\n",
      "One thus descended,\n",
      "That hath beside well in his person wrought\n",
      "To be set high in place, we did commend\n",
      "To your remembrances: but you have found,\n",
      "Scaling his present bearing with his past,\n",
      "That he's your fixed enemy, and revoke\n",
      "Your sudden approbation.\n",
      "\n",
      "BRUTUS:\n",
      "Say, you ne'er had done't--\n",
      "Harp on that still--but by our putting on;\n",
      "And presently, when you have drawn your number,\n",
      "Repair to the Capitol.\n",
      "\n",
      "All:\n",
      "We will so: almost all\n",
      "Repent in their election.\n",
      "\n",
      "BRUTUS:\n",
      "Let them go on;\n",
      "This mutiny were better put in hazard,\n",
      "Than stay, past doubt, for greater:\n",
      "If, as his nature is, he fall in rage\n",
      "With their refusal, both observe and answer\n",
      "The vantage of his anger.\n",
      "\n",
      "SICINIUS:\n",
      "To the Capitol, come:\n",
      "We will be there before the stream o' the people;\n",
      "And this shall seem, as partly 'tis, their own,\n",
      "Which we have goaded onward.\n",
      "\n",
      "CORIOLANUS:\n",
      "Tullus Aufidius then had made new head?\n",
      "\n",
      "LARTIUS:\n",
      "He had, my lord; and that it was which caused\n",
      "Our swifter composition.\n",
      "\n",
      "CORIOLANUS:\n",
      "So then the Volsces stand but as at first,\n",
      "Ready, when time shall prompt them, to make road.\n",
      "Upon's again.\n",
      "\n",
      "COMINIUS:\n",
      "They are worn, lord consul, so,\n",
      "That we shall hardly in our ages see\n",
      "Their banners wave again.\n",
      "\n",
      "CORIOLANUS:\n",
      "Saw you Aufidius?\n",
      "\n",
      "LARTIUS:\n",
      "On safe-guard he came to me; and did curse\n",
      "Against the Volsces, for they had so vilely\n",
      "Yielded the town: he is retired to Antium.\n",
      "\n",
      "CORIOLANUS:\n",
      "Spoke he of me?\n",
      "\n",
      "LARTIUS:\n",
      "He did, my lord.\n",
      "\n",
      "CORIOLANUS:\n",
      "How? what?\n",
      "\n",
      "LARTIUS:\n",
      "How often he had met you, sword to sword;\n",
      "That of all things upon the earth he hated\n",
      "Your person most, that he would pawn his fortunes\n",
      "To hopeless restitution, so he might\n",
      "Be call'd your vanquisher.\n",
      "\n",
      "CORIOLANUS:\n",
      "At Antium lives he?\n",
      "\n",
      "LARTIUS:\n",
      "At Antium.\n",
      "\n",
      "CORIOLANUS:\n",
      "I wish I had a cause to seek him there,\n",
      "To oppose his hatred fully. Welcome home.\n",
      "Behold, these are the tribunes of the people,\n",
      "The tongues o' the common mouth: I do despise them;\n",
      "For they do prank them in authority,\n",
      "Against all noble sufferance.\n",
      "\n",
      "SICINIUS:\n",
      "Pass no further.\n",
      "\n",
      "CORIOLANUS:\n",
      "Ha! what is that?\n",
      "\n",
      "BRUTUS:\n",
      "It will be dangerous to go on: no further.\n",
      "\n",
      "CORIOLANUS:\n",
      "What makes this change?\n",
      "\n",
      "MENENIUS:\n",
      "The matter?\n",
      "\n",
      "COMINIUS:\n",
      "Hath he not pass'd the noble and the common?\n",
      "\n",
      "BRUTUS:\n",
      "Cominius, no.\n",
      "\n",
      "CORIOLANUS:\n",
      "Have I had children's voices?\n",
      "\n",
      "First Senator:\n",
      "Tribunes, give way; he shall to the market-place.\n",
      "\n",
      "BRUTUS:\n",
      "The people are incensed against him.\n",
      "\n",
      "SICINIUS:\n",
      "Stop,\n",
      "Or all will fall in broil.\n",
      "\n",
      "CORIOLANUS:\n",
      "Are these your herd?\n",
      "Must these have voices, that can yield them now\n",
      "And straight disclaim their tongues? What are\n",
      "your offices?\n",
      "You being their mouths, why rule you not their teeth?\n",
      "Have you not set them on?\n",
      "\n",
      "MENENIUS:\n",
      "Be calm, be calm.\n",
      "\n",
      "CORIOLANUS:\n",
      "It is a purposed thing, and grows by plot,\n",
      "To curb the will of the nobility:\n",
      "Suffer't, and live with such as cannot rule\n",
      "Nor ever will be ruled.\n",
      "\n",
      "BRUTUS:\n",
      "Call't not a plot:\n",
      "The people cry you mock'd them, and of late,\n",
      "When corn was given them gratis, you repined;\n",
      "Scandal'd the suppliants for the people, call'd them\n",
      "Time-pleasers, flatterers, foes to nobleness.\n",
      "\n",
      "CORIOLANUS:\n",
      "Why, this was known before.\n",
      "\n",
      "BRUTUS:\n",
      "Not to them all.\n",
      "\n",
      "CORIOLANUS:\n",
      "Have you inform'd them sithence?\n",
      "\n",
      "BRUTUS:\n",
      "How! I inform them!\n",
      "\n",
      "CORIOLANUS:\n",
      "You are like to do such business.\n",
      "\n",
      "BRUTUS:\n",
      "Not unlike,\n",
      "Each way, to better yours.\n",
      "\n",
      "CORIOLANUS:\n",
      "Why then should I be consul? By yond clouds,\n",
      "Let me deserve so ill as you, and make me\n",
      "Your fellow tribune.\n",
      "\n",
      "SICINIUS:\n",
      "You show too much of that\n",
      "For which the people stir: if you will pass\n",
      "To where you are bound, you must inquire your way,\n",
      "Which you are out of, with a gentler spirit,\n",
      "Or never be so noble as a consul,\n",
      "Nor yoke with him for tribune.\n",
      "\n",
      "MENENIUS:\n",
      "Let's be calm.\n",
      "\n",
      "COMINIUS:\n",
      "The people are abused; set on. This paltering\n",
      "Becomes not Rome, nor has Coriolanus\n",
      "Deserved this so dishonour'd rub, laid falsely\n",
      "I' the plain way of his merit.\n",
      "\n",
      "CORIOLANUS:\n",
      "Tell me of corn!\n",
      "This was my speech, and I will speak't again--\n",
      "\n",
      "MENENIUS:\n",
      "Not now, not now.\n",
      "\n",
      "First Senator:\n",
      "Not in this heat, sir, now.\n",
      "\n",
      "CORIOLANUS:\n",
      "Now, as I live, I will. My nobler friends,\n",
      "I crave their pardons:\n",
      "For the mutable, rank-scented many, let them\n",
      "Regard me as I do not flatter, and\n",
      "Therein behold themselves: I say again,\n",
      "In soothing them, we nourish 'gainst our senate\n",
      "The cockle of rebellion, insolence, sedition,\n",
      "Which we ourselves have plough'd for, sow'd,\n",
      "and scatter'd,\n",
      "By mingling them with us, the honour'd number,\n",
      "Who lack not virtue, no, nor power, but that\n",
      "Which they have given to beggars.\n",
      "\n",
      "MENENIUS:\n",
      "Well, no more.\n",
      "\n",
      "First Senator:\n",
      "No more words, we beseech you.\n",
      "\n",
      "CORIOLANUS:\n",
      "How! no more!\n",
      "As for my country I have shed my blood,\n",
      "Not fearing outward force, so shall my lungs\n",
      "Coin words till their decay against those measles,\n",
      "Which we disdain should tatter us, yet sought\n",
      "The very way to catch them.\n",
      "\n",
      "BRUTUS:\n",
      "You speak o' the people,\n",
      "As if you were a god to punish, not\n",
      "A man of their infirmity.\n",
      "\n",
      "SICINIUS:\n",
      "'Twere well\n",
      "We let the people know't.\n",
      "\n",
      "MENENIUS:\n",
      "What, what? his choler?\n",
      "\n",
      "CORIOLANUS:\n",
      "Choler!\n",
      "Were I as patient as the midnight sleep,\n",
      "By Jove, 'twould be my mind!\n",
      "\n",
      "SICINIUS:\n",
      "It is a mind\n",
      "That shall remain a poison where it is,\n",
      "Not poison any further.\n",
      "\n",
      "CORIOLANUS:\n",
      "Shall remain!\n",
      "Hear you this Triton of the minnows? mark you\n",
      "His absolute 'shall'?\n",
      "\n",
      "COMINIUS:\n",
      "'Twas from the canon.\n",
      "\n",
      "CORIOLANUS:\n",
      "'Shall'!\n",
      "O good but most unwise patricians! why,\n",
      "You grave but reckless senators, have you thus\n",
      "Given Hydra here to choose an officer,\n",
      "That with his peremptory 'shall,' being but\n",
      "The horn and noise o' the monster's, wants not spirit\n",
      "To say he'll turn your current in a ditch,\n",
      "And make your channel his? If he have power\n",
      "Then vail your ignorance; if none, awake\n",
      "Your dangerous lenity. If you are learn'd,\n",
      "Be not as common fools; if you are not,\n",
      "Let them have cushions by you. You are plebeians,\n",
      "If they be senators: and they are no less,\n",
      "When, both your voices blended, the great'st taste\n",
      "Most palates theirs. They choose their magistrate,\n",
      "And such a one as he, who puts his 'shall,'\n",
      "His popular 'shall' against a graver bench\n",
      "Than ever frown in Greece. By Jove himself!\n",
      "It makes the consuls base: and my soul aches\n",
      "To know, when two authorities are up,\n",
      "Neither supreme, how soon confusion\n",
      "May enter 'twixt the gap of both and take\n",
      "The one by the other.\n",
      "\n",
      "COMINIUS:\n",
      "Well, on to the market-place.\n",
      "\n",
      "CORIOLANUS:\n",
      "Whoever gave that counsel, to give forth\n",
      "The corn o' the storehouse gratis, as 'twas used\n",
      "Sometime in Greece,--\n",
      "\n",
      "MENENIUS:\n",
      "Well, well, no more of that.\n",
      "\n",
      "CORIOLANUS:\n",
      "Though there the people had more absolute power,\n",
      "I say, they nourish'd disobedience, fed\n",
      "The ruin of the state.\n",
      "\n",
      "BRUTUS:\n",
      "Why, shall the people give\n",
      "One that speaks thus their voice?\n",
      "\n",
      "CORIOLANUS:\n",
      "I'll give my reasons,\n",
      "More worthier than their voices. They know the corn\n",
      "Was not our recompense, resting well assured\n",
      "That ne'er did service for't: being press'd to the war,\n",
      "Even when the navel of the state was touch'd,\n",
      "They would not thread the gates. This kind of service\n",
      "Did not deserve corn gratis. Being i' the war\n",
      "Their mutinies and revolts, wherein they show'd\n",
      "Most valour, spoke not for them: the accusation\n",
      "Which they have often made against the senate,\n",
      "All cause unborn, could never be the motive\n",
      "Of our so frank donation. Well, what then?\n",
      "How shall this bisson multitude digest\n",
      "The senate's courtesy? Let deeds express\n",
      "What's like to be their words: 'we did request it;\n",
      "We are the greater poll, and in true fear\n",
      "They gave us our demands.' Thus we debase\n",
      "The nature of our seats and make the rabble\n",
      "Call our cares fears; which will in time\n",
      "Break ope the locks o' the senate and bring in\n",
      "The crows to peck the eagles.\n",
      "\n",
      "MENENIUS:\n",
      "Come, enough.\n",
      "\n",
      "BRUTUS:\n",
      "Enough, with over-measure.\n",
      "\n",
      "CORIOLANUS:\n",
      "No, take more:\n",
      "What may be sworn by, both divine and human,\n",
      "Seal what I end withal! This double worship,\n",
      "Where one part does disdain with cause, the other\n",
      "Insult without all reason, where gentry, title, wisdom,\n",
      "Cannot conclude but by the yea and no\n",
      "Of general ignorance,--it must omit\n",
      "Real necessities, and give way the while\n",
      "To unstable slightness: purpose so barr'd,\n",
      "it follows,\n",
      "Nothing is done to purpose. Therefore, beseech you,--\n",
      "You that will be less fearful than discreet,\n",
      "That love the fundamental part of state\n",
      "More than you doubt the change on't, that prefer\n",
      "A noble life before a long, and wish\n",
      "To jump a body with a dangerous physic\n",
      "That's sure of death without it, at once pluck out\n",
      "The multitudinous tongue; let them not lick\n",
      "The sweet which is their poison: your dishonour\n",
      "Mangles true judgment and bereaves the state\n",
      "Of that integrity which should become't,\n",
      "Not having the power to do the good it would,\n",
      "For the in which doth control't.\n",
      "\n",
      "BRUTUS:\n",
      "Has said enough.\n",
      "\n",
      "SICINIUS:\n",
      "Has spoken like a traitor, and shall answer\n",
      "As traitors do.\n",
      "\n",
      "CORIOLANUS:\n",
      "Thou wretch, despite o'erwhelm thee!\n",
      "What should the people do with these bald tribunes?\n",
      "On whom depending, their obedience fails\n",
      "To the greater bench: in a rebellion,\n",
      "When what's not meet, but what must be, was law,\n",
      "Then were they chosen: in a better hour,\n",
      "Let what is meet be said it must be meet,\n",
      "And throw their power i' the dust.\n",
      "\n",
      "BRUTUS:\n",
      "Manifest treason!\n",
      "\n",
      "SICINIUS:\n",
      "This a consul? no.\n",
      "\n",
      "BRUTUS:\n",
      "The aediles, ho!\n",
      "Let him be apprehended.\n",
      "\n",
      "SICINIUS:\n",
      "Go, call the people:\n",
      "in whose name myself\n",
      "Attach thee as a traitorous innovator,\n",
      "A foe to the public weal: obey, I charge thee,\n",
      "And follow to thine answer.\n",
      "\n",
      "CORIOLANUS:\n",
      "Hence, old goat!\n",
      "\n",
      "Senators, &C:\n",
      "We'll surety him.\n",
      "\n",
      "COMINIUS:\n",
      "Aged sir, hands off.\n",
      "\n",
      "CORIOLANUS:\n",
      "Hence, rotten thing! or I shall shake thy bones\n",
      "Out of thy garments.\n",
      "\n",
      "SICINIUS:\n",
      "Help, ye citizens!\n",
      "\n",
      "MENENIUS:\n",
      "On both sides more respect.\n",
      "\n",
      "SICINIUS:\n",
      "Here's he that would take from you all your power.\n",
      "\n",
      "BRUTUS:\n",
      "Seize him, AEdiles!\n",
      "\n",
      "Citizens:\n",
      "Down with him! down with him!\n",
      "\n",
      "Senators, &C:\n",
      "Weapons, weapons, weapons!\n",
      "'Tribunes!' 'Patricians!' 'Citizens!' 'What, ho!'\n",
      "'Sicinius!' 'Brutus!' 'Coriolanus!' 'Citizens!'\n",
      "'Peace, peace, peace!' 'Stay, hold, peace!'\n",
      "\n",
      "MENENIUS:\n",
      "What is about to be? I am out of breath;\n",
      "Confusion's near; I cannot speak. You, tribunes\n",
      "To the people! Coriolanus, patience!\n",
      "Speak, good Sicinius.\n",
      "\n",
      "SICINIUS:\n",
      "Hear me, people; peace!\n",
      "\n",
      "Citizens:\n",
      "Let's hear our tribune: peace Speak, speak, speak.\n",
      "\n",
      "SICINIUS:\n",
      "You are at point to lose your liberties:\n",
      "Marcius would have all from you; Marcius,\n",
      "Whom late you have named for consul.\n",
      "\n",
      "MENENIUS:\n",
      "Fie, fie, fie!\n",
      "This is the way to kindle, not to quench.\n",
      "\n",
      "First Senator:\n",
      "To unbuild the city and to lay all flat.\n",
      "\n",
      "SICINIUS:\n",
      "What is the city but the people?\n",
      "\n",
      "Citizens:\n",
      "True,\n",
      "The people are the city.\n",
      "\n",
      "BRUTUS:\n",
      "By the consent of all, we were establish'd\n",
      "The people's magistrates.\n",
      "\n",
      "Citizens:\n",
      "You so remain.\n",
      "\n",
      "MENENIUS:\n",
      "And so are like to do.\n",
      "\n",
      "COMINIUS:\n",
      "That is the way to lay the city flat;\n",
      "To bring the roof to the foundation,\n",
      "And bury all, which yet distinctly ranges,\n",
      "In heaps and piles of ruin.\n",
      "\n",
      "SICINIUS:\n",
      "This deserves death.\n",
      "\n",
      "BRUTUS:\n",
      "Or let us stand to our authority,\n",
      "Or let us lose it. We do here pronounce,\n",
      "Upon the part o' the people, in whose power\n",
      "We were elected theirs, Marcius is worthy\n",
      "Of present death.\n",
      "\n",
      "SICINIUS:\n",
      "Therefore lay hold of him;\n",
      "Bear him to the rock Tarpeian, and from thence\n",
      "Into destruction cast him.\n",
      "\n",
      "BRUTUS:\n",
      "AEdiles, seize him!\n",
      "\n",
      "Citizens:\n",
      "Yield, Marcius, yield!\n",
      "\n",
      "MENENIUS:\n",
      "Hear me one word;\n",
      "Beseech you, tribunes, hear me but a word.\n",
      "\n",
      "AEdile:\n",
      "Peace, peace!\n",
      "\n",
      "MENENIUS:\n",
      "\n",
      "BRUTUS:\n",
      "Sir, those cold ways,\n",
      "That seem like prudent helps, are very poisonous\n",
      "Where the disease is violent. Lay hands upon him,\n",
      "And bear him to the rock.\n",
      "\n",
      "CORIOLANUS:\n",
      "No, I'll die here.\n",
      "There's some among you have beheld me fighting:\n",
      "Come, try upon yourselves what you have seen me.\n",
      "\n",
      "MENENIUS:\n",
      "Down with that sword! Tribunes, withdraw awhile.\n",
      "\n",
      "BRUTUS:\n",
      "Lay hands upon him.\n",
      "\n",
      "COMINIUS:\n",
      "Help Marcius, help,\n",
      "You that be noble; help him, young and old!\n",
      "\n",
      "Citizens:\n",
      "Down with him, down with him!\n",
      "\n",
      "MENENIUS:\n",
      "Go, get you to your house; be gone, away!\n",
      "All will be naught else.\n",
      "\n",
      "Second Senator:\n",
      "Get you gone.\n",
      "\n",
      "COMINIUS:\n",
      "Stand fast;\n",
      "We have as many friends as enemies.\n",
      "\n",
      "MENENIUS:\n",
      "Sham it be put to that?\n",
      "\n",
      "First Senator:\n",
      "The gods forbid!\n",
      "I prithee, noble friend, home to thy house;\n",
      "Leave us to cure this cause.\n",
      "\n",
      "MENENIUS:\n",
      "For 'tis a sore upon us,\n",
      "You cannot tent yourself: be gone, beseech you.\n",
      "\n",
      "COMINIUS:\n",
      "Come, sir, along with us.\n",
      "\n",
      "CORIOLANUS:\n",
      "I would they were barbarians--as they are,\n",
      "Though in Rome litter'd--not Romans--as they are not,\n",
      "Though calved i' the porch o' the Capitol--\n",
      "\n",
      "MENENIUS:\n",
      "Be gone;\n",
      "Put not your worthy rage into your tongue;\n",
      "One time will owe another.\n",
      "\n",
      "CORIOLANUS:\n",
      "On fair ground\n",
      "I could beat forty of them.\n",
      "\n",
      "COMINIUS:\n",
      "I could myself\n",
      "Take up a brace o' the best of them; yea, the\n",
      "two tribunes:\n",
      "But now 'tis odds beyond arithmetic;\n",
      "And manhood is call'd foolery, when it stands\n",
      "Against a falling fabric. Will you hence,\n",
      "Before the tag return? whose rage doth rend\n",
      "Like interrupted waters and o'erbear\n",
      "What they are used to bear.\n",
      "\n",
      "MENENIUS:\n",
      "Pray you, be gone:\n",
      "I'll try whether my old wit be in request\n",
      "With those that have but little: this must be patch'd\n",
      "With cloth of any colour.\n",
      "\n",
      "COMINIUS:\n",
      "Nay, come away.\n",
      "\n",
      "A Patrician:\n",
      "This man has marr'd his fortune.\n",
      "\n",
      "MENENIUS:\n",
      "His nature is too noble for the world:\n",
      "He would not flatter Neptune for his trident,\n",
      "Or Jove for's power to thunder. His heart's his mouth:\n",
      "What his breast forges, that his tongue must vent;\n",
      "And, being angry, does forget that ever\n",
      "He heard the name of death.\n",
      "Here's goodly work!\n",
      "\n",
      "Second Patrician:\n",
      "I would they were abed!\n",
      "\n",
      "MENENIUS:\n",
      "I would they were in Tiber! What the vengeance!\n",
      "Could he not speak 'em fair?\n",
      "\n",
      "SICINIUS:\n",
      "Where is this viper\n",
      "That would depopulate the city and\n",
      "Be every man himself?\n",
      "\n",
      "MENENIUS:\n",
      "You worthy tribunes,--\n",
      "\n",
      "SICINIUS:\n",
      "He shall be thrown down the Tarpeian rock\n",
      "With rigorous hands: he hath resisted law,\n",
      "And therefore law shall scorn him further trial\n",
      "Than the severity of the public power\n",
      "Which he so sets at nought.\n",
      "\n",
      "First Citizen:\n",
      "He shall well know\n",
      "The noble tribunes are the people's mouths,\n",
      "And we their hands.\n",
      "\n",
      "Citizens:\n",
      "He shall, sure on't.\n",
      "\n",
      "MENENIUS:\n",
      "Sir, sir,--\n",
      "\n",
      "SICINIUS:\n",
      "Peace!\n",
      "\n",
      "MENENIUS:\n",
      "Do not cry havoc, where you should but hunt\n",
      "With modest warrant.\n",
      "\n",
      "SICINIUS:\n",
      "Sir, how comes't that you\n",
      "Have holp to make this rescue?\n",
      "\n",
      "MENENIUS:\n",
      "Hear me speak:\n",
      "As I do know the consul's worthiness,\n",
      "So can I name his faults,--\n",
      "\n",
      "SICINIUS:\n",
      "Consul! what consul?\n",
      "\n",
      "MENENIUS:\n",
      "The consul Coriolanus.\n",
      "\n",
      "BRUTUS:\n",
      "He consul!\n",
      "\n",
      "Citizens:\n",
      "No, no, no, no, no.\n",
      "\n",
      "MENENIUS:\n",
      "If, by the tribunes' leave, and yours, good people,\n",
      "I may be heard, I would crave a word or two;\n",
      "The which shall turn you to no further harm\n",
      "Than so much loss of time.\n",
      "\n",
      "SICINIUS:\n",
      "Speak briefly then;\n",
      "For we are peremptory to dispatch\n",
      "This viperous traitor: to eject him hence\n",
      "Were but one danger, and to keep him here\n",
      "Our certain death: therefore it is decreed\n",
      "He dies to-night.\n",
      "\n",
      "MENENIUS:\n",
      "Now the good gods forbid\n",
      "That our renowned Rome, whose gratitude\n",
      "Towards her deserved children is enroll'd\n",
      "In Jove's own book, like an unnatural dam\n",
      "Should now eat up her own!\n",
      "\n",
      "SICINIUS:\n",
      "He's a disease that must be cut away.\n",
      "\n",
      "MENENIUS:\n",
      "O, he's a limb that has but a disease;\n",
      "Mortal, to cut it off; to cure it, easy.\n",
      "What has he done to Rome that's worthy death?\n",
      "Killing our enemies, the blood he hath lost--\n",
      "Which, I dare vouch, is more than that he hath,\n",
      "By many an ounce--he dropp'd it for his country;\n",
      "And what is left, to lose it by his country,\n",
      "Were to us all, that do't and suffer it,\n",
      "A brand to the end o' the world.\n",
      "\n",
      "SICINIUS:\n",
      "This is clean kam.\n",
      "\n",
      "BRUTUS:\n",
      "Merely awry: when he did love his country,\n",
      "It honour'd him.\n",
      "\n",
      "MENENIUS:\n",
      "The service of the foot\n",
      "Being once gangrened, is not then respected\n",
      "For what before it was.\n",
      "\n",
      "BRUTUS:\n",
      "We'll hear no more.\n",
      "Pursue him to his house, and pluck him thence:\n",
      "Lest his infection, being of catching nature,\n",
      "Spread further.\n",
      "\n",
      "MENENIUS:\n",
      "One word more, one word.\n",
      "This tiger-footed rage, when it shall find\n",
      "The harm of unscann'd swiftness, will too late\n",
      "Tie leaden pounds to's heels. Proceed by process;\n",
      "Lest parties, as he is beloved, break out,\n",
      "And sack great Rome with Romans.\n",
      "\n",
      "BRUTUS:\n",
      "If it were so,--\n",
      "\n",
      "SICINIUS:\n",
      "What do ye talk?\n",
      "Have we not had a taste of his obedience?\n",
      "Our aediles smote? ourselves resisted? Come.\n",
      "\n",
      "MENENIUS:\n",
      "Consider this: he has been bred i' the wars\n",
      "Since he could draw a sword, and is ill school'd\n",
      "In bolted language; meal and bran together\n",
      "He throws without distinction. Give me leave,\n",
      "I'll go to him, and undertake to bring him\n",
      "Where he shall answer, by a lawful form,\n",
      "In peace, to his utmost peril.\n",
      "\n",
      "First Senator:\n",
      "Noble tribunes,\n",
      "It is the humane way: the other course\n",
      "Will prove too bloody, and the end of it\n",
      "Unknown to the beginning.\n",
      "\n",
      "SICINIUS:\n",
      "Noble Menenius,\n",
      "Be you then as the people's officer.\n",
      "Masters, lay down your weapons.\n",
      "\n",
      "BRUTUS:\n",
      "Go not home.\n",
      "\n",
      "SICINIUS:\n",
      "Meet on the market-place. We'll attend you there:\n",
      "Where, if you bring not Marcius, we'll proceed\n",
      "In our first way.\n",
      "\n",
      "MENENIUS:\n",
      "I'll bring him to you.\n",
      "Let me desire your company: he must come,\n",
      "Or what is worst will follow.\n",
      "\n",
      "First Senator:\n",
      "Pray you, let's to him.\n",
      "\n",
      "CORIOLANUS:\n",
      "Let them puff all about mine ears, present me\n",
      "Death on the wheel or at wild horses' heels,\n",
      "Or pile ten hills on the Tarpeian rock,\n",
      "That the precipitation might down stretch\n",
      "Below the beam of sight, yet will I still\n",
      "Be thus to them.\n",
      "\n",
      "A Patrician:\n",
      "You do the nobler.\n",
      "\n",
      "CORIOLANUS:\n",
      "I muse my mother\n",
      "Does not approve me further, who was wont\n",
      "To call them woollen vassals, things created\n",
      "To buy and sell with groats, to show bare heads\n",
      "In congregations, to yawn, be still and wonder,\n",
      "When one but of my ordinance stood up\n",
      "To speak of peace or war.\n",
      "I talk of you:\n",
      "Why did you wish me milder? would you have me\n",
      "False to my nature? Rather say I play\n",
      "The man I am.\n",
      "\n",
      "VOLUMNIA:\n",
      "O, sir, sir, sir,\n",
      "I would have had you put your power well on,\n",
      "Before you had worn it out.\n",
      "\n",
      "CORIOLANUS:\n",
      "Let go.\n",
      "\n",
      "VOLUMNIA:\n",
      "You might have been enough the man you are,\n",
      "With striving less to be so; lesser had been\n",
      "The thwartings of your dispositions, if\n",
      "You had not show'd them how ye were disposed\n",
      "Ere they lack'd power to cross you.\n",
      "\n",
      "CORIOLANUS:\n",
      "Let them hang.\n",
      "\n",
      "A Patrician:\n",
      "Ay, and burn too.\n",
      "\n",
      "MENENIUS:\n",
      "Come, come, you have been too rough, something\n",
      "too rough;\n",
      "You must return and mend it.\n",
      "\n",
      "First Senator:\n",
      "There's no remedy;\n",
      "Unless, by not so doing, our good city\n",
      "Cleave in the midst, and perish.\n",
      "\n",
      "VOLUMNIA:\n",
      "Pray, be counsell'd:\n",
      "I have a heart as little apt as yours,\n",
      "But yet a brain that leads my use of anger\n",
      "To better vantage.\n",
      "\n",
      "MENENIUS:\n",
      "Well said, noble woman?\n",
      "Before he should thus stoop to the herd, but that\n",
      "The violent fit o' the time craves it as physic\n",
      "For the whole state, I would put mine armour on,\n",
      "Which I can scarcely bear.\n",
      "\n",
      "CORIOLANUS:\n",
      "What must I do?\n",
      "\n",
      "MENENIUS:\n",
      "Return to the tribunes.\n",
      "\n",
      "CORIOLANUS:\n",
      "Well, what then? what then?\n",
      "\n",
      "MENENIUS:\n",
      "Repent what you have spoke.\n",
      "\n",
      "CORIOLANUS:\n",
      "For them! I cannot do it to the gods;\n",
      "Must I then do't to them?\n",
      "\n",
      "VOLUMNIA:\n",
      "You are too absolute;\n",
      "Though therein you can never be too noble,\n",
      "But when extremities speak. I have heard you say,\n",
      "Honour and policy, like unsever'd friends,\n",
      "I' the war do grow together: grant that, and tell me,\n",
      "In peace what each of them by the other lose,\n",
      "That they combine not there.\n",
      "\n",
      "CORIOLANUS:\n",
      "Tush, tush!\n",
      "\n",
      "MENENIUS:\n",
      "A good demand.\n",
      "\n",
      "VOLUMNIA:\n",
      "If it be honour in your wars to seem\n",
      "The same you are not, which, for your best ends,\n",
      "You adopt your policy, how is it less or worse,\n",
      "That it shall hold companionship in peace\n",
      "With honour, as in war, since that to both\n",
      "It stands in like request?\n",
      "\n",
      "CORIOLANUS:\n",
      "Why force you this?\n",
      "\n",
      "VOLUMNIA:\n",
      "Because that now it lies you on to speak\n",
      "To the people; not by your own instruction,\n",
      "Nor by the matter which your heart prompts you,\n",
      "But with such words that are but rooted in\n",
      "Your tongue, though but bastards and syllables\n",
      "Of no allowance to your bosom's truth.\n",
      "Now, this no more dishonours you at all\n",
      "Than to take in a town with gentle words,\n",
      "Which else would put you to your fortune and\n",
      "The hazard of much blood.\n",
      "I would dissemble with my nature where\n",
      "My fortunes and my friends at stake required\n",
      "I should do so in honour: I am in this,\n",
      "Your wife, your son, these senators, the nobles;\n",
      "And you will rather show our general louts\n",
      "How you can frown than spend a fawn upon 'em,\n",
      "For the inheritance of their loves and safeguard\n",
      "Of what that want might ruin.\n",
      "\n",
      "MENENIUS:\n",
      "Noble lady!\n",
      "Come, go with us; speak fair: you may salve so,\n",
      "Not what is dangerous present, but the loss\n",
      "Of what is past.\n",
      "\n",
      "VOLUMNIA:\n",
      "I prithee now, my son,\n",
      "Go to them, with this bonnet in thy hand;\n",
      "And thus far having stretch'd it--here be with them--\n",
      "Thy knee bussing the stones--for in such business\n",
      "Action is eloquence, and the eyes of the ignorant\n",
      "More learned than the ears--waving thy head,\n",
      "Which often, thus, correcting thy stout heart,\n",
      "Now humble as the ripest mulberry\n",
      "That will not hold the handling: or say to them,\n",
      "Thou art their soldier, and being bred in broils\n",
      "Hast not the soft way which, thou dost confess,\n",
      "Were fit for thee to use as they to claim,\n",
      "In asking their good loves, but thou wilt frame\n",
      "Thyself, forsooth, hereafter theirs, so far\n",
      "As thou hast power and person.\n",
      "\n",
      "MENENIUS:\n",
      "This but done,\n",
      "Even as she speaks, why, their hearts were yours;\n",
      "For they have pardons, being ask'd, as free\n",
      "As words to little purpose.\n",
      "\n",
      "VOLUMNIA:\n",
      "Prithee now,\n",
      "Go, and be ruled: although I know thou hadst rather\n",
      "Follow thine enemy in a fiery gulf\n",
      "Than flatter him in a bower. Here is Cominius.\n",
      "\n",
      "COMINIUS:\n",
      "I have been i' the market-place; and, sir,'tis fit\n",
      "You make strong party, or defend yourself\n",
      "By calmness or by absence: all's in anger.\n",
      "\n",
      "MENENIUS:\n",
      "Only fair speech.\n",
      "\n",
      "COMINIUS:\n",
      "I think 'twill serve, if he\n",
      "Can thereto frame his spirit.\n",
      "\n",
      "VOLUMNIA:\n",
      "He must, and will\n",
      "Prithee now, say you will, and go about it.\n",
      "\n",
      "CORIOLANUS:\n",
      "Must I go show them my unbarbed sconce?\n",
      "Must I with base tongue give my noble heart\n",
      "A lie that it must bear? Well, I will do't:\n",
      "Yet, were there but this single plot to lose,\n",
      "This mould of Marcius, they to dust should grind it\n",
      "And throw't against the wind. To the market-place!\n",
      "You have put me now to such a part which never\n",
      "I shall discharge to the life.\n",
      "\n",
      "COMINIUS:\n",
      "Come, come, we'll prompt you.\n",
      "\n",
      "VOLUMNIA:\n",
      "I prithee now, sweet son, as thou hast said\n",
      "My praises made thee first a soldier, so,\n",
      "To have my praise for this, perform a part\n",
      "Thou hast not done before.\n",
      "\n",
      "CORIOLANUS:\n",
      "Well, I must do't:\n",
      "Away, my disposition, and possess me\n",
      "Some harlot's spirit! my throat of war be turn'd,\n",
      "Which quired with my drum, into a pipe\n",
      "Small as an eunuch, or the virgin voice\n",
      "That babies lulls asleep! the smiles of knaves\n",
      "Tent in my cheeks, and schoolboys' tears take up\n",
      "The glasses of my sight! a beggar's tongue\n",
      "Make motion through my lips, and my arm'd knees,\n",
      "Who bow'd but in my stirrup, bend like his\n",
      "That hath received an alms! I will not do't,\n",
      "Lest I surcease to honour mine own truth\n",
      "And by my body's action teach my mind\n",
      "A most inherent baseness.\n",
      "\n",
      "VOLUMNIA:\n",
      "At thy choice, then:\n",
      "To beg of thee, it is my more dishonour\n",
      "Than thou of them. Come all to ruin; let\n",
      "Thy mother rather feel thy pride than fear\n",
      "Thy dangerous stoutness, for I mock at death\n",
      "With as big heart as thou. Do as thou list\n",
      "Thy valiantness was mine, thou suck'dst it from me,\n",
      "But owe thy pride thyself.\n",
      "\n",
      "CORIOLANUS:\n",
      "Pray, be content:\n",
      "Mother, I am going to the market-place;\n",
      "Chide me no more. I'll mountebank their loves,\n",
      "Cog their hearts from them, and come home beloved\n",
      "Of all the trades in Rome. Look, I am going:\n",
      "Commend me to my wife. I'll return consul;\n",
      "Or never trust to what my tongue can do\n",
      "I' the way of flattery further.\n",
      "\n",
      "VOLUMNIA:\n",
      "Do your will.\n",
      "\n",
      "COMINIUS:\n",
      "Away! the tribunes do attend you: arm yourself\n",
      "To answer mildly; for they are prepared\n",
      "With accusations, as I hear, more strong\n",
      "Than are upon you yet.\n",
      "\n",
      "CORIOLANUS:\n",
      "The word is 'mildly.' Pray you, let us go:\n",
      "Let them accuse me by invention, I\n",
      "Will answer in mine honour.\n",
      "\n",
      "MENENIUS:\n",
      "Ay, but mildly.\n",
      "\n",
      "CORIOLANUS:\n",
      "Well, mildly be it then. Mildly!\n",
      "\n",
      "BRUTUS:\n",
      "In this point charge him home, that he affects\n",
      "Tyrannical power: if he evade us there,\n",
      "Enforce him with his envy to the people,\n",
      "And that the spoil got on the Antiates\n",
      "Was ne'er distributed.\n",
      "What, will he come?\n",
      "\n",
      "AEdile:\n",
      "He's coming.\n",
      "\n",
      "BRUTUS:\n",
      "How accompanied?\n",
      "\n",
      "AEdile:\n",
      "With old Menenius, and those senators\n",
      "That always favour'd him.\n",
      "\n",
      "SICINIUS:\n",
      "Have you a catalogue\n",
      "Of all the voices that we have procured\n",
      "Set down by the poll?\n",
      "\n",
      "AEdile:\n",
      "I have; 'tis ready.\n",
      "\n",
      "SICINIUS:\n",
      "Have you collected them by tribes?\n",
      "\n",
      "AEdile:\n",
      "I have.\n",
      "\n",
      "SICINIUS:\n",
      "Assemble presently the people hither;\n",
      "And when they bear me say 'It shall be so\n",
      "I' the right and strength o' the commons,' be it either\n",
      "For death, for fine, or banishment, then let them\n",
      "If I say fine, cry 'Fine;' if death, cry 'Death.'\n",
      "Insisting on the old prerogative\n",
      "And power i' the truth o' the cause.\n",
      "\n",
      "AEdile:\n",
      "I shall inform them.\n",
      "\n",
      "BRUTUS:\n",
      "And when such time they have begun to cry,\n",
      "Let them not cease, but with a din confused\n",
      "Enforce the present execution\n",
      "Of what we chance to sentence.\n",
      "\n",
      "AEdile:\n",
      "Very well.\n",
      "\n",
      "SICINIUS:\n",
      "Make them be strong and ready for this hint,\n",
      "When we shall hap to give 't them.\n",
      "\n",
      "BRUTUS:\n",
      "Go about it.\n",
      "Put him to choler straight: he hath been used\n",
      "Ever to conquer, and to have his worth\n",
      "Of contradiction: being once chafed, he cannot\n",
      "Be rein'd again to temperance; then he speaks\n",
      "What's in his heart; and that is there which looks\n",
      "With us to break his neck.\n",
      "\n",
      "SICINIUS:\n",
      "Well, here he comes.\n",
      "\n",
      "MENENIUS:\n",
      "Calmly, I do beseech you.\n",
      "\n",
      "CORIOLANUS:\n",
      "Ay, as an ostler, that for the poorest piece\n",
      "Will bear the knave by the volume. The honour'd gods\n",
      "Keep Rome in safety, and the chairs of justice\n",
      "Supplied with worthy men! plant love among 's!\n",
      "Throng our large temples with the shows of peace,\n",
      "And not our streets with war!\n",
      "\n",
      "First Senator:\n",
      "Amen, amen.\n",
      "\n",
      "MENENIUS:\n",
      "A noble wish.\n",
      "\n",
      "SICINIUS:\n",
      "Draw near, ye people.\n",
      "\n",
      "AEdile:\n",
      "List to your tribunes. Audience: peace, I say!\n",
      "\n",
      "CORIOLANUS:\n",
      "First, hear me speak.\n",
      "\n",
      "Both Tribunes:\n",
      "Well, say. Peace, ho!\n",
      "\n",
      "CORIOLANUS:\n",
      "Shall I be charged no further than this present?\n",
      "Must all determine here?\n",
      "\n",
      "SICINIUS:\n",
      "I do demand,\n",
      "If you submit you to the people's voices,\n",
      "Allow their officers and are content\n",
      "To suffer lawful censure for such faults\n",
      "As shall be proved upon you?\n",
      "\n",
      "CORIOLANUS:\n",
      "I am content.\n",
      "\n",
      "MENENIUS:\n",
      "Lo, citizens, he says he is content:\n",
      "The warlike service he has done, consider; think\n",
      "Upon the wounds his body bears, which show\n",
      "Like graves i' the holy churchyard.\n",
      "\n",
      "CORIOLANUS:\n",
      "Scratches with briers,\n",
      "Scars to move laughter only.\n",
      "\n",
      "MENENIUS:\n",
      "Consider further,\n",
      "That when he speaks not like a citizen,\n",
      "You find him like a soldier: do not take\n",
      "His rougher accents for malicious sounds,\n",
      "But, as I say, such as become a soldier,\n",
      "Rather than envy you.\n",
      "\n",
      "COMINIUS:\n",
      "Well, well, no more.\n",
      "\n",
      "CORIOLANUS:\n",
      "What is the matter\n",
      "That being pass'd for consul with full voice,\n",
      "I am so dishonour'd that the very hour\n",
      "You take it off again?\n",
      "\n",
      "SICINIUS:\n",
      "Answer to us.\n",
      "\n",
      "CORIOLANUS:\n",
      "Say, then: 'tis true, I ought so.\n",
      "\n",
      "SICINIUS:\n",
      "We charge you, that you have contrived to take\n",
      "From Rome all season'd office and to wind\n",
      "Yourself into a power tyrannical;\n",
      "For which you are a traitor to the people.\n",
      "\n",
      "CORIOLANUS:\n",
      "How! traitor!\n",
      "\n",
      "MENENIUS:\n",
      "Nay, temperately; your promise.\n",
      "\n",
      "CORIOLANUS:\n",
      "The fires i' the lowest hell fold-in the people!\n",
      "Call me their traitor! Thou injurious tribune!\n",
      "Within thine eyes sat twenty thousand deaths,\n",
      "In thy hand clutch'd as many millions, in\n",
      "Thy lying tongue both numbers, I would say\n",
      "'Thou liest' unto thee with a voice as free\n",
      "As I do pray the gods.\n",
      "\n",
      "SICINIUS:\n",
      "Mark you this, people?\n",
      "\n",
      "Citizens:\n",
      "To the rock, to the rock with him!\n",
      "\n",
      "SICINIUS:\n",
      "Peace!\n",
      "We need not put new matter to his charge:\n",
      "What you have seen him do and heard him speak,\n",
      "Beating your officers, cursing yourselves,\n",
      "Opposing laws with strokes and here defying\n",
      "Those whose great power must try him; even this,\n",
      "So criminal and in such capital kind,\n",
      "Deserves the extremest death.\n",
      "\n",
      "BRUTUS:\n",
      "But since he hath\n",
      "Served well for Rome,--\n",
      "\n",
      "CORIOLANUS:\n",
      "What do you prate of service?\n",
      "\n",
      "BRUTUS:\n",
      "I talk of that, that know it.\n",
      "\n",
      "CORIOLANUS:\n",
      "You?\n",
      "\n",
      "MENENIUS:\n",
      "Is this the promise that you made your mother?\n",
      "\n",
      "COMINIUS:\n",
      "Know, I pray you,--\n",
      "\n",
      "CORIOLANUS:\n",
      "I know no further:\n",
      "Let them pronounce the steep Tarpeian death,\n",
      "Vagabond exile, raying, pent to linger\n",
      "But with a grain a day, I would not buy\n",
      "Their mercy at the price of one fair word;\n",
      "Nor cheque my courage for what they can give,\n",
      "To have't with saying 'Good morrow.'\n",
      "\n",
      "SICINIUS:\n",
      "For that he has,\n",
      "As much as in him lies, from time to time\n",
      "Envied against the people, seeking means\n",
      "To pluck away their power, as now at last\n",
      "Given hostile strokes, and that not in the presence\n",
      "Of dreaded justice, but on the ministers\n",
      "That do distribute it; in the name o' the people\n",
      "And in the power of us the tribunes, we,\n",
      "Even from this instant, banish him our city,\n",
      "In peril of precipitation\n",
      "From off the rock Tarpeian never more\n",
      "To enter our Rome gates: i' the people's name,\n",
      "I say it shall be so.\n",
      "\n",
      "Citizens:\n",
      "It shall be so, it shall be so; let him away:\n",
      "He's banish'd, and it shall be so.\n",
      "\n",
      "COMINIUS:\n",
      "Hear me, my masters, and my common friends,--\n",
      "\n",
      "SICINIUS:\n",
      "He's sentenced; no more hearing.\n",
      "\n",
      "COMINIUS:\n",
      "Let me speak:\n",
      "I have been consul, and can show for Rome\n",
      "Her enemies' marks upon me. I do love\n",
      "My country's good with a respect more tender,\n",
      "More holy and profound, than mine own life,\n",
      "My dear wife's estimate, her womb's increase,\n",
      "And treasure of my loins; then if I would\n",
      "Speak that,--\n",
      "\n",
      "SICINIUS:\n",
      "We know your drift: speak what?\n",
      "\n",
      "BRUTUS:\n",
      "There's no more to be said, but he is banish'd,\n",
      "As enemy to the people and his country:\n",
      "It shall be so.\n",
      "\n",
      "Citizens:\n",
      "It shall be so, it shall be so.\n",
      "\n",
      "CORIOLANUS:\n",
      "You common cry of curs! whose breath I hate\n",
      "As reek o' the rotten fens, whose loves I prize\n",
      "As the dead carcasses of unburied men\n",
      "That do corrupt my air, I banish you;\n",
      "And here remain with your uncertainty!\n",
      "Let every feeble rumour shake your hearts!\n",
      "Your enemies, with nodding of their plumes,\n",
      "Fan you into despair! Have the power still\n",
      "To banish your defenders; till at length\n",
      "Your ignorance, which finds not till it feels,\n",
      "Making not reservation of yourselves,\n",
      "Still your own foes, deliver you as most\n",
      "Abated captives to some nation\n",
      "That won you without blows! Despising,\n",
      "For you, the city, thus I turn my back:\n",
      "There is a world elsewhere.\n",
      "\n",
      "AEdile:\n",
      "The people's enemy is gone, is gone!\n",
      "\n",
      "Citizens:\n",
      "Our enemy is banish'd! he is gone! Hoo! hoo!\n",
      "\n",
      "SICINIUS:\n",
      "Go, see him out at gates, and follow him,\n",
      "As he hath followed you, with all despite;\n",
      "Give him deserved vexation. Let a guard\n",
      "Attend us through the city.\n",
      "\n",
      "Citizens:\n",
      "Come, come; let's see him out at gates; come.\n",
      "The gods preserve our noble tribunes! Come.\n",
      "\n",
      "CORIOLANUS:\n",
      "Come, leave your tears: a brief farewell: the beast\n",
      "With many heads butts me away. Nay, mother,\n",
      "Where is your ancient courage? you were used\n",
      "To say extremity was the trier of spirits;\n",
      "That common chances common men could bear;\n",
      "That when the sea was calm all boats alike\n",
      "Show'd mastership in floating; fortune's blows,\n",
      "When most struck home, being gentle wounded, craves\n",
      "A noble cunning: you were used to load me\n",
      "With precepts that would make invincible\n",
      "The heart that conn'd them.\n",
      "\n",
      "VIRGILIA:\n",
      "O heavens! O heavens!\n",
      "\n",
      "CORIOLANUS:\n",
      "Nay! prithee, woman,--\n",
      "\n",
      "VOLUMNIA:\n",
      "Now the red pestilence strike all trades in Rome,\n",
      "And occupations perish!\n",
      "\n",
      "CORIOLANUS:\n",
      "What, what, what!\n",
      "I shall be loved when I am lack'd. Nay, mother.\n",
      "Resume that spirit, when you were wont to say,\n",
      "If you had been the wife of Hercules,\n",
      "Six of his labours you'ld have done, and saved\n",
      "Your husband so much sweat. Cominius,\n",
      "Droop not; adieu. Farewell, my wife, my mother:\n",
      "I'll do well yet. Thou old and true Menenius,\n",
      "Thy tears are salter than a younger man's,\n",
      "And venomous to thine eyes. My sometime general,\n",
      "I have seen thee stem, and thou hast oft beheld\n",
      "Heart-hardening spectacles; tell these sad women\n",
      "'Tis fond to wail inevitable strokes,\n",
      "As 'tis to laugh at 'em. My mother, you wot well\n",
      "My hazards still have been your solace: and\n",
      "Believe't not lightly--though I go alone,\n",
      "Like to a lonely dragon, that his fen\n",
      "Makes fear'd and talk'd of more than seen--your son\n",
      "Will or exceed the common or be caught\n",
      "With cautelous baits and practise.\n",
      "\n",
      "VOLUMNIA:\n",
      "My first son.\n",
      "Whither wilt thou go? Take good Cominius\n",
      "With thee awhile: determine on some course,\n",
      "More than a wild exposture to each chance\n",
      "That starts i' the way before thee.\n",
      "\n",
      "CORIOLANUS:\n",
      "O the gods!\n",
      "\n",
      "COMINIUS:\n",
      "I'll follow thee a month, devise with thee\n",
      "Where thou shalt rest, that thou mayst hear of us\n",
      "And we of thee: so if the time thrust forth\n",
      "A cause for thy repeal, we shall not send\n",
      "O'er the vast world to seek a single man,\n",
      "And lose advantage, which doth ever cool\n",
      "I' the absence of the needer.\n",
      "\n",
      "CORIOLANUS:\n",
      "Fare ye well:\n",
      "Thou hast years upon thee; and thou art too full\n",
      "Of the wars' surfeits, to go rove with one\n",
      "That's yet unbruised: bring me but out at gate.\n",
      "Come, my sweet wife, my dearest mother, and\n",
      "My friends of noble touch, when I am forth,\n",
      "Bid me farewell, and smile. I pray you, come.\n",
      "While I remain above the ground, you shall\n",
      "Hear from me still, and never of me aught\n",
      "But what is like me formerly.\n",
      "\n",
      "MENENIUS:\n",
      "That's worthily\n",
      "As any ear can hear. Come, let's not weep.\n",
      "If I could shake off but one seven years\n",
      "From these old arms and legs, by the good gods,\n",
      "I'ld with thee every foot.\n",
      "\n",
      "CORIOLANUS:\n",
      "Give me thy hand: Come.\n",
      "\n",
      "SICINIUS:\n",
      "Bid them all home; he's gone, and we'll no further.\n",
      "The nobility are vex'd, whom we see have sided\n",
      "In his behalf.\n",
      "\n",
      "BRUTUS:\n",
      "Now we have shown our power,\n",
      "Let us seem humbler after it is done\n",
      "Than when it was a-doing.\n",
      "\n",
      "SICINIUS:\n",
      "Bid them home:\n",
      "Say their great enemy is gone, and they\n",
      "Stand in their ancient strength.\n",
      "\n",
      "BRUTUS:\n",
      "Dismiss them home.\n",
      "Here comes his mother.\n",
      "\n",
      "SICINIUS:\n",
      "Let's not meet her.\n",
      "\n",
      "BRUTUS:\n",
      "Why?\n",
      "\n",
      "SICINIUS:\n",
      "They say she's mad.\n",
      "\n",
      "BRUTUS:\n",
      "They have ta'en note of us: keep on your way.\n",
      "\n",
      "VOLUMNIA:\n",
      "O, ye're well met: the hoarded plague o' the gods\n",
      "Requite your love!\n",
      "\n",
      "MENENIUS:\n",
      "Peace, peace; be not so loud.\n",
      "\n",
      "VOLUMNIA:\n",
      "If that I could for weeping, you should hear,--\n",
      "Nay, and you shall hear some.\n",
      "Will you be gone?\n",
      "\n",
      "VIRGILIA:\n",
      "\n",
      "SICINIUS:\n",
      "Are you mankind?\n",
      "\n",
      "VOLUMNIA:\n",
      "Ay, fool; is that a shame? Note but this fool.\n",
      "Was not a man my father? Hadst thou foxship\n",
      "To banish him that struck more blows for Rome\n",
      "Than thou hast spoken words?\n",
      "\n",
      "SICINIUS:\n",
      "O blessed heavens!\n",
      "\n",
      "VOLUMNIA:\n",
      "More noble blows than ever thou wise words;\n",
      "And for Rome's good. I'll tell thee what; yet go:\n",
      "Nay, but thou shalt stay too: I would my son\n",
      "Were in Arabia, and thy tribe before him,\n",
      "His good sword in his hand.\n",
      "\n",
      "SICINIUS:\n",
      "What then?\n",
      "\n",
      "VIRGILIA:\n",
      "What then!\n",
      "He'ld make an end of thy posterity.\n",
      "\n",
      "VOLUMNIA:\n",
      "Bastards and all.\n",
      "Good man, the wounds that he does bear for Rome!\n",
      "\n",
      "MENENIUS:\n",
      "Come, come, peace.\n",
      "\n",
      "SICINIUS:\n",
      "I would he had continued to his country\n",
      "As he began, and not unknit himself\n",
      "The noble knot he made.\n",
      "\n",
      "BRUTUS:\n",
      "I would he had.\n",
      "\n",
      "VOLUMNIA:\n",
      "'I would he had'! 'Twas you incensed the rabble:\n",
      "Cats, that can judge as fitly of his worth\n",
      "As I can of those mysteries which heaven\n",
      "Will not have earth to know.\n",
      "\n",
      "BRUTUS:\n",
      "Pray, let us go.\n",
      "\n",
      "VOLUMNIA:\n",
      "Now, pray, sir, get you gone:\n",
      "You have done a brave deed. Ere you go, hear this:--\n",
      "As far as doth the Capitol exceed\n",
      "The meanest house in Rome, so far my son--\n",
      "This lady's husband here, this, do you see--\n",
      "Whom you have banish'd, does exceed you all.\n",
      "\n",
      "BRUTUS:\n",
      "Well, well, we'll leave you.\n",
      "\n",
      "SICINIUS:\n",
      "Why stay we to be baited\n",
      "With one that wants her wits?\n",
      "\n",
      "VOLUMNIA:\n",
      "Take my prayers with you.\n",
      "I would the gods had nothing else to do\n",
      "But to confirm my curses! Could I meet 'em\n",
      "But once a-day, it would unclog my heart\n",
      "Of what lies heavy to't.\n",
      "\n",
      "MENENIUS:\n",
      "You have told them home;\n",
      "And, by my troth, you have cause. You'll sup with me?\n",
      "\n",
      "VOLUMNIA:\n",
      "Anger's my meat; I sup upon myself,\n",
      "And so shall starve with feeding. Come, let's go:\n",
      "Leave this faint puling and lament as I do,\n",
      "In anger, Juno-like. Come, come, come.\n",
      "\n",
      "MENENIUS:\n",
      "Fie, fie, fie!\n",
      "\n",
      "Roman:\n",
      "I know you well, sir, and you know\n",
      "me: your name, I think, is Adrian.\n",
      "\n",
      "Volsce:\n",
      "It is so, sir: truly, I have forgot you.\n",
      "\n",
      "Roman:\n",
      "I am a Roman; and my services are,\n",
      "as you are, against 'em: know you me yet?\n",
      "\n",
      "Volsce:\n",
      "Nicanor? no.\n",
      "\n",
      "Roman:\n",
      "The same, sir.\n",
      "\n",
      "Volsce:\n",
      "You had more beard when I last saw you; but your\n",
      "favour is well approved by your tongue. What's the\n",
      "news in Rome? I have a note from the Volscian state,\n",
      "to find you out there: you have well saved me a\n",
      "day's journey.\n",
      "\n",
      "Roman:\n",
      "There hath been in Rome strange insurrections; the\n",
      "people against the senators, patricians, and nobles.\n",
      "\n",
      "Volsce:\n",
      "Hath been! is it ended, then? Our state thinks not\n",
      "so: they are in a most warlike preparation, and\n",
      "hope to come upon them in the heat of their division.\n",
      "\n",
      "Roman:\n",
      "The main blaze of it is past, but a small thing\n",
      "would make it flame again: for the nobles receive\n",
      "so to heart the banishment of that worthy\n",
      "Coriolanus, that they are in a ripe aptness to take\n",
      "all power from the people and to pluck from them\n",
      "their tribunes for ever. This lies glowing, I can\n",
      "tell you, and is almost mature for the violent\n",
      "breaking out.\n",
      "\n",
      "Volsce:\n",
      "Coriolanus banished!\n",
      "\n",
      "Roman:\n",
      "Banished, sir.\n",
      "\n",
      "Volsce:\n",
      "You will be welcome with this intelligence, Nicanor.\n",
      "\n",
      "Roman:\n",
      "The day serves well for them now. I have heard it\n",
      "said, the fittest time to corrupt a man's wife is\n",
      "when she's fallen out with her husband. Your noble\n",
      "Tullus Aufidius will appear well in these wars, his\n",
      "great opposer, Coriolanus, being now in no request\n",
      "of his country.\n",
      "\n",
      "Volsce:\n",
      "He cannot choose. I am most fortunate, thus\n",
      "accidentally to encounter you: you have ended my\n",
      "business, and I will merrily accompany you home.\n",
      "\n",
      "Roman:\n",
      "I shall, between this and supper, tell you most\n",
      "strange things from Rome; all tending to the good of\n",
      "their adversaries. Have you an army ready, say you?\n",
      "\n",
      "Volsce:\n",
      "A most royal one; the centurions and their charges,\n",
      "distinctly billeted, already in the entertainment,\n",
      "and to be on foot at an hour's warning.\n",
      "\n",
      "Roman:\n",
      "I am joyful to hear of their readiness, and am the\n",
      "man, I think, that shall set them in present action.\n",
      "So, sir, heartily well met, and most glad of your company.\n",
      "\n",
      "Volsce:\n",
      "You take my part from me, sir; I have the most cause\n",
      "to be glad of yours.\n",
      "\n",
      "Roman:\n",
      "Well, let us go together.\n",
      "\n",
      "CORIOLANUS:\n",
      "A goodly city is this Antium. City,\n",
      "'Tis I that made thy widows: many an heir\n",
      "Of these fair edifices 'fore my wars\n",
      "Have I heard groan and drop: then know me not,\n",
      "Lest that thy wives with spits and boys with stones\n",
      "In puny battle slay me.\n",
      "Save you, sir.\n",
      "\n",
      "Citizen:\n",
      "And you.\n",
      "\n",
      "CORIOLANUS:\n",
      "Direct me, if it be your will,\n",
      "Where great Aufidius lies: is he in Antium?\n",
      "\n",
      "Citizen:\n",
      "He is, and feasts the nobles of the state\n",
      "At his house this night.\n",
      "\n",
      "CORIOLANUS:\n",
      "Which is his house, beseech you?\n",
      "\n",
      "Citizen:\n",
      "This, here before you.\n",
      "\n",
      "CORIOLANUS:\n",
      "Thank you, sir: farewell.\n",
      "O world, thy slippery turns! Friends now fast sworn,\n",
      "Whose double bosoms seem to wear one heart,\n",
      "Whose house, whose bed, whose meal, and exercise,\n",
      "Are still together, who twin, as 'twere, in love\n",
      "Unseparable, shall within this hour,\n",
      "On a dissension of a doit, break out\n",
      "To bitterest enmity: so, fellest foes,\n",
      "Whose passions and whose plots have broke their sleep,\n",
      "To take the one the other, by some chance,\n",
      "Some trick not worth an egg, shall grow dear friends\n",
      "And interjoin their issues. So with me:\n",
      "My birth-place hate I, and my love's upon\n",
      "This enemy town. I'll enter: if he slay me,\n",
      "He does fair justice; if he give me way,\n",
      "I'll do his country service.\n",
      "\n",
      "First Servingman:\n",
      "Wine, wine, wine! What service\n",
      "is here! I think our fellows are asleep.\n",
      "\n",
      "Second Servingman:\n",
      "Where's Cotus? my master calls\n",
      "for him. Cotus!\n",
      "\n",
      "CORIOLANUS:\n",
      "A goodly house: the feast smells well; but I\n",
      "Appear not like a guest.\n",
      "\n",
      "First Servingman:\n",
      "What would you have, friend? whence are you?\n",
      "Here's no place for you: pray, go to the door.\n",
      "\n",
      "CORIOLANUS:\n",
      "I have deserved no better entertainment,\n",
      "In being Coriolanus.\n",
      "\n",
      "Second Servingman:\n",
      "Whence are you, sir? Has the porter his eyes in his\n",
      "head; that he gives entrance to such companions?\n",
      "Pray, get you out.\n",
      "\n",
      "CORIOLANUS:\n",
      "Away!\n",
      "\n",
      "Second Servingman:\n",
      "Away! get you away.\n",
      "\n",
      "CORIOLANUS:\n",
      "Now thou'rt troublesome.\n",
      "\n",
      "Second Servingman:\n",
      "Are you so brave? I'll have you talked with anon.\n",
      "\n",
      "Third Servingman:\n",
      "What fellow's this?\n",
      "\n",
      "First Servingman:\n",
      "A strange one as ever I looked on: I cannot get him\n",
      "out of the house: prithee, call my master to him.\n",
      "\n",
      "Third Servingman:\n",
      "What have you to do here, fellow? Pray you, avoid\n",
      "the house.\n",
      "\n",
      "CORIOLANUS:\n",
      "Let me but stand; I will not hurt your hearth.\n",
      "\n",
      "Third Servingman:\n",
      "What are you?\n",
      "\n",
      "CORIOLANUS:\n",
      "A gentleman.\n",
      "\n",
      "Third Servingman:\n",
      "A marvellous poor one.\n",
      "\n",
      "CORIOLANUS:\n",
      "True, so I am.\n",
      "\n",
      "Third Servingman:\n",
      "Pray you, poor gentleman, take up some other\n",
      "station; here's no place for you; pray you, avoid: come.\n",
      "\n",
      "CORIOLANUS:\n",
      "Follow your function, go, and batten on cold bits.\n",
      "\n",
      "Third Servingman:\n",
      "What, you will not? Prithee, tell my master what a\n",
      "strange guest he has here.\n",
      "\n",
      "Second Servingman:\n",
      "And I shall.\n",
      "\n",
      "Third Servingman:\n",
      "Where dwellest thou?\n",
      "\n",
      "CORIOLANUS:\n",
      "Under the canopy.\n",
      "\n",
      "Third Servingman:\n",
      "Under the canopy!\n",
      "\n",
      "CORIOLANUS:\n",
      "Ay.\n",
      "\n",
      "Third Servingman:\n",
      "Where's that?\n",
      "\n",
      "CORIOLANUS:\n",
      "I' the city of kites and crows.\n",
      "\n",
      "Third Servingman:\n",
      "I' the city of kites and crows! What an ass it is!\n",
      "Then thou dwellest with daws too?\n",
      "\n",
      "CORIOLANUS:\n",
      "No, I serve not thy master.\n",
      "\n",
      "Third Servingman:\n",
      "How, sir! do you meddle with my master?\n",
      "\n",
      "CORIOLANUS:\n",
      "Ay; 'tis an honester service than to meddle with thy\n",
      "mistress. Thou pratest, and pratest; serve with thy\n",
      "trencher, hence!\n",
      "\n",
      "AUFIDIUS:\n",
      "Where is this fellow?\n",
      "\n",
      "Second Servingman:\n",
      "Here, sir: I'ld have beaten him like a dog, but for\n",
      "disturbing the lords within.\n",
      "\n",
      "AUFIDIUS:\n",
      "Whence comest thou? what wouldst thou? thy name?\n",
      "Why speak'st not? speak, man: what's thy name?\n",
      "\n",
      "CORIOLANUS:\n",
      "If, Tullus,\n",
      "Not yet thou knowest me, and, seeing me, dost not\n",
      "Think me for the man I am, necessity\n",
      "Commands me name myself.\n",
      "\n",
      "AUFIDIUS:\n",
      "What is thy name?\n",
      "\n",
      "CORIOLANUS:\n",
      "A name unmusical to the Volscians' ears,\n",
      "And harsh in sound to thine.\n",
      "\n",
      "AUFIDIUS:\n",
      "Say, what's thy name?\n",
      "Thou hast a grim appearance, and thy face\n",
      "Bears a command in't; though thy tackle's torn.\n",
      "Thou show'st a noble vessel: what's thy name?\n",
      "\n",
      "CORIOLANUS:\n",
      "Prepare thy brow to frown: know'st\n",
      "thou me yet?\n",
      "\n",
      "AUFIDIUS:\n",
      "I know thee not: thy name?\n",
      "\n",
      "CORIOLANUS:\n",
      "My name is Caius Marcius, who hath done\n",
      "To thee particularly and to all the Volsces\n",
      "Great hurt and mischief; thereto witness may\n",
      "My surname, Coriolanus: the painful service,\n",
      "The extreme dangers and the drops of blood\n",
      "Shed for my thankless country are requited\n",
      "But with that surname; a good memory,\n",
      "And witness of the malice and displeasure\n",
      "Which thou shouldst bear me: only that name remains;\n",
      "The cruelty and envy of the people,\n",
      "Permitted by our dastard nobles, who\n",
      "Have all forsook me, hath devour'd the rest;\n",
      "And suffer'd me by the voice of slaves to be\n",
      "Whoop'd out of Rome. Now this extremity\n",
      "Hath brought me to thy hearth; not out of hope--\n",
      "Mistake me not--to save my life, for if\n",
      "I had fear'd death, of all the men i' the world\n",
      "I would have 'voided thee, but in mere spite,\n",
      "To be full quit of those my banishers,\n",
      "Stand I before thee here. Then if thou hast\n",
      "A heart of wreak in thee, that wilt revenge\n",
      "Thine own particular wrongs and stop those maims\n",
      "Of shame seen through thy country, speed\n",
      "thee straight,\n",
      "And make my misery serve thy turn: so use it\n",
      "That my revengeful services may prove\n",
      "As benefits to thee, for I will fight\n",
      "Against my canker'd country with the spleen\n",
      "Of all the under fiends. But if so be\n",
      "Thou darest not this and that to prove more fortunes\n",
      "Thou'rt tired, then, in a word, I also am\n",
      "Longer to live most weary, and present\n",
      "My throat to thee and to thy ancient malice;\n",
      "Which not to cut would show thee but a fool,\n",
      "Since I have ever follow'd thee with hate,\n",
      "Drawn tuns of blood out of thy country's breast,\n",
      "And cannot live but to thy shame, unless\n",
      "It be to do thee service.\n",
      "\n",
      "AUFIDIUS:\n",
      "O Marcius, Marcius!\n",
      "Each word thou hast spoke hath weeded from my heart\n",
      "A root of ancient envy. If Jupiter\n",
      "Should from yond cloud speak divine things,\n",
      "And say 'Tis true,' I'ld not believe them more\n",
      "Than thee, all noble Marcius. Let me twine\n",
      "Mine arms about that body, where against\n",
      "My grained ash an hundred times hath broke\n",
      "And scarr'd the moon with splinters: here I clip\n",
      "The anvil of my sword, and do contest\n",
      "As hotly and as nobly with thy love\n",
      "As ever in ambitious strength I did\n",
      "Contend against thy valour. Know thou first,\n",
      "I loved the maid I married; never man\n",
      "Sigh'd truer breath; but that I see thee here,\n",
      "Thou noble thing! more dances my rapt heart\n",
      "Than when I first my wedded mistress saw\n",
      "Bestride my threshold. Why, thou Mars! I tell thee,\n",
      "We have a power on foot; and I had purpose\n",
      "Once more to hew thy target from thy brawn,\n",
      "Or lose mine arm fort: thou hast beat me out\n",
      "Twelve several times, and I have nightly since\n",
      "Dreamt of encounters 'twixt thyself and me;\n",
      "We have been down together in my sleep,\n",
      "Unbuckling helms, fisting each other's throat,\n",
      "And waked half dead with nothing. Worthy Marcius,\n",
      "Had we no quarrel else to Rome, but that\n",
      "Thou art thence banish'd, we would muster all\n",
      "From twelve to seventy, and pouring war\n",
      "Into the bowels of ungrateful Rome,\n",
      "Like a bold flood o'er-bear. O, come, go in,\n",
      "And take our friendly senators by the hands;\n",
      "Who now are here, taking their leaves of me,\n",
      "Who am prepared against your territories,\n",
      "Though not for Rome itself.\n",
      "\n",
      "CORIOLANUS:\n",
      "You bless me, gods!\n",
      "\n",
      "AUFIDIUS:\n",
      "Therefore, most absolute sir, if thou wilt have\n",
      "The leading of thine own revenges, take\n",
      "The one half of my commission; and set down--\n",
      "As best thou art experienced, since thou know'st\n",
      "Thy country's strength and weakness,--thine own ways;\n",
      "Whether to knock against the gates of Rome,\n",
      "Or rudely visit them in parts remote,\n",
      "To fright them, ere destroy. But come in:\n",
      "Let me commend thee first to those that shall\n",
      "Say yea to thy desires. A thousand welcomes!\n",
      "And more a friend than e'er an enemy;\n",
      "Yet, Marcius, that was much. Your hand: most welcome!\n",
      "\n",
      "First Servingman:\n",
      "Here's a strange alteration!\n",
      "\n",
      "Second Servingman:\n",
      "By my hand, I had thought to have strucken him with\n",
      "a cudgel; and yet my mind gave me his clothes made a\n",
      "false report of him.\n",
      "\n",
      "First Servingman:\n",
      "What an arm he has! he turned me about with his\n",
      "finger and his thumb, as one would set up a top.\n",
      "\n",
      "Second Servingman:\n",
      "Nay, I knew by his face that there was something in\n",
      "him: he had, sir, a kind of face, methought,--I\n",
      "cannot tell how to term it.\n",
      "\n",
      "First Servingman:\n",
      "He had so; looking as it were--would I were hanged,\n",
      "but I thought there was more in him than I could think.\n",
      "\n",
      "Second Servingman:\n",
      "So did I, I'll be sworn: he is simply the rarest\n",
      "man i' the world.\n",
      "\n",
      "First Servingman:\n",
      "I think he is: but a greater soldier than he you wot on.\n",
      "\n",
      "Second Servingman:\n",
      "Who, my master?\n",
      "\n",
      "First Servingman:\n",
      "Nay, it's no matter for that.\n",
      "\n",
      "Second Servingman:\n",
      "Worth six on him.\n",
      "\n",
      "First Servingman:\n",
      "Nay, not so neither: but I take him to be the\n",
      "greater soldier.\n",
      "\n",
      "Second Servingman:\n",
      "Faith, look you, one cannot tell how to say that:\n",
      "for the defence of a town, our general is excellent.\n",
      "\n",
      "First Servingman:\n",
      "Ay, and for an assault too.\n",
      "\n",
      "Third Servingman:\n",
      "O slaves, I can tell you news,-- news, you rascals!\n",
      "\n",
      "First Servingman:\n",
      "What, what, what? let's partake.\n",
      "\n",
      "Third Servingman:\n",
      "I would not be a Roman, of all nations; I had as\n",
      "lieve be a condemned man.\n",
      "\n",
      "First Servingman:\n",
      "Wherefore? wherefore?\n",
      "\n",
      "Third Servingman:\n",
      "Why, here's he that was wont to thwack our general,\n",
      "Caius Marcius.\n",
      "\n",
      "First Servingman:\n",
      "Why do you say 'thwack our general '?\n",
      "\n",
      "Third Servingman:\n",
      "I do not say 'thwack our general;' but he was always\n",
      "good enough for him.\n",
      "\n",
      "Second Servingman:\n",
      "Come, we are fellows and friends: he was ever too\n",
      "hard for him; I have heard him say so himself.\n",
      "\n",
      "First Servingman:\n",
      "He was too hard for him directly, to say the troth\n",
      "on't: before Corioli he scotched him and notched\n",
      "him like a carbon ado.\n",
      "\n",
      "Second Servingman:\n",
      "An he had been cannibally given, he might have\n",
      "broiled and eaten him too.\n",
      "\n",
      "First Servingman:\n",
      "But, more of thy news?\n",
      "\n",
      "Third Servingman:\n",
      "Why, he is so made on here within, as if he were son\n",
      "and heir to Mars; set at upper end o' the table; no\n",
      "question asked him by any of the senators, but they\n",
      "stand bald before him: our general himself makes a\n",
      "mistress of him: sanctifies himself with's hand and\n",
      "turns up the white o' the eye to his discourse. But\n",
      "the bottom of the news is that our general is cut i'\n",
      "the middle and but one half of what he was\n",
      "yesterday; for the other has half, by the entreaty\n",
      "and grant of the whole table. He'll go, he says,\n",
      "and sowl the porter of Rome gates by the ears: he\n",
      "will mow all down before him, and leave his passage polled.\n",
      "\n",
      "Second Servingman:\n",
      "And he's as like to do't as any man I can imagine.\n",
      "\n",
      "Third Servingman:\n",
      "Do't! he will do't; for, look you, sir, he has as\n",
      "many friends as enemies; which friends, sir, as it\n",
      "were, durst not, look you, sir, show themselves, as\n",
      "we term it, his friends whilst he's in directitude.\n",
      "\n",
      "First Servingman:\n",
      "Directitude! what's that?\n",
      "\n",
      "Third Servingman:\n",
      "But when they shall see, sir, his crest up again,\n",
      "and the man in blood, they will out of their\n",
      "burrows, like conies after rain, and revel all with\n",
      "him.\n",
      "\n",
      "First Servingman:\n",
      "But when goes this forward?\n",
      "\n",
      "Third Servingman:\n",
      "To-morrow; to-day; presently; you shall have the\n",
      "drum struck up this afternoon: 'tis, as it were, a\n",
      "parcel of their feast, and to be executed ere they\n",
      "wipe their lips.\n",
      "\n",
      "Second Servingman:\n",
      "Why, then we shall have a stirring world again.\n",
      "This peace is nothing, but to rust iron, increase\n",
      "tailors, and breed ballad-makers.\n",
      "\n",
      "First Servingman:\n",
      "Let me have war, say I; it exceeds peace as far as\n",
      "day does night; it's spritely, waking, audible, and\n",
      "full of vent. Peace is a very apoplexy, lethargy;\n",
      "mulled, deaf, sleepy, insensible; a getter of more\n",
      "bastard children than war's a destroyer of men.\n",
      "\n",
      "Second Servingman:\n",
      "'Tis so: and as war, in some sort, may be said to\n",
      "be a ravisher, so it cannot be denied but peace is a\n",
      "great maker of cuckolds.\n",
      "\n",
      "First Servingman:\n",
      "Ay, and it makes men hate one another.\n",
      "\n",
      "Third Servingman:\n",
      "Reason; because they then less need one another.\n",
      "The wars for my money. I hope to see Romans as cheap\n",
      "as Volscians. They are rising, they are rising.\n",
      "\n",
      "All:\n",
      "In, in, in, in!\n",
      "\n",
      "SICINIUS:\n",
      "We hear not of him, neither need we fear him;\n",
      "His remedies are tame i' the present peace\n",
      "And quietness of the people, which before\n",
      "Were in wild hurry. Here do we make his friends\n",
      "Blush that the world goes well, who rather had,\n",
      "Though they themselves did suffer by't, behold\n",
      "Dissentious numbers pestering streets than see\n",
      "Our tradesmen with in their shops and going\n",
      "About their functions friendly.\n",
      "\n",
      "BRUTUS:\n",
      "We stood to't in good time.\n",
      "Is this Menenius?\n",
      "\n",
      "SICINIUS:\n",
      "'Tis he,'tis he: O, he is grown most kind of late.\n",
      "\n",
      "Both Tribunes:\n",
      "Hail sir!\n",
      "\n",
      "MENENIUS:\n",
      "Hail to you both!\n",
      "\n",
      "SICINIUS:\n",
      "Your Coriolanus\n",
      "Is not much miss'd, but with his friends:\n",
      "The commonwealth doth stand, and so would do,\n",
      "Were he more angry at it.\n",
      "\n",
      "MENENIUS:\n",
      "All's well; and might have been much better, if\n",
      "He could have temporized.\n",
      "\n",
      "SICINIUS:\n",
      "Where is he, hear you?\n",
      "\n",
      "MENENIUS:\n",
      "Nay, I hear nothing: his mother and his wife\n",
      "Hear nothing from him.\n",
      "\n",
      "Citizens:\n",
      "The gods preserve you both!\n",
      "\n",
      "SICINIUS:\n",
      "God-den, our neighbours.\n",
      "\n",
      "BRUTUS:\n",
      "God-den to you all, god-den to you all.\n",
      "\n",
      "First Citizen:\n",
      "Ourselves, our wives, and children, on our knees,\n",
      "Are bound to pray for you both.\n",
      "\n",
      "SICINIUS:\n",
      "Live, and thrive!\n",
      "\n",
      "BRUTUS:\n",
      "Farewell, kind neighbours: we wish'd Coriolanus\n",
      "Had loved you as we did.\n",
      "\n",
      "Citizens:\n",
      "Now the gods keep you!\n",
      "\n",
      "Both Tribunes:\n",
      "Farewell, farewell.\n",
      "\n",
      "SICINIUS:\n",
      "This is a happier and more comely time\n",
      "Than when these fellows ran about the streets,\n",
      "Crying confusion.\n",
      "\n",
      "BRUTUS:\n",
      "Caius Marcius was\n",
      "A worthy officer i' the war; but insolent,\n",
      "O'ercome with pride, ambitious past all thinking,\n",
      "Self-loving,--\n",
      "\n",
      "SICINIUS:\n",
      "And affecting one sole throne,\n",
      "Without assistance.\n",
      "\n",
      "MENENIUS:\n",
      "I think not so.\n",
      "\n",
      "SICINIUS:\n",
      "We should by this, to all our lamentation,\n",
      "If he had gone forth consul, found it so.\n",
      "\n",
      "BRUTUS:\n",
      "The gods have well prevented it, and Rome\n",
      "Sits safe and still without him.\n",
      "\n",
      "AEdile:\n",
      "Worthy tribunes,\n",
      "There is a slave, whom we have put in prison,\n",
      "Reports, the Volsces with two several powers\n",
      "Are enter'd in the Roman territories,\n",
      "And with the deepest malice of the war\n",
      "Destroy what lies before 'em.\n",
      "\n",
      "MENENIUS:\n",
      "'Tis Aufidius,\n",
      "Who, hearing of our Marcius' banishment,\n",
      "Thrusts forth his horns again into the world;\n",
      "Which were inshell'd when Marcius stood for Rome,\n",
      "And durst not once peep out.\n",
      "\n",
      "SICINIUS:\n",
      "Come, what talk you\n",
      "Of Marcius?\n",
      "\n",
      "BRUTUS:\n",
      "Go see this rumourer whipp'd. It cannot be\n",
      "The Volsces dare break with us.\n",
      "\n",
      "MENENIUS:\n",
      "Cannot be!\n",
      "We have record that very well it can,\n",
      "And three examples of the like have been\n",
      "Within my age. But reason with the fellow,\n",
      "Before you punish him, where he heard this,\n",
      "Lest you shall chance to whip your information\n",
      "And beat the messenger who bids beware\n",
      "Of what is to be dreaded.\n",
      "\n",
      "SICINIUS:\n",
      "Tell not me:\n",
      "I know this cannot be.\n",
      "\n",
      "BRUTUS:\n",
      "Not possible.\n",
      "\n",
      "Messenger:\n",
      "The nobles in great earnestness are going\n",
      "All to the senate-house: some news is come\n",
      "That turns their countenances.\n",
      "\n",
      "SICINIUS:\n",
      "'Tis this slave;--\n",
      "Go whip him, 'fore the people's eyes:--his raising;\n",
      "Nothing but his report.\n",
      "\n",
      "Messenger:\n",
      "Yes, worthy sir,\n",
      "The slave's report is seconded; and more,\n",
      "More fearful, is deliver'd.\n",
      "\n",
      "SICINIUS:\n",
      "What more fearful?\n",
      "\n",
      "Messenger:\n",
      "It is spoke freely out of many mouths--\n",
      "How probable I do not know--that Marcius,\n",
      "Join'd with Aufidius, leads a power 'gainst Rome,\n",
      "And vows revenge as spacious as between\n",
      "The young'st and oldest thing.\n",
      "\n",
      "SICINIUS:\n",
      "This is most likely!\n",
      "\n",
      "BRUTUS:\n",
      "Raised only, that the weaker sort may wish\n",
      "Good Marcius home again.\n",
      "\n",
      "SICINIUS:\n",
      "The very trick on't.\n",
      "\n",
      "MENENIUS:\n",
      "This is unlikely:\n",
      "He and Aufidius can no more atone\n",
      "Than violentest contrariety.\n",
      "\n",
      "Second Messenger:\n",
      "You are sent for to the senate:\n",
      "A fearful army, led by Caius Marcius\n",
      "Associated with Aufidius, rages\n",
      "Upon our territories; and have already\n",
      "O'erborne their way, consumed with fire, and took\n",
      "What lay before them.\n",
      "\n",
      "COMINIUS:\n",
      "O, you have made good work!\n",
      "\n",
      "MENENIUS:\n",
      "What news? what news?\n",
      "\n",
      "COMINIUS:\n",
      "You have holp to ravish your own daughters and\n",
      "To melt the city leads upon your pates,\n",
      "To see your wives dishonour'd to your noses,--\n",
      "\n",
      "MENENIUS:\n",
      "What's the news? what's the news?\n",
      "\n",
      "COMINIUS:\n",
      "Your temples burned in their cement, and\n",
      "Your franchises, whereon you stood, confined\n",
      "Into an auger's bore.\n",
      "\n",
      "MENENIUS:\n",
      "Pray n\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "#url = \"https://www.gutenberg.org/cache/epub/64317/pg64317.txt\" # The Great Gatsby\n",
    "\n",
    "response = httpx.get(url)\n",
    "text = response.text\n",
    "\n",
    "text = text[:120_000]  # Using 100k characters for speedup FEDE\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d4bf6",
   "metadata": {
    "id": "2c3d4bf6"
   },
   "source": [
    "# Character-based encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9534ad30",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1755380455432,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "9534ad30"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text))) # Toma el texto y obtiene los caracteres que lo conforman, luego genera una lista ordenada alfabeticamente.\n",
    "vocab_size = len(chars) # Tamaño del vocabulario (Numero de caracteres)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)} # Genera diccionario para la conversion de string a enteros\n",
    "itos = {i: ch for ch, i in stoi.items()} # Genera diccionario para la conversion de enteros a string\n",
    "def encode(s): return [stoi[c] for c in s] #Define funcion para codificar caracteres\n",
    "def decode(l): return ''.join([itos[i] for i in l])#Define uncion poara decodificar caracteres\n",
    "data = torch.tensor(encode(text), dtype=torch.long) #Convierte el texto a secuencia de numeros como tensor\n",
    "\n",
    "# Train/test split\n",
    "split = int(0.9 * len(data)) # separa datos en 90 y 10%\n",
    "train_data = data[:split] #90% de datos para entrenamiento\n",
    "val_data = data[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ef2c6",
   "metadata": {
    "id": "253ef2c6"
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c7342eb",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1755380455434,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "3c7342eb"
   },
   "outputs": [],
   "source": [
    "#Define clase que recibe cadena de caracteres (input) y un tamaño de bloque (Ventana), y retorna el par X,Y siendo las cadenas definidas por el largo del bloque y la\n",
    "#  misma cadena desplazada en una posicion. Se va desplazando la ventana por el texto de a un caracter.\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, block_size: int):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx : idx + self.block_size]\n",
    "        y = self.data[idx + 1 : idx + self.block_size + 1]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8724e",
   "metadata": {
    "id": "24d8724e"
   },
   "source": [
    "# GPT Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "412ec5c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1755380455486,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "412ec5c8",
    "outputId": "4f6134cd-094f-4aac-9e15-b7feb8feec7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'block_size': 32, 'batch_size': 8, 'n_embd': 64, 'n_head': 8, 'n_layer': 2, 'dropout': 0.1, 'vocab_size': 61, 'bias': True, 'ff_class': None, 'moe_args': None}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class MoEArgs():\n",
    "    \"\"\"\n",
    "    MoE input arguments class.\n",
    "    \"\"\"\n",
    "    num_experts : int = field(default=4)\n",
    "    num_experts_per_token : int = field(default=2)\n",
    "    top_k : int = field(default=2) # FEDERICO\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    \"\"\"\n",
    "    Base class for GPT models.\n",
    "    \"\"\"\n",
    "    block_size: int = 32\n",
    "    batch_size: int = 8\n",
    "    n_embd: int = 64\n",
    "    #n_head: int = 4\n",
    "    n_head: int = 8\n",
    "    n_layer: int = 2\n",
    "    dropout: float = 0.1\n",
    "    vocab_size: int = vocab_size\n",
    "    bias: bool = True\n",
    "    ff_class: Optional[Type[nn.Module]] = None\n",
    "    moe_args : Optional[MoEArgs] = None\n",
    "\n",
    "config = GPTConfig()\n",
    "print(config.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8693f574",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1755380455492,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "8693f574",
    "outputId": "82aa76c8-5897-46d8-f669-aa6606ed511a"
   },
   "outputs": [],
   "source": [
    "train_dataset = CharDataset(train_data, config.block_size) #Se instancia clase con datos de entrenamiento de tamaño block_size\n",
    "val_dataset = CharDataset(val_data, config.block_size) #Se instancia clase con datos de validacion\n",
    "\n",
    "# Se generan los dataloaders correspondientes para train and val partiendo de los objetos XXX_dataset.\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=config.batch_size,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        pin_memory=True,\n",
    "                        num_workers= 8, # if using mps set num_workers as 0.\n",
    "                        )\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=config.batch_size,\n",
    "                        shuffle=False,\n",
    "                        drop_last=True,\n",
    "                        pin_memory=True,\n",
    "                        num_workers= 8,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee03a21b",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1755380455494,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "ee03a21b"
   },
   "outputs": [],
   "source": [
    "# clase que define una unica cabeza de atencion\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention Head for Multi-Head Attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, args: GPTConfig) -> None:\n",
    "        super().__init__()\n",
    "        assert args.n_embd % args.n_head == 0, \"n_embd must be divisible by n_head\" # controles de consistencia de datos y parametros\n",
    "        self.head_dim = args.n_embd // args.n_head #El espacio de embeddings es separado en partes guales hacia cada cabeza de atension, con lo cual se definen dimensiones de heads de manera consistente\n",
    "\n",
    "        # Combined QKV projection\n",
    "        self.key_query_value = nn.Linear(args.n_embd, 3 * self.head_dim, bias=args.bias) # Entrada dim del input embedding y salida 3 vectores QKV= inut embedding del self-attention head.\n",
    "\n",
    "        self.dropout = nn.Dropout(args.dropout) #Aplico dropout solo en trainign\n",
    "        self.block_size = args.block_size\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(args.block_size, args.block_size))) # Creo buffer con la Mask de atencion con matriz triangular inferior.\n",
    "\n",
    "    # Cabeza de atención recibe input embedding y parametros kv_cache y return_weights\n",
    "    def forward(self, x: torch.Tensor, kv_cache: Optional[torch.Tensor] = None, return_weights=False):\n",
    "        B, T, C = x.shape #X corresponde al tensor con los datos del batch en proceso, bloque de caracteres de entrada y bloque de caracteres de salida (edsplazado 1 caracter)\n",
    "        key_query_value = self.key_query_value(x)  # (B, T, 3 * head_dim) - Es decir paso el batch por la red FFN  obtengo los 3 vectores QKV\n",
    "        k, q, v = torch.chunk(key_query_value, 3, dim=-1)  # (B, T, head_dim) each ENTONCES Los separo\n",
    "\n",
    "        # Se van almacenando los vectores para los token que ya fueron procesados con el fin de hacer eficiente la generacion - En train suele ser None.\n",
    "        if kv_cache is not None:\n",
    "            key_cache, value_cache = kv_cache.unbind(dim=0)  # (B, T', head_dim)\n",
    "            k = torch.cat((key_cache, k), dim=1)\n",
    "            v = torch.cat((value_cache, v), dim=1)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        wei = q @ k.transpose(-2, -1) * (self.head_dim ** -0.5)  # (B, T, T) Se aplica formula Q.K⁷/SQRT(d)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # Se le aplica la Mask de atencion- reemplaza 0 por -inf para la Softmax posterior\n",
    "        wei = F.softmax(wei, dim=-1) #Al resultado se le aplica Softmax\n",
    "        wei = self.dropout(wei) #Se aplica dropout a los pesos de atencion - Esto debe estudiarse mejor!!!!\n",
    "\n",
    "        out = wei @ v  # (B, T, head_dim) Se multiplica por V para finalizar el calculo de la matriz de Atencion.\n",
    "\n",
    "        if return_weights:\n",
    "            return out, wei\n",
    "\n",
    "        if kv_cache is not None:\n",
    "            return out, torch.stack((k, v))\n",
    "\n",
    "        return out, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7de8ad04",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1755380455495,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "7de8ad04"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, args: GPTConfig):\n",
    "        super().__init__()\n",
    "        assert args.n_embd % args.n_head == 0, \"n_embd must be divisible by n_head\"\n",
    "        self.n_heads = args.n_head\n",
    "        self.head_dim = args.n_embd // args.n_head\n",
    "\n",
    "        self.heads = nn.ModuleList([ #Lista de modulos nn.Module\n",
    "            AttentionHead(args) for _ in range(self.n_heads) # instancia las cabezas de atencion para que trabajen en paralelo\n",
    "        ])\n",
    "\n",
    "        self.proj = nn.Linear(args.n_embd, args.n_embd, bias=args.bias) # Capa lineal de poryeccion\n",
    "        self.dropout = nn.Dropout(args.dropout) #Dropouts\n",
    "\n",
    "    def forward(self, x, kv_cache=None, return_weights=False):\n",
    "        all_outputs = []\n",
    "        all_weights = []\n",
    "        new_kv_cache = [] if kv_cache is not None else None\n",
    "\n",
    "        for i, head in enumerate(self.heads): #por cada cabeza de atencion se procesan los datos de entrada\n",
    "            head_cache = kv_cache[i] if kv_cache is not None else None\n",
    "            out, weights_or_kv = head(x, kv_cache=head_cache, return_weights=return_weights)\n",
    "            all_outputs.append(out)\n",
    "            if return_weights:\n",
    "                all_weights.append(weights_or_kv)\n",
    "            if kv_cache is not None:\n",
    "                new_kv_cache.append(weights_or_kv)  # weights_or_kv is new kv_cache here\n",
    "\n",
    "        concat = torch.cat(all_outputs, dim=-1)  # concat along embedding dim - Concatena las salidas y pasa por capa lineal\n",
    "        out = self.dropout(self.proj(concat))\n",
    "\n",
    "        if return_weights:\n",
    "            return out, torch.stack(all_weights)\n",
    "        if kv_cache is not None:\n",
    "            return out, new_kv_cache\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d94a31d5",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1755380455517,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "d94a31d5"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module): # Definicion de capa lineal FFN de entrada por token\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            nn.Dropout(config.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module): # Construye el bloque Transformer uniendo los componentes Lay&Norm - FFN - Multi-Head Attention Block\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd) #Se instancias los objetos que conforman el bloque transformer\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = MultiHeadAttention(config)\n",
    "\n",
    "        ff_class = config.ff_class if config.ff_class is not None else FeedForward\n",
    "        self.ff = ff_class(config)\n",
    "\n",
    "    def forward(self, x, kv_cache=None, return_weights=False):\n",
    "        attn_out = self.attn(self.ln1(x), kv_cache=kv_cache, return_weights=return_weights) #Se iteran los datos de entrada por la primera capa L&N y se envia al bloque multihead\n",
    "        if return_weights:\n",
    "            attn_out, weights = attn_out\n",
    "        else:\n",
    "            weights = None\n",
    "\n",
    "        if isinstance(attn_out, tuple):\n",
    "            attn_out, updated_kv = attn_out\n",
    "        else:\n",
    "            updated_kv = None\n",
    "\n",
    "        x = x + attn_out\n",
    "        x = x + self.ff(self.ln2(x)) # se le suma la conexion residual y se pasa el resulado por capa FFN final\n",
    "        return (x, updated_kv, weights) if return_weights else (x, updated_kv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c3ef8",
   "metadata": {
    "id": "9a4c3ef8"
   },
   "source": [
    "## TinyGPT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcf750eb",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755380455518,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "fcf750eb"
   },
   "outputs": [],
   "source": [
    "class TinyGPT(nn.Module): # Se define la clase de todo el modelo\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config.vocab_size, config.n_embd) #Embedding de inputs\n",
    "        self.pos_emb = nn.Embedding(config.block_size, config.n_embd)#Embedding de Posicion\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)]) #Se instancias los N=n_layer = 2 bloques transformer\n",
    "        self.ln_f = nn.LayerNorm(config.n_embd) #Capa de normalizacion\n",
    "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False) #Capa de salida\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, idx, kv_cache=None, return_weights=False): #Se procesa el token por su indice idx\n",
    "        B, T = idx.shape # B: Batch size (número de secuencias/ejemplos procesados en paralelo). T: Longitud de la secuencia (número de tokens en cada secuencia).\n",
    "                         # idx: contiene los índices de los tokens de entrada.\n",
    "        tok_emb = self.token_emb(idx) # a partir de cada token genera su embedding correspondiente\n",
    "        pos = torch.arange(T, device=idx.device)\n",
    "        pos_emb = self.pos_emb(pos)[None, :, :] #Genera vector de embedding posicional\n",
    "        x = tok_emb + pos_emb # Suma ambos embeddings para generar la entrada.\n",
    "\n",
    "        new_kv_cache = [] if kv_cache is not None else None\n",
    "        all_weights = [] if return_weights else None\n",
    "\n",
    "        for i, block in enumerate(self.blocks): # Itera sobre los bloques que compoenen el modelo pasandole los datos de entrada\n",
    "            layer_kv = kv_cache[i] if kv_cache is not None else None\n",
    "            if return_weights:\n",
    "                x, updated_kv, weights = block(x, kv_cache=layer_kv, return_weights=True)\n",
    "                all_weights.append(weights)  # weights shape: (n_heads, B, T, T)\n",
    "            else:\n",
    "                x, updated_kv = block(x, kv_cache=layer_kv)\n",
    "            if kv_cache is not None:\n",
    "                new_kv_cache.append(updated_kv)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "\n",
    "        if return_weights:\n",
    "            if kv_cache is not None:\n",
    "                return logits, new_kv_cache, all_weights\n",
    "            else:\n",
    "                return logits, all_weights\n",
    "        else:\n",
    "            if kv_cache is not None:\n",
    "                return logits, new_kv_cache\n",
    "            return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca10608",
   "metadata": {
    "id": "6ca10608"
   },
   "source": [
    "## Generation function (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e694232f",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1755380455519,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "e694232f"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(prompt: str, max_new_tokens: int = 100, use_cache: bool = True):\n",
    "    model.eval()\n",
    "    idx = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    kv_cache = None\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        if use_cache and kv_cache is not None:\n",
    "            idx_cond = idx[:, -1:]\n",
    "        else:\n",
    "            idx_cond = idx[:, -config.block_size:]\n",
    "\n",
    "        out = model(idx_cond, kv_cache=kv_cache) if use_cache else model(idx_cond)\n",
    "\n",
    "        if isinstance(out, tuple):\n",
    "            logits, kv_cache = out\n",
    "        else:\n",
    "            logits = out\n",
    "            kv_cache = None\n",
    "\n",
    "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat((idx, next_token), dim=1)\n",
    "\n",
    "    return decode(idx[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5d7bd",
   "metadata": {
    "id": "17b5d7bd"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f757e415",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1755380455519,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "f757e415"
   },
   "outputs": [],
   "source": [
    "device =  'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "m = TinyGPT(config).to(device)\n",
    "model = torch.compile(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71a1b596",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1755380455521,
     "user": {
      "displayName": "Federico Martín Zoya",
      "userId": "17811220531049175137"
     },
     "user_tz": 180
    },
    "id": "71a1b596"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=100, gamma=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c7cd7",
   "metadata": {
    "id": "180c7cd7"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "KdYmn-3KpZ56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdYmn-3KpZ56",
    "outputId": "df6ee6fd-1ad5-45c6-8405-159fc924ba36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13496 [00:00<?, ?it/s]W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/2162509525.py line 11 \n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:08:59.284000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/4094430363.py line 24 \n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:01.371000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/2824854219.py line 15 \n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:03.242000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/4153342562.py line 19 \n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:03.512000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/4094430363.py line 11 \n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 20:09:03.727000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "loss 2.11828: 100%|██████████| 13496/13496 [04:07<00:00, 54.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training loss: 2.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 138.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.14563: 100%|██████████| 13496/13496 [03:41<00:00, 60.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 training loss: 2.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:11<00:00, 131.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.11828: 100%|██████████| 13496/13496 [03:42<00:00, 60.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 training loss: 2.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:11<00:00, 135.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.09842: 100%|██████████| 13496/13496 [03:39<00:00, 61.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 training loss: 2.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 138.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.11752: 100%|██████████| 13496/13496 [03:39<00:00, 61.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 training loss: 2.2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 137.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.13578: 100%|██████████| 13496/13496 [03:39<00:00, 61.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 training loss: 2.1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 138.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.14320: 100%|██████████| 13496/13496 [03:45<00:00, 59.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 training loss: 2.1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 139.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.11278: 100%|██████████| 13496/13496 [03:42<00:00, 60.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 training loss: 2.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 140.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.10432: 100%|██████████| 13496/13496 [03:41<00:00, 61.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 training loss: 2.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 138.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.10091: 100%|██████████| 13496/13496 [03:39<00:00, 61.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 training loss: 2.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 138.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.06735: 100%|██████████| 13496/13496 [03:39<00:00, 61.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 training loss: 2.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 138.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.16643: 100%|██████████| 13496/13496 [03:38<00:00, 61.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 training loss: 2.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 138.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.13588: 100%|██████████| 13496/13496 [03:39<00:00, 61.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 training loss: 2.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 141.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.11956: 100%|██████████| 13496/13496 [03:35<00:00, 62.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 training loss: 2.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 141.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.12810: 100%|██████████| 13496/13496 [03:36<00:00, 62.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 training loss: 2.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 141.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.13530: 100%|██████████| 13496/13496 [03:35<00:00, 62.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 training loss: 2.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 140.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.10449: 100%|██████████| 13496/13496 [03:36<00:00, 62.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 training loss: 2.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 141.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.12661: 100%|██████████| 13496/13496 [03:36<00:00, 62.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 training loss: 2.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 141.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.15509: 100%|██████████| 13496/13496 [03:36<00:00, 62.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 training loss: 2.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 140.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 validation loss: 2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.12789: 100%|██████████| 13496/13496 [03:36<00:00, 62.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 training loss: 2.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.83425: 100%|██████████| 1496/1496 [00:10<00:00, 141.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 validation loss: 2.1675\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#Problemas de cincompatibilidad con arquitectura GTX970\n",
    "#import torch._dynamo # Agregado por compatibilidad\n",
    "#torch._dynamo.config.suppress_errors = True # Agregado por compatibilidad con GPU gtx970\n",
    "\n",
    "# Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_data_loader=train_loader,\n",
    "    test_data_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    save_dir=\"./checkpoints\",\n",
    "    save_every_n=500\n",
    ")\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    #avg_train_loss = trainer.train_model_v2(use_amp=True, dtype=torch.bfloat16)\n",
    "    avg_train_loss = trainer.train_model_v2(use_amp=True, dtype=torch.float32)\n",
    "    print(f\"Epoch {epoch+1} training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    val_loss = trainer.eval_model()\n",
    "    print(f\"Epoch {epoch+1} validation loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5b33a",
   "metadata": {
    "id": "88e5b33a"
   },
   "source": [
    "### Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "798ca80d",
   "metadata": {
    "id": "798ca80d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name iskin\\nEt pee 'thar on I stheang shens Isim?\\nBll tod dof sInd the wick nads tas.\\n\\nMe sist.\\n\\nMENIUS:\\n\\nSe\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"Your name is\", max_new_tokens=100,use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47ebc6",
   "metadata": {
    "id": "7d47ebc6"
   },
   "source": [
    "# Task I\n",
    "\n",
    "Using TinyGPT you need to implement the following modifications:\n",
    "\n",
    "\n",
    "## Inference: Modify the generate function to:\n",
    "- Greedy decoding (pick max probability token).\n",
    "- Temperature sampling.\n",
    "- top-k or top-p sampling.\n",
    "\n",
    "### References\n",
    "- [huggingface generate](https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1875a7ee",
   "metadata": {
    "id": "1875a7ee"
   },
   "outputs": [],
   "source": [
    "# TODO Implement Greedy decoding, Temperature and top_k/top_p\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# Asume que 'model', 'encode', 'decode', 'device' y 'config' ya están definidos en tu entorno.\n",
    "# Por ejemplo:\n",
    "# from your_model_module import model, encode, decode, device, config\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_V2(\n",
    "    prompt: str,\n",
    "    max_new_tokens: int = 100,\n",
    "    use_cache: bool = True,\n",
    "    strategy: str = 'temperature', # 'greedy', 'temperature', 'top-k', 'top-p'\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = None,\n",
    "    top_p: float = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera texto a partir de un prompt inicial utilizando diferentes estrategias de muestreo.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): El texto inicial para comenzar la generación.\n",
    "        max_new_tokens (int): El número máximo de nuevos tokens a generar.\n",
    "        use_cache (bool): Si se debe usar el caché KV para acelerar la inferencia.\n",
    "        strategy (str): La estrategia de muestreo a utilizar. Opciones:\n",
    "                        'greedy': Selecciona el token con la probabilidad más alta.\n",
    "                        'temperature': Muestreo con ajuste de temperatura.\n",
    "                        'top-k': Muestreo de los k tokens más probables.\n",
    "                        'top-p': Muestreo de los tokens dentro de una masa de probabilidad 'p'.\n",
    "        temperature (float): Factor de temperatura para el muestreo. Solo relevante para 'temperature', 'top-k', 'top-p'.\n",
    "                             Valores > 1.0 hacen el muestreo más aleatorio.\n",
    "                             Valores < 1.0 hacen el muestreo más determinista.\n",
    "        top_k (int): Número de tokens a considerar para el muestreo Top-K. Solo relevante para 'top-k'.\n",
    "                     Debe ser un entero positivo.\n",
    "        top_p (float): Masa de probabilidad acumulada para el muestreo Top-P. Solo relevante para 'top-p'.\n",
    "                       Debe ser un valor entre 0.0 y 1.0.\n",
    "    \"\"\"\n",
    "    model.eval() # Asegura que el modelo esté en modo evaluación (desactiva dropout, etc.)\n",
    "    idx = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    kv_cache = None\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Preparar la entrada para el modelo, usando el último token si hay caché\n",
    "        if use_cache and kv_cache is not None:\n",
    "            idx_cond = idx[:, -1:] # Solo el último token para la siguiente predicción\n",
    "        else:\n",
    "            # Si no hay caché o es la primera iteración, usar el bloque completo\n",
    "            idx_cond = idx[:, -config.block_size:]\n",
    "\n",
    "        # Realizar una pasada hacia adelante a través del modelo\n",
    "        out = model(idx_cond, kv_cache=kv_cache) if use_cache else model(idx_cond)\n",
    "\n",
    "        # Desempaquetar la salida: logits y (opcionalmente) el nuevo caché KV\n",
    "        if isinstance(out, tuple):\n",
    "            logits, kv_cache = out\n",
    "        else:\n",
    "            logits = out\n",
    "            kv_cache = None\n",
    "\n",
    "        # Obtener los logits del último token predicho\n",
    "        logits = logits[:, -1, :] # logit para el último token en la secuencia\n",
    "\n",
    "        # Aplicar temperatura si es diferente de 1.0\n",
    "        if temperature != 1.0 and temperature != 0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "        # Aplicar el muestreo según la estrategia\n",
    "        if strategy == 'greedy':\n",
    "            next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        elif strategy == 'temperature':\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        elif strategy == 'top-k':\n",
    "            if top_k is None or top_k <= 0:\n",
    "                raise ValueError(\"top_k debe ser un entero positivo para la estrategia 'top-k'.\")\n",
    "\n",
    "            # Filtrar los k valores más grandes\n",
    "            v, i = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            out = logits.clone().fill_(-float('inf')) # Copia y rellena con -inf\n",
    "            out.scatter_(1, i, v) # Vuelve a colocar los valores top-k\n",
    "            probs = F.softmax(out, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        elif strategy == 'top-p':\n",
    "            if top_p is None or not (0.0 < top_p <= 1.0):\n",
    "                raise ValueError(\"top_p debe ser un float entre 0.0 y 1.0 para la estrategia 'top-p'.\")\n",
    "\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "            # Remover tokens cuya probabilidad acumulada excede top_p\n",
    "            # Considerar también el token actual para no eliminarlo\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            # Retroceder un paso para incluir el último token que contribuyó a 'top_p'\n",
    "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "            sorted_indices_to_remove[..., 0] = False # Asegurar que al menos el primer token no se elimine\n",
    "\n",
    "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "            logits[:, indices_to_remove] = -float('inf') # Establecer sus logits a -inf\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Estrategia de muestreo no reconocida: {strategy}\")\n",
    "\n",
    "        # Añadir el token generado a la secuencia\n",
    "        idx = torch.cat((idx, next_token), dim=1)\n",
    "\n",
    "    return decode(idx[0].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36709c59",
   "metadata": {
    "id": "36709c59"
   },
   "source": [
    "## Compare Generate vs GenerateV2\n",
    "\n",
    "Add your comments and findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "076f9e0f",
   "metadata": {
    "id": "076f9e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== EXPERIMENTO 1 ==========\n",
      "Params: {'strategy': 'greedy', 'temperature': 0.7, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is your sint me his 'tiutr tars umons din wanbl slycergisy, sit havecat bee coms,\n",
      "A she bulf hincom thay lo\n",
      "\n",
      "GenerateV2: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "========== EXPERIMENTO 2 ==========\n",
      "Params: {'strategy': 'greedy', 'temperature': 1.0, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is yourst\n",
      "Thimy po, wanef your eom, buld\n",
      "Ase, asie benf if boove-\n",
      "Wheanspite fanthe stist ean and; ditsoy b\n",
      "\n",
      "GenerateV2: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "========== EXPERIMENTO 3 ==========\n",
      "Params: {'strategy': 'greedy', 'temperature': 1.3, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is your mare ther cliveef lence!\n",
      "\n",
      "Cit wers theill ith You at dill youre lat-igh s dim. The:\n",
      "I'st talo naver\n",
      "\n",
      "GenerateV2: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "========== EXPERIMENTO 4 ==========\n",
      "Params: {'strategy': 'temperature', 'temperature': 0.7, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is yourse thepeans, wif ut: iny, your to artmeh the ar, rond cim: aneme thaly youre\n",
      "He thdeang wore wow bes\n",
      "\n",
      "GenerateV2: How is your ins, pearten prakl own the lade hime nown ferstll cond sase ange dent and wher I pead.\n",
      "\n",
      "\n",
      "MENENUS:\n",
      "C\n",
      "\n",
      "========== EXPERIMENTO 5 ==========\n",
      "Params: {'strategy': 'temperature', 'temperature': 1.0, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is your hresens ayst herot my.\n",
      "\n",
      "Thint!--nou haple thig wheirvelp Con fno a yourcet plids theoncom pthe cobe\n",
      "\n",
      "GenerateV2: How is your urents rim-veve Orang\n",
      "Ost bol swin ouse vown gay, bued\n",
      "Sere ha le nownounge leavert's yat, not whou\n",
      "\n",
      "========== EXPERIMENTO 6 ==========\n",
      "Params: {'strategy': 'temperature', 'temperature': 1.3, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is yoursd the hela whas forme in\n",
      "Yone god the d rauld homr gralc?\n",
      "\n",
      "Four you. Wit Ref hailing's.\n",
      "\n",
      "You god yo\n",
      "\n",
      "GenerateV2: How is your widike arunten Sos.\n",
      "\n",
      "Yu COMORIOLORIO:\n",
      "\n",
      "Sobr Libly, ped, angor thatts nonee\n",
      "y mat wo thent ete doofi\n",
      "\n",
      "========== EXPERIMENTO 7 ==========\n",
      "Params: {'strategy': 'top-k', 'temperature': 1.0, 'top_k': 3, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is your case anged oly beer thom;\n",
      "Core cory atang eferck, les inbles oms\n",
      "Prud ato mot week cinge hay in hal\n",
      "\n",
      "GenerateV2: How is yours the thin har wing here are and than ther than at the shater ate this the son wis se ange theres to\n",
      "\n",
      "========== EXPERIMENTO 8 ==========\n",
      "Params: {'strategy': 'top-k', 'temperature': 1.0, 'top_k': 5, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is yours; the banur. uppowes:\n",
      "\n",
      "Nof gore porem gonene yous tha-\n",
      "And Iadi ad to Amy for hem be,\n",
      "Four. CIOLNed\n",
      "\n",
      "GenerateV2: How is your atind aten whes wire wor woulds.\n",
      "\n",
      "SIUTUS:\n",
      "I show her he wirell sald heand as thart thom thingers at\n",
      "\n",
      "========== EXPERIMENTO 9 ==========\n",
      "Params: {'strategy': 'top-k', 'temperature': 1.0, 'top_k': 9, 'top_p': None}\n",
      "\n",
      "GenerateV1: How is yourd bipuende, bueced; one'e 't, hascts!\n",
      "\n",
      "The Iind sitil wit ben his you--on tars.\n",
      "\n",
      "VINIA:\n",
      "Jrd you mave\n",
      "\n",
      "GenerateV2: How is your shase boodiss, splang ote shitthe ongow ant\n",
      "We stell own sow thichs aser botthend shoun st bugeing \n",
      "\n",
      "========== EXPERIMENTO 10 ==========\n",
      "Params: {'strategy': 'top-p', 'temperature': 1.0, 'top_k': None, 'top_p': 0.3}\n",
      "\n",
      "GenerateV1: How is yours you wey, hamou hen youengu on ane to swathe miolve, pas the troe thart ores:\n",
      "I filliow him; ther i\n",
      "\n",
      "GenerateV2: How is your the the the and the the with the the the sthe the and the the the at the and the the the the the th\n",
      "\n",
      "========== EXPERIMENTO 11 ==========\n",
      "Params: {'strategy': 'top-p', 'temperature': 1.0, 'top_k': None, 'top_p': 0.6}\n",
      "\n",
      "GenerateV1: How is youre fou ser haneis st ies mpongnchat\n",
      "Wth yous, ged'esu, sereall tonceeld\n",
      "Hes kn werere me thous, oth M\n",
      "\n",
      "GenerateV2: How is your at forer the ind thatit wo whan mald wons but will wous owerters, sther theas,\n",
      "An om wis will the h\n",
      "\n",
      "========== EXPERIMENTO 12 ==========\n",
      "Params: {'strategy': 'top-p', 'temperature': 1.0, 'top_k': None, 'top_p': 0.9}\n",
      "\n",
      "GenerateV1: How is yourme for\n",
      "y fur tor tone suld lit\n",
      "mye I uged Of to sarrtis I whealve.\n",
      "\n",
      "You the the u mo eay,\n",
      "Whis, wise\n",
      "\n",
      "GenerateV2: How is youre thou.\n",
      "\n",
      "MICIOMINIUS:\n",
      "Sers wher nour chat, the lit hevere bak, ifened puon, peareaik\n",
      "Wh dickn oon be\n"
     ]
    }
   ],
   "source": [
    "Text_ = \"How is your\"\n",
    "\n",
    "# Lista de configuraciones a probar\n",
    "param_grid = [\n",
    "    {\"strategy\": \"greedy\", \"temperature\": 0.7, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"greedy\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"greedy\", \"temperature\": 1.3, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"temperature\", \"temperature\": 0.7, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"temperature\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"temperature\", \"temperature\": 1.3, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"top-k\", \"temperature\": 1.0, \"top_k\": 3, \"top_p\": None},\n",
    "    {\"strategy\": \"top-k\", \"temperature\": 1.0, \"top_k\": 5, \"top_p\": None},\n",
    "    {\"strategy\": \"top-k\", \"temperature\": 1.0, \"top_k\": 9, \"top_p\": None},\n",
    "    {\"strategy\": \"top-p\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": 0.3},\n",
    "    {\"strategy\": \"top-p\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": 0.6},\n",
    "    {\"strategy\": \"top-p\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": 0.9},\n",
    "]\n",
    "\n",
    "# Loop de experimentación\n",
    "for i, params in enumerate(param_grid, 1):\n",
    "    print(f\"\\n========== EXPERIMENTO {i} ==========\")\n",
    "    print(f\"Params: {params}\")\n",
    "\n",
    "    # Generación con el modelo base\n",
    "    result_1 = generate(\n",
    "        Text_,\n",
    "        max_new_tokens=100,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "    # Generación con generate_V2 y los parámetros actuales\n",
    "    result_2 = generate_V2(\n",
    "        Text_,\n",
    "        max_new_tokens=100,\n",
    "        use_cache=True,\n",
    "        strategy=params[\"strategy\"],\n",
    "        temperature=params[\"temperature\"],\n",
    "        top_k=params[\"top_k\"],\n",
    "        top_p=params[\"top_p\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nGenerateV1:\", result_1)\n",
    "    print(\"\\nGenerateV2:\", result_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2n-DBqhhq4MV",
   "metadata": {
    "id": "2n-DBqhhq4MV"
   },
   "source": [
    "## CONCLUSIONES:\n",
    "\n",
    "Luego de efectuar una evaluación del efecto de los parámetros en la generación de texto, se puede verificar lo siguiente:\n",
    "\n",
    "GenerateV1 parece más robusto frente al colapso repetitivo, aunque sus salidas carecen de coherencia semántica y corresponden a un modelo menos afinado.\n",
    "\n",
    "GenerateV2, en cambio, es muy sensible a la estrategia: con greedy colapsa, pero con top-k y especialmente con top-p logra producir secuencias más variadas y con mayor potencial gramatical.\n",
    "\n",
    "Los parámetros de temperatura y estrategia de muestreo tienen un impacto crítico y evidente:\n",
    "\n",
    "Temperatura baja → más control pero mayor riesgo de repetición.\n",
    "\n",
    "Temperatura alta → mayor diversidad pero mayor incoherencia.\n",
    "\n",
    "Top-p y top-k → balancean entre diversidad y coherencia, siendo top-p con valores intermedios (0.6–0.9) el escenario más prometedor para evitar colapso y repetición excesiva.\n",
    "\n",
    "Los parámetros intrucidos permiten efectuar ajustes a la capacidad del modelo de generar texto, pero aún lejos de lo pretendido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f07ffc1",
   "metadata": {
    "id": "9f07ffc1"
   },
   "source": [
    "## Task II\n",
    "- Make TinyGPT a Mixture of Experts (MoE) of at least 2 experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac0b57f2",
   "metadata": {
    "id": "ac0b57f2"
   },
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    \"\"\"\n",
    "    An expert MLP instance from within a MoE.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,config:GPTConfig) -> None:\n",
    "        \"\"\"\n",
    "        Initiates expert MLP given dimensions/hidden dimensions.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "            nn.Dropout(config.dropout)\n",
    "        ) ## Example network\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    \"\"\"\n",
    "    MoE gating network MLP.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(config.n_embd, config.moe_args.num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f606f6f",
   "metadata": {
    "id": "1f606f6f"
   },
   "outputs": [],
   "source": [
    "class MoELayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture of experts FeedForward Layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, experts : List[nn.Module], gate : nn.Module, moe_args : MoEArgs):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList(experts)\n",
    "        self.gate = gate\n",
    "        self.args = moe_args\n",
    "\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor: # IMPLEMENTADA POR FEDE\n",
    "        B, T, D = x.shape  # Batch, Time, Dimensión\n",
    "        x_flat = x.view(B * T, D)  # (B*T, D)\n",
    "\n",
    "        # 1. Gating - produce scores para cada experto\n",
    "        gate_scores = self.gate(x_flat)  # (B*T, N_experts)\n",
    "\n",
    "        # 2. Top-k selección\n",
    "        topk_vals, topk_indices = torch.topk(gate_scores, k=self.args.top_k, dim=-1)  # (B*T, k)\n",
    "        topk_weights = F.softmax(topk_vals, dim=-1)  # pesos normalizados\n",
    "\n",
    "        # 3. Crear salida vacía\n",
    "        output = torch.zeros_like(x_flat)  # (B*T, D)\n",
    "\n",
    "        # 4. Enrutar a cada experto\n",
    "        for i in range(self.args.top_k):\n",
    "            expert_idx = topk_indices[:, i]  # índice del experto para cada token\n",
    "            weight = topk_weights[:, i].unsqueeze(1)  # (B*T, 1)\n",
    "\n",
    "            for e in range(len(self.experts)):\n",
    "                mask = (expert_idx == e)  # tokens que van al experto `e`\n",
    "                if mask.any():\n",
    "                    selected_x = x_flat[mask]  # entradas seleccionadas\n",
    "                    y = self.experts[e](selected_x)  # salida del experto\n",
    "                    output[mask] += weight[mask] * y  # acumulamos con su peso\n",
    "\n",
    "        # 5. Restaurar forma original\n",
    "        return output.view(B, T, D)\n",
    "        return None #FEDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4507fcd8",
   "metadata": {
    "id": "4507fcd8"
   },
   "outputs": [],
   "source": [
    "class MoEFFN(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.moe = MoELayer(\n",
    "            #experts=[Expert(config) for _ in range(config.moe_args.num_experts)], FEDERICO\n",
    "            experts=[Expert(config) for _ in range(config.moe_args.num_experts)],\n",
    "            gate=Gate(config),\n",
    "            #moe_args=config.moe_args FEDERICO\n",
    "            moe_args=config.moe_args\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.moe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dJCjQniOr-TC",
   "metadata": {
    "id": "dJCjQniOr-TC"
   },
   "source": [
    "## Adding MoE to Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7077f76b",
   "metadata": {
    "id": "7077f76b"
   },
   "outputs": [],
   "source": [
    "config.ff_class = MoEFFN\n",
    "config.moe_args = MoEArgs(num_experts=4, num_experts_per_token=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5505e231",
   "metadata": {
    "id": "5505e231"
   },
   "outputs": [],
   "source": [
    "# Nuevo codigo FEDE\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Construye el bloque Transformer uniendo los componentes Lay&Norm - FFN / MoE - Multi-Head Attention Block \"\"\"\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = MultiHeadAttention(config)\n",
    "        # Lógica para elegir entre FFN estándar y MoE\n",
    "        self.ff = config.ff_class(config) if config.moe_args is not None else FeedForward(config)\n",
    "\n",
    "    def forward(self, x, kv_cache=None, return_weights=False):\n",
    "        attn_out = self.attn(self.ln1(x), kv_cache=kv_cache, return_weights=return_weights)\n",
    "        if return_weights:\n",
    "            attn_out, weights = attn_out\n",
    "        else:\n",
    "            weights = None\n",
    "\n",
    "        if isinstance(attn_out, tuple):\n",
    "            attn_out, updated_kv = attn_out\n",
    "        else:\n",
    "            updated_kv = None\n",
    "\n",
    "        x = x + attn_out\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "\n",
    "        return (x, updated_kv, weights) if return_weights else (x, updated_kv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iMKvmdxYrcDn",
   "metadata": {
    "id": "iMKvmdxYrcDn"
   },
   "source": [
    "# Training TinyGPT-MoE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "FJIDVc0KrpEM",
   "metadata": {
    "id": "FJIDVc0KrpEM"
   },
   "outputs": [],
   "source": [
    "m_moe = TinyGPT(config).to(device)\n",
    "model_moe = torch.compile(m_moe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "762a7e42",
   "metadata": {
    "id": "762a7e42"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model_moe.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=100, gamma=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2xz2uaMvrrAW",
   "metadata": {
    "id": "2xz2uaMvrrAW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13496 [00:00<?, ?it/s]W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/2815764454.py line 12 \n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 657, in wrapper\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return handle_graph_break(self, inst, speculation.reason)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 698, in handle_graph_break\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(self, reason=reason)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 657, in wrapper\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return handle_graph_break(self, inst, speculation.reason)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 698, in handle_graph_break\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(self, reason=reason)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1136, in compile_subgraph\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 21:26:13.259000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/2740146290.py line 31 \n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1968, in codegen\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3477, in codegen\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self._codegen()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3567, in _codegen\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     if device is not None and self.get_backend(device).ready_to_flush():\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1968, in codegen\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3477, in codegen\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     return self._codegen()\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3567, in _codegen\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     if device is not None and self.get_backend(device).ready_to_flush():\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 21:26:13.468000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /tmp/ipykernel_87778/2740146290.py line 18 \n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]   File \"/home/federico/ClasesIA/CEIA-IA/lib/python3.12/site-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found NVIDIA GeForce GTX 970 which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 5.2\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0816 21:26:13.731000 87778 torch/_dynamo/convert_frame.py:1233] \n",
      "loss 2.01916: 100%|██████████| 13496/13496 [07:42<00:00, 29.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training loss: 2.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:18<00:00, 78.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.09877: 100%|██████████| 13496/13496 [07:33<00:00, 29.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 training loss: 2.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:18<00:00, 78.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 1.99572: 100%|██████████| 13496/13496 [07:33<00:00, 29.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 training loss: 2.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 78.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.01397: 100%|██████████| 13496/13496 [07:33<00:00, 29.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 training loss: 1.9833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:18<00:00, 78.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.01346: 100%|██████████| 13496/13496 [07:32<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 training loss: 1.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 78.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.05699: 100%|██████████| 13496/13496 [07:54<00:00, 28.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 training loss: 2.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:20<00:00, 71.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.01515: 100%|██████████| 13496/13496 [07:54<00:00, 28.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 training loss: 2.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:20<00:00, 72.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.01487: 100%|██████████| 13496/13496 [07:40<00:00, 29.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 training loss: 2.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:20<00:00, 74.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.01522: 100%|██████████| 13496/13496 [07:39<00:00, 29.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 training loss: 2.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 75.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.08270: 100%|██████████| 13496/13496 [07:40<00:00, 29.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 training loss: 2.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 75.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.07318: 100%|██████████| 13496/13496 [07:39<00:00, 29.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 training loss: 2.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 74.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.05417: 100%|██████████| 13496/13496 [07:39<00:00, 29.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 training loss: 2.0512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 75.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.03655: 100%|██████████| 13496/13496 [07:39<00:00, 29.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 training loss: 2.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 75.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.07345: 100%|██████████| 13496/13496 [07:39<00:00, 29.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 training loss: 2.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 74.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 1.99217: 100%|██████████| 13496/13496 [07:39<00:00, 29.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 training loss: 2.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 74.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.11508: 100%|██████████| 13496/13496 [07:39<00:00, 29.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 training loss: 2.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 75.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.06521: 100%|██████████| 13496/13496 [07:40<00:00, 29.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 training loss: 2.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 74.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.01461: 100%|██████████| 13496/13496 [07:41<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 training loss: 2.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:19<00:00, 75.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.07320: 100%|██████████| 13496/13496 [08:04<00:00, 27.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 training loss: 2.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:20<00:00, 71.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 validation loss: 2.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 2.03875: 100%|██████████| 13496/13496 [08:00<00:00, 28.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 training loss: 1.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss 1.67844: 100%|██████████| 1496/1496 [00:22<00:00, 67.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 validation loss: 2.0799\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model_moe,\n",
    "    train_data_loader=train_loader,\n",
    "    test_data_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    save_dir=\"./checkpoints\",\n",
    "    save_every_n=500\n",
    ")\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    #avg_train_loss = trainer.train_model_v2(use_amp=True, dtype=torch.bfloat16)\n",
    "    avg_train_loss = trainer.train_model_v2(use_amp=True, dtype=torch.float32 )\n",
    "    print(f\"Epoch {epoch+1} training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    val_loss = trainer.eval_model()\n",
    "    print(f\"Epoch {epoch+1} validation loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e4b4aa",
   "metadata": {
    "id": "e7e4b4aa"
   },
   "source": [
    "## Visualizing Attention\n",
    "\n",
    "As we know, a GPT has the task to complete text, let's see the attention maps generated by a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c08536d8",
   "metadata": {
    "id": "c08536d8"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_attention(model, prompt, max_len=10):\n",
    "    model.eval()\n",
    "    idx = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "\n",
    "    # Run forward with return_weights=True\n",
    "    logits, all_weights = model(idx, return_weights=True)\n",
    "\n",
    "    # all_weights is a list of length n_layers\n",
    "    # each element: shape (n_heads, batch_size, seq_len, seq_len)\n",
    "    # We'll visualize the first batch element only\n",
    "\n",
    "    n_layers = len(all_weights)\n",
    "    n_heads = all_weights[0].shape[0]\n",
    "    seq_len = all_weights[0].shape[-1]\n",
    "\n",
    "    for layer_i in range(n_layers):\n",
    "        fig, axes = plt.subplots(1, n_heads, figsize=(5 * n_heads, 5))\n",
    "        if n_heads == 1:\n",
    "            axes = [axes]\n",
    "        for head_i in range(n_heads):\n",
    "            attn = all_weights[layer_i][head_i, 0].cpu()  # shape (seq_len, seq_len)\n",
    "            im = axes[head_i].imshow(attn, cmap='viridis')\n",
    "            axes[head_i].set_title(f'Layer {layer_i + 1} Head {head_i + 1}')\n",
    "            axes[head_i].set_xlabel('Key Position')\n",
    "            axes[head_i].set_ylabel('Query Position')\n",
    "            axes[head_i].set_xticks(range(seq_len))\n",
    "            axes[head_i].set_yticks(range(seq_len))\n",
    "            fig.colorbar(im, ax=axes[head_i])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C2rpVv-OpUgy",
   "metadata": {
    "id": "C2rpVv-OpUgy"
   },
   "source": [
    "## Simple Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83a8993c",
   "metadata": {
    "id": "83a8993c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x500 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x500 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"How is your\"\n",
    "visualize_attention(model, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvAz_Gs2gu7i",
   "metadata": {
    "id": "OvAz_Gs2gu7i"
   },
   "source": [
    "## MoE Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "FziUh9xzgTog",
   "metadata": {
    "id": "FziUh9xzgTog"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAD4kAAAHqCAYAAACjy5lPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAtpVJREFUeJzs3XmYXFWB//9PdUKaAElYE7ZAQEQWQRGEQdTRAURFEIZxgcjmNgiRJY4LboCKUX8D4saisowCCi4wjiIMZliGbUAcVEQQkSUCCSCQkCBJ6K7fH5F87UmC3elbdet0vV7Pcx/t6qp7TjWQd/p0n3sbzWazGQAAAAAAAAAAAAAAAAAAAIrQU/cEAAAAAAAAAAAAAAAAAAAAGDybxAEAAAAAAAAAAAAAAAAAAApikzgAAAAAAAAAAAAAAAAAAEBBbBIHAAAAAAAAAAAAAAAAAAAoiE3iAAAAAAAAAAAAAAAAAAAABbFJHAAAAAAAAAAAAAAAAAAAoCA2iQMAAAAAAAAAAAAAAAAAABTEJnEAAAAAAAAAAAAAAAAAAICC2CQOAAAAAAAAAAAAAAAAAABQEJvEAQAAAAAAAAAAAAAAAAAACmKTOAAMwrXXXpt99tknG264YRqNRi699NK/+Zqrr746L3vZy9Lb25stttgi5513XsvnCQAsn5YDQLl0HADKpeMAUC4dB4By6TgAlEvHAaBcdXXcJnEAGIQFCxbkJS95Sb72ta8N6vn33ntv9t5777z2ta/NbbfdlmOPPTbvfve7c8UVV7R4pgDA8mg5AJRLxwGgXDoOAOXScQAol44DQLl0HADKVVfHG81ms7kyEwaAbtVoNHLJJZdkv/32W+FzPvzhD+cnP/lJbr/99qWPvf3tb8+TTz6Zyy+/vA2zBABWRMsBoFw6DgDl0nEAKJeOA0C5dBwAyqXjAFCudnbcncQBoAVuvPHG7LHHHgMe22uvvXLjjTfWNCMAYCi0HADKpeMAUC4dB4By6TgAlEvHAaBcOg4A5aqq46OrnBQAVO2ZZ57JokWLWnLuZrOZRqMx4LHe3t709vYO+9yzZ8/OpEmTBjw2adKkzJs3L3/+858zduzYYY8BACVoVctb2fFEywEg0XEAKJm1dQAol44DQLl0HADKpeMAUK5u77hN4gB0rGeeeSabbbpGZj/S15Lzr7HGGpk/f/6Ax0444YSceOKJLRkPALpNK1uu4wDQWjoOAOWytg4A5dJxACiXjgNAuXQcAMql4zaJA9DBFi1alNmP9OXeWzfN+HE9lZ573lP92WzH+zNr1qyMHz9+6eNV3bVs/fXXz5w5cwY8NmfOnIwfP94V2QDoGq1qeas7nmg5AOg4AJTL2joAlEvHAaBcOg4A5dJxACiXjtskDkABxo/rqTzUS889fvyAUFdl1113zWWXXTbgsSuvvDK77rpr5WMBQKdrVctb1fFEywHgOToOAOWytg4A5dJxACiXjgNAuXQcAMrVzR1vzbsGgAr1NftbcgzF/Pnzc9ttt+W2225Lktx777257bbb8sADDyRJjj/++BxyyCFLn3/EEUfkD3/4Qz70oQ/lzjvvzOmnn56LL744xx13XGVfFwAoRd0dT7QcAFaWjgNAuaytA0C5dBwAyqXjAFAuHQeAcnVzx20SB4BB+PnPf54ddtghO+ywQ5Jk+vTp2WGHHfLJT34ySfLwww8vjXaSbLbZZvnJT36SK6+8Mi95yUtyyimn5Jvf/Gb22muvWuYPAN1OywGgXDoOAOXScQAol44DQLl0HADKpeMAUK66Ot5oNpvN6t4GAFRn3rx5mTBhQmbftUnGj6v2uibznurP+i96IHPnzs348eMrPTcAsESrWq7jANB6Og4A5bK2DgDl0nEAKJeOA0C5dBwAyqXj7iQOAAAAAAAAAAAAAAAAAABQlNF1TwAA/pb+9Ke/BecEANqj6pbrOAC0j44DQLmsrQNAuXQcAMql4wBQLh0HgHJ1c8dtEgeg4/U1m+lrNis/JwDQHlW3XMcBoH10HADKZW0dAMql4wBQLh0HgHLpOACUq5s73lP3BAAAAAAAAAAAAAAAAAAAABg8dxIHoOP1p5n+VHv1larPBwCsWNUt13EAaB8dB4ByWVsHgHLpOACUS8cBoFw6DgDl6uaOu5M4AAAAAAAAAAAAAAAAAABAQdxJHICO159m+rr0ai4AMBJU3XIdB4D20XEAKJe1dQAol44DQLl0HADKpeMAUK5u7rg7iQMAAAAAAAAAAAAAAAAAABTEncQB6Hj9aVZ+9ZVSruYCACNB1S3XcQBoHx0HgHJZWweAcuk4AJRLxwGgXDoOAOXq5o67kzgAAAAAAAAAAAAAAAAAAEBB3EkcgI7X12ymr1nt1VeqPh8AsGJVt1zHAaB9dBwAymVtHQDKpeMAUC4dB4By6TgAlKubO26TOAAdr/8vR9XnBADao+qW6zgAtI+OA0C5rK0DQLl0HADKpeMAUC4dB4BydXPHe+qeAAAAAAAAAAAAAAAAAAAAAIPnTuIAdLy+NNOXZuXnBADao+qW6zgAtI+OA0C5rK0DQLl0HADKpeMAUC4dB4BydXPH3UkcAAAAAAAAAAAAAAAAAACgIO4kDkDH62suOao+JwDQHlW3XMcBoH10HADKZW0dAMql4wBQLh0HgHLpOACUq5s77k7iAAAAAAAAAAAAAAAAAAAABXEncQA6Xv9fjqrPCQC0R9Ut13EAaB8dB4ByWVsHgHLpOACUS8cBoFw6DgDl6uaO2yQOQMfrTyN9aVR+TgCgPapuuY4DQPvoOACUy9o6AJRLxwGgXDoOAOXScQAoVzd3vKfuCQAAAAAAAAAAAAAAAAAAADB47iQOQMfrby45qj4nANAeVbdcxwGgfXQcAMplbR0AyqXjAFAuHQeAcuk4AJSrmzvuTuIAAAAAAAAAAAAAAAAAAAAFcSdxADpeXxrpS6PycwIA7VF1y3UcANpHxwGgXNbWAaBcOg4A5dJxACiXjgNAubq54+4kDgAAAAAAAAAAAAAAAAAAUBB3Egeg43Xz1VwAYCRwB1IAKJeOA0C5rK0DQLl0HADKpeMAUC4dB4BydXPH3UkcGLb77rsvjUYj5513Xt1TAQBWgpYDQLl0HADKpeMAUC4dB4By6TgAlEvHAaBcOg6tY5M4He28885Lo9HIz3/+87qnUombb745Rx55ZHbcccesssoqaTSGdjWJKVOm5E1vetNyP3f11Ven0Wjk+9//fhVTbZmTTz45++67byZNmpRGo5ETTzyx7ilRgP5moyUH0HpaPlDpLb/zzjvzoQ99KC996Uszbty4bLDBBtl7771HzD9fWkfHoUw6PlDpHX/ooYfyjne8Iy960Ysybty4rLnmmtl5553zb//2b2k2m3VPjw6m41AmHR+o9I7/XxdccEEajUbWWGONuqdCh7O2DmXS8YFK7/hzv/S2vOO73/1u3dOjg+k4lEnHByq948+55557ctBBB2XixIkZO3ZsXvjCF+ZjH/tY3dOig+k4lEnHByq94yeeeOIKvx9vNBq5/vrr654iHUrHoUw6PlDpHU+Shx9+OO9973uz2WabZezYsXnBC16Q6dOn509/+lPdU6ODdXPHR9c9Aegml112Wb75zW9m++23z+abb57f/e53dU+p7T7+8Y9n/fXXzw477JArrrii7ulQiL400pdqw1r1+YDu0O0t/+Y3v5mzzz47BxxwQI488sjMnTs3Z511Vv7u7/4ul19+efbYY4+6p0iHqrrlOg6sjG7v+GOPPZY//vGP+ad/+qdssskmWbx4ca688socdthhueuuu/LZz3627inSoXQc6ATd3vG/Nn/+/HzoQx/K6quvXvdUKIC1daAT6PgSBx54YN74xjcOeGzXXXetaTaUQMeBTqDjyW233ZbXvOY12WijjfKBD3wg66yzTh544IHMmjWr7qnRwXQc6ATd3vF//Md/zBZbbLHM4x/96Eczf/78vPzlL69hVpRAx4FO0O0dnz9/fnbdddcsWLAgRx55ZCZPnpxf/vKX+epXv5qrrroqt956a3p63DeZZXVzx20Shwr19/dn0aJFWXXVVZf7+fe973358Ic/nLFjx2batGldF+okuffeezNlypQ89thjWW+99eqeDgAMoOXP78ADD8yJJ5444E5l73znO7P11lvnxBNPtEkcgFrp+PPbfvvtc/XVVw94bNq0adlnn33y5S9/OZ/+9KczatSoeiYHQNfT8cH7zGc+k3HjxuW1r31tLr300rqnAwA6Pkgve9nL8o53vKPuaQDAADr+/Pr7+3PwwQdnq622ylVXXZWxY8fWPSUAWErHn9/222+f7bfffsBjs2bNyh//+Me8+93vzpgxY2qaGQDo+N/yox/9KPfff39+/OMfZ++99176+Nprr51PfepT+eUvf5kddtihxhlC53HZBIq3aNGifPKTn8yOO+6YCRMmZPXVV8+rXvWqXHXVVUuf02w2M2XKlLz5zW9e5vXPPPNMJkyYkH/+539e+tjChQtzwgknZIsttkhvb28mT56cD33oQ1m4cOGA1zYajUybNi0XXHBBtt122/T29ubyyy9f4VwnTZrU9sXiBx98MO985zszadKk9Pb2Ztttt80555wz4DmD+Ro+58knn8xhhx2WCRMmZM0118yhhx6aJ598ctDzmTJlyjDfEd2oLz0tOYDOoOXPr5NavuOOOw7YIJ4k66yzTl71qlflt7/97Uq/R0Y+HYeRS8efXyd1fEWmTJmSp59+OosWLRrWeRi5dBxGLh1/fp3Y8bvvvjtf/OIXc+qpp2b0aNeB5m+ztg4jl44/v07seJIsWLDA998Mmo7DyKXjz6+TOv6f//mfuf3223PCCSdk7Nixefrpp9PX11fF22SE03EYuXT8+XVSx5fnO9/5TprNZqZOnbrS52Dk03EYuXT8+XVSx+fNm5dkydfhr22wwQZJ4iJurFA3d9xvkFC8efPm5Zvf/GYOPPDAvOc978lTTz2Vs88+O3vttVduvvnmvPSlL02j0cg73vGOfOELX8jjjz+etddee+nr/+M//iPz5s1betXu/v7+7Lvvvrnuuuvy3ve+N1tvvXV+/etf54tf/GJ+97vfLXNnjv/6r//KxRdfnGnTpmXddddt+SboxYsX57HHHlvm8blz5y7z2Jw5c/J3f/d3S/9Csd566+WnP/1p3vWud2XevHk59thjkwzua5gs+QvPm9/85lx33XU54ogjsvXWW+eSSy7JoYce2sq3DMAIp+VLlNzy2bNnZ9111x3WOQAok44vUVLH//znP2fBggWZP39+rrnmmpx77rnZddddLZ4DdCEdX6Kkjh977LF57Wtfmze+8Y25+OKLh/w1AGDk0PElSur4SSedlA9+8INpNBrZcccdc/LJJ+d1r3vdkL8WAJRPx5cooeM/+9nPkiS9vb3Zaaedcuutt2bMmDHZf//9c/rppw/45wJAd9DxJUro+PJccMEFmTx5cl796lev9DkAKJeOL1FCx1/96lenp6cnxxxzTE455ZRsvPHG+dWvfpWTTz45++23X7baaquV/rrAiNWEDnbuuec2kzRvueWWFT7n2WefbS5cuHDAY0888URz0qRJzXe+851LH7vrrruaSZpnnHHGgOfuu+++zSlTpjT7+/ubzWaz+e1vf7vZ09PT/O///u8BzzvzzDObSZrXX3/90seSNHt6epq/+c1vhvzejjrqqOZQ/xPcdNNNm0me9/je97639Pnvete7mhtssEHzscceG3Cet7/97c0JEyY0n3766WazOfiv4aWXXtpM0vzCF76w9LFnn322+apXvaqZpHnuuecO+r08+uijzSTNE044YQhfAbrN3Llzm0maM3+9SfOm+6ZUesz89SbNJM25c+fW/TZhRNPygUZSy59z7bXXNhuNRvMTn/jEkF/LyNeqlus4tIeODzRSOj5jxowBc959992bDzzwwJC+FnQHHYey6fhAI6HjP/7xj5ujR49e+jU79NBDm6uvvvqQvg50D2vrUDYdH6j0jt9///3N173udc0zzjij+aMf/ah52mmnNTfZZJNmT09P88c//vGQvhZ0Bx2Hsun4QKV3fN99920maa6zzjrNqVOnNr///e83P/GJTzRHjx7dfMUrXrH0nwE8R8ehbDo+UOkd/79uv/32ZpLmhz70oSG9ju6h41A2HR9oJHT8m9/8ZnPNNdccMOdDDz20uXjx4iF9LegOOt5slnG/c3geo0aNypgxY5IsuRLL448/nmeffTY77bRTfvGLXyx93pZbbplddtklF1xwwdLHHn/88fz0pz/N1KlT02g0kiTf+973svXWW2errbbKY489tvT4h3/4hyTJVVddNWD8v//7v88222zT6re51C677JIrr7xymeNf//VfBzyv2WzmBz/4QfbZZ580m80B72WvvfbK3Llzl359Bvs1vOyyyzJ69Oi8733vW/rYqFGj8v73v78N7xyAkUrLy235I488koMOOiibbbZZPvShD63UOQAom46X1/EDDzwwV155ZS688MIcdNBBSZbcXRyA7qPj5XR80aJFOe6443LEEUe09WsGQOfS8XI6vskmm+SKK67IEUcckX322SfHHHNM/vd//zfrrbdePvCBDwz3SwNAgXS8nI7Pnz8/SfLyl788559/fg444IB86lOfyqc//enccMMNmTlz5rC+NgCUR8fL6fj/9dw/i6lTp67U6wEon46X1fGNNtooO++8c0477bRccsklmT59ei644IJ85CMfGc6XBUas0XVPAKrwb//2bznllFNy5513ZvHixUsf32yzzQY875BDDsm0adNy//33Z9NNN833vve9LF68OAcffPDS59x999357W9/m/XWW2+5Yz3yyCMDPv6/Y7Tauuuumz322GOZx0ePHvif86OPPponn3wyX//61/P1r399uef66/cymK/h/fffnw022CBrrLHGgPO86EUvWqn3AoPVl0b60qj8nEDn0PLyWr5gwYK86U1vylNPPZXrrrtumXPCX6u65ToOnUXHy+r4pptumk033TTJkg3j733ve7PHHnvkrrvuytixY4d0LrqDjsPIpuNldPyLX/xiHnvssZx00kmDej48x9o6jGw6XkbHl2fttdfO4Ycfns997nP54x//mI033nilz8XIpeMwsul4GR1/bs38wAMPHPD4QQcdlOOPPz433HDDct8b6DiMbDpeRsf/WrPZzIUXXpgXv/jF2X777Yf8erqLjsPIpuNldPz666/Pm970ptx0003ZaaedkiT77bdfxo8fn5NOOinvfOc7XVyd5ermjtskTvHOP//8HHbYYdlvv/3ywQ9+MBMnTsyoUaMyY8aM3HPPPQOe+/a3vz3HHXdcLrjggnz0ox/N+eefn5122mlAaPr7+7Pddtvl1FNPXe54kydPHvBxp/4CdX9/f5LkHe94Rw499NDlPue5b3SH8jWEOvQ1e9LX7Kn4nJWeDhgGLV++Tm75okWL8o//+I/51a9+lSuuuCIvfvGLKx+DkaXqlus4dA4dX75O7vj/9U//9E/5xje+kWuvvTZ77bVXy8ejPDoOI5eOL1+ndXzu3Ln5zGc+kyOPPDLz5s3LvHnzkiy5m1mz2cx9992X1VZbLRMnTqxkPEYWa+swcun48nVax5/Pc1/Txx9/3CZxlkvHYeTS8eXrxI5vuOGGSZJJkyYNePy578GfeOKJysZiZNFxGLl0fPk6seN/7frrr8/999+fGTNmtOT8jCw6DiOXji9fJ3b8rLPOyqRJk5ZuEH/OvvvumxNPPDE33HCDTeIsVzd33CZxivf9738/m2++eX74wx+m0fh/V2c44YQTlnnu2muvnb333jsXXHBBpk6dmuuvvz6nnXbagOe84AUvyC9/+cvsvvvuA85XmvXWWy/jxo1LX1/f37xi6WC/hptuumlmzpyZ+fPnD7iiy1133VXt5AHoKlq+fJ3a8v7+/hxyyCGZOXNmLr744vz93//9oF8LwMij48vXqR1fnj//+c9JlmxAA6C76PjydVrHn3jiicyfPz9f+MIX8oUvfGGZz2+22WZ585vfnEsvvfRvnguAkUPHl6/TOv58/vCHPyydMwDdRceXrxM7vuOOO+Yb3/hGHnzwwQGPP/TQQ0vnDEB30fHl68SO/7ULLrggjUYjBx100JBfC8DIoePL14kdnzNnTvr6+pZ5/Lk7lz/77LODOg90k2q3xkMNRo0alSRpNv/fpRn+53/+JzfeeONyn3/wwQfnjjvuyAc/+MGMGjUqb3/72wd8/q1vfWsefPDBfOMb31jmtX/+85+zYMGCCmffOqNGjcoBBxyQH/zgB7n99tuX+fyjjz464LnJ3/4avvGNb8yzzz6bM844Y+ljfX19+cpXvlL19GGA/jTSn56Kj3L/Ig4jjZYvX6e2/P3vf38uuuiinH766fnHf/zHQb+O7lZ9y3UcOoWOL18ndvyvx/xrZ599dhqNRl72spcN6jx0Hx2HkUvHl6/TOj5x4sRccsklyxyvfe1rs+qqq+aSSy7J8ccfP+T3SXewtg4jl44vX6d1/P+O+ZwHH3ww55xzTrbffvtssMEGgzoP3UfHYeTS8eXrxI6/+c1vTm9vb84999yld1ZLkm9+85tJkj333HNQ56H76DiMXDq+fJ3Y8ecsXrw43/ve9/LKV74ym2yyyZBeS3fScRi5dHz5OrHjW265ZebMmZOrr756wOPf+c53kiQ77LDDoM5D9+nmjruTOEU455xzcvnlly/z+DHHHJM3velN+eEPf5j9998/e++9d+69996ceeaZ2WabbTJ//vxlXrP33ntnnXXWyfe+97284Q1vyMSJEwd8/uCDD87FF1+cI444IldddVV222239PX15c4778zFF1+cK664IjvttNNKvY/7778/3/72t5MkP//5z5Mkn/nMZ5IsuVLKwQcfvFLnXZHPfe5zueqqq7LLLrvkPe95T7bZZps8/vjj+cUvfpGf/exnefzxx5Nk0F/DffbZJ7vttls+8pGP5L777ss222yTH/7wh0O629i3v/3t3H///Xn66aeTJNdee+3Sr8HBBx+cTTfdtMKvAACdQstXTqe1/LTTTsvpp5+eXXfdNauttlrOP//8AZ/ff//9s/rqq1f3BQCgI+j4yum0jp988sm5/vrr8/rXvz6bbLJJHn/88fzgBz/ILbfckve///3ZYostKn3/AHQGHV85ndTx1VZbLfvtt98yj1966aW5+eabl/s5AEYGHV85ndTxJPnQhz6Ue+65J7vvvns23HDD3HfffTnrrLOyYMGCfOlLX6r0vQPQOXR85XRax9dff/187GMfyyc/+cm8/vWvz3777Zdf/vKX+cY3vpEDDzwwL3/5yyt9/wB0Bh1fOZ3W8edcccUV+dOf/pSpU6dW+n4B6Ew6vnI6rePTpk3Lueeem3322Sfvf//7s+mmm+aaa67Jd77zney5557ZZZddKn3/MBLYJE4R/vrqIX/tsMMOy2GHHZbZs2fnrLPOyhVXXJFtttkm559/fr73ve8tc9WQJBkzZkze9ra35fTTT19uGHt6enLppZfmi1/8Yr71rW/lkksuyWqrrZbNN988xxxzTLbccsuVfh/33ntvPvGJTwx47LmP//7v/77yUE+aNCk333xzPvWpT+WHP/xhTj/99KyzzjrZdttt8/nPf37p8wb7Nezp6cmPfvSjHHvssTn//PPTaDSy77775pRTThn0lVjOPvvsXHPNNUs/vuqqq3LVVVclSV75ylfaJM5y9aWRvoqvvlL1+YDnp+Urp9NafttttyVJbrzxxuVeOe/ee++1SZzlqrrlOg7tpeMrp9M6vvfee+eee+7JOeeck0cffTSrrrpqtt9++5x77rk59NBDK33vjCw6DmXT8ZXTaR2HlWVtHcqm4yun0zr+ute9LmeeeWa+9rWv5Yknnsiaa66ZV7/61fn4xz+el73sZZW+d0YWHYey6fjK6bSOJ8nHP/7xrLXWWvnKV76SY489dsDGcVgRHYey6fjK6cSOJ8kFF1yQVVZZJW95y1uqfLuMYDoOZdPxldNpHX/Ri16UW2+9NR//+Mdz/vnnZ/bs2dlwww3zL//yLznppJMqfe+MLN3c8Uaz2WzWPQlot+OOOy5nn312Zs+endVWW63u6QArMG/evEyYMCE/+tULsvq4UZWee8FTfdl3+3syd+7cjB8/vtJzA62n5VCGVrVcx6FsOg5l0HFgeXQcymBtHVgeHYcy6DiwPDoOZdBxYHl0HMqg48Dy6DiUQcfdSZwu9Mwzz+T888/PAQccINJQiL5mT/qaPRWf0zVSoFRaDuWpuuU6DuXScSiPjgPP0XEoj7V14Dk6DuXRceA5Og7l0XHgOToO5dFx4Dk6DuXp5o7bJE7XeOSRR/Kzn/0s3//+9/OnP/0pxxxzTN1TAgCGQMsBoFw6DgDl0nEAKJeOA0C5dBwAyqXjAFAuHQdKZJM4XeOOO+7I1KlTM3HixHz5y1/OS1/60rqnBAxSfxrpT6PycwJl0XIoV9Ut13Eoj45DuXQc0HEol7V1QMehXDoO6DiUS8cBHYdy6Tig41Cubu64TeJ0jde85jVpNpt1TwNYCf3pSV96Kj6nPw+gNFoO5aq65ToO5dFxKJeOAzoO5bK2Dug4lEvHAR2Hcuk4oONQLh0HdBzK1c0dr/ZdAwAAAAAAAAAAAAAAAAAA0FLuJA5Ax+tr9qSvWe11Tfpc3QkA2qbqlus4ALSPjgNAuaytA0C5dBwAyqXjAFAuHQeAcnVzx91JHAAAAAAAAAAAAAAAAAAAoCAj/k7i/f39eeihhzJu3Lg0Go26pwMwYjWbzTz11FPZcMMN09NT7TVI+tOT/oqva9KfMq7m0u10HKA9WtnxpPqW63gZdBygPXScVtBxgPYoreNLzqnlnU7HAdpDx2kVLQdoPR2nVXQcoPV0nFbRcYD2sPesNUb8JvGHHnookydPrnsaAF1j1qxZ2XjjjeueBiOEjgO0l45TJR0HaC8dp0o6DtBeOk6VdBygvXScqmk5QPvoOFXTcYD20XGqpuMA7aXl1Rrxm8THjRuXJLn/F1Myfo3qrxQ0GPtvuV0t4wK007NZnOty2dI/d6vU12ykr1ntFbmqPh+toeMA7dHKjifVt1zHy6DjAO2h47SCjgO0R2kdf+6cdDYdB2gPHadVtByg9XScVtFxgNbTcVpFxwHaw96z1hjxm8QbjSX/IMav0ZPx4+oJ9ejGKrWMC9BWzSX/89yfu1AFHQdoEx2nBXQcoE10nBbQcYA20XFaQMcB2kTHaREtB2gDHadFdBygDXScFtFxgDbR8pYY8ZvEAShfX3rSl2q/2ep77m8WAEDLVd1yHQeA9tFxACiXtXUAKJeOA0C5dBwAyqXjAFCubu64TeIAdLz+Zk/6m9WGur9ZRqgBYCSouuU6DgDto+MAUC5r6wBQLh0HgHLpOACUS8cBoFzd3PFq3zUAAAAAAAAAAAAAAAAAAAAt5U7iAHS8vvSkr+LrmvSljKu5AMBIUHXLdRwA2kfHAaBc1tYBoFw6DgDl0nEAKJeOA0C5urnj7iQOAAAAAAAAAAAAAAAAAABQEHcSB6Dj9SfpazYqPycA0B5Vt1zHAaB9dBwAymVtHQDKpeMAUC4dB4By6TgAlKubO+5O4gAAAAAAAAAAAAAAAAAAAAVxJ3EAOl5/etJf8XVNqj4fALBiVbdcxwGgfXQcAMplbR0AyqXjAFAuHQeAcuk4AJSrmztexCy/9rWvZcqUKVl11VWzyy675Oabb657SgC0UV+zpyUH7aHjAOh42bQcoLvpeNl0HKC7WVsvm44DdDcdL5uOA3Q3HS+bjgN0Nx0vm44DdLdu7njHz/Kiiy7K9OnTc8IJJ+QXv/hFXvKSl2SvvfbKI488UvfUAIC/QccBoGxaDgDl0nEAKJeOA0C5dBwAyqXjAFAuHQegm3X8JvFTTz0173nPe3L44Ydnm222yZlnnpnVVlst55xzTt1TA6BN+tNoyUHr6TgASWtaTntoOQA6Xi4dB8Daerl0HAAdL5eOA6Dj5dJxAHS8XDoOQDd3vKM3iS9atCi33npr9thjj6WP9fT0ZI899siNN9643NcsXLgw8+bNG3AAAO2n4wBQtqG2XMcBoHPoOACUS8cBoFx+Rg4A5dJxACiXjgPQ7Tp6k/hjjz2Wvr6+TJo0acDjkyZNyuzZs5f7mhkzZmTChAlLj8mTJ7djqgC0UF+zpyUHraXjADxHx8s01JbrOMDIpONl0nEAEmvrpdJxABIdL5WfkQOQ6HipdByARMdLpeMAJN3d8TJmOQTHH3985s6du/SYNWtW3VMCAAZJxwGgXDoOAOXScQAol44DQNm0HADKpeMAUC4dB2AkGV33BJ7Puuuum1GjRmXOnDkDHp8zZ07WX3/95b6mt7c3vb297ZgeAG3Sl570VXxdk6rPx7J0HIDnVN1yHW+PobZcxwFGJh0vk44DkFhbL5WOA5DoeKn8jByARMdLpeMAJDpeKh0HIOnujnf0LMeMGZMdd9wxM2fOXPpYf39/Zs6cmV133bXGmQEAf4uOA0DZtBwAyqXjAFAuHQeAcuk4AJRLxwGgXDoOQLfr6DuJJ8n06dNz6KGHZqeddsrOO++c0047LQsWLMjhhx9e99QAaJP+ZiP9zUbl56T1dByApPqW63j7aDkAOl4uHQfA2nq5dBwAHS+XjgOg4+XScQB0vFw6DkA3d7zjN4m/7W1vy6OPPppPfvKTmT17dl760pfm8ssvz6RJk+qeGgBt0p+e9KWn8nPSejoOQFJ9y3W8fbQcAB0vl44DYG29XDoOgI6XS8cB0PFy6TgAOl4uHQegmzve8ZvEk2TatGmZNm1a3dMAAFaCjgNA2bQcAMql4wBQLh0HgHLpOACUS8cBoFw6DkC3KmKTOADdrb/Zk/5mxVdzqfh8AMCKVd1yHQeA9tFxACiXtXUAKJeOA0C5dBwAyqXjAFCubu54GbMEAAAAAAAAAAAAAAAAAAAgiTuJA1CAvjTSl0bl5wQA2qPqlus4ALSPjgNAuaytA0C5dBwAyqXjAFAuHQeAcnVzx91JHAAAAAAAAAAAAAAAAAAAoCDuJA5Ax+tv9qS/We11Tao+HwCwYlW3XMcBoH10HADKZW0dAMql4wBQLh0HgHLpOACUq5s7bpM4AB2vL0lfGpWfEwBoj6pbruMA0D46DgDlsrYOAOXScQAol44DQLl0HADK1c0dL2MrOwAAAAAAAAAAAAAAAAAAAEncSRyAAvQ3e9LfrPa6JlWfDwBYsapbruMA0D46DgDlsrYOAOXScQAol44DQLl0HADK1c0dL2OWAAAAAAAAAAAAAAAAAAAAJOmiO4m/+rb9M2q13lrGbr5vnVrGTZL1zrixtrEBqtLX7ElfxVdfqfp8tNbZczfI2L56/trSePl2tYybJM1bfl3b2ABVqrrlOl6W7a48JD1jV61l7FVPHFPLuEmyyYk31DY2QJV0vLvtdM67M6q3no4/c+7CWsZNki0Pv7W2sQGqZG29u73sO+9Kz6r1dHzx6X21jJskWx55c21jA1RJx/n3+eOyWmNULWOP2vZFtYybJH2/uau2sQGqouO87IIavyc/s8bvyY/wPTlQPh1n57Nq/Bn5+X+uZdwk2eId/1vb2ABV6eaOlzFLAOgQX/va1zJlypSsuuqq2WWXXXLzzc+/sHnaaaflRS96UcaOHZvJkyfnuOOOyzPPPNOm2QIAf03HAaBcOg4A5dJxACiXjgNAuXQcAMqm5QBQrnZ3vGvuJA5AuZpppD+Nys85VBdddFGmT5+eM888M7vssktOO+207LXXXrnrrrsyceLEZZ5/4YUX5iMf+UjOOeecvOIVr8jvfve7HHbYYWk0Gjn11FOreBsAUISqW67jANA+Og4A5eqEtXUdB4CVo+MAUC4dB4BydULHEy0HgJXRzR13J3EAGKRTTz0173nPe3L44Ydnm222yZlnnpnVVlst55xzznKff8MNN2S33XbLQQcdlClTpuR1r3tdDjzwwL95BRgAoHo6DgDl0nEAKJeOA0C5dBwAyqXjAFA2LQeActXRcZvEAeh4fc2elhxDsWjRotx6663ZY489lj7W09OTPfbYIzfeeONyX/OKV7wit95669Iw/+EPf8hll12WN77xjSv/xQCAAuk4AJRLxwGgXHWvres4AKw8HQeAcuk4AJSr7o4nWg4AK6ubOz56SLMEgBr0NxvpbzYqP2eSzJs3b8Djvb296e3tXeb5jz32WPr6+jJp0qQBj0+aNCl33nnncsc46KCD8thjj+WVr3xlms1mnn322RxxxBH56Ec/WtG7AIAyVN1yHQeA9tFxAChX3WvrOg4AK0/HAaBcOg4A5aq744mWA8DK6uaOu5M4AF1t8uTJmTBhwtJjxowZlZ376quvzmc/+9mcfvrp+cUvfpEf/vCH+clPfpJPf/rTlY0BAN1MxwGgXDoOAGVrVct1HABaT8cBoFw6DgDl8jNyAChXp3fcncQB6Hh96Ulfxdc1ee58s2bNyvjx45c+vrwruSTJuuuum1GjRmXOnDkDHp8zZ07WX3/95b7mE5/4RA4++OC8+93vTpJst912WbBgQd773vfmYx/7WHp6XKsFgO5Qdct1HADaR8cBoFx1r63rOACsPB0HgHLpOACUq+6OJ1oOACurmzuu9AB0tfHjxw84VhTqMWPGZMcdd8zMmTOXPtbf35+ZM2dm1113Xe5rnn766WViPGrUqCRJs9ms6B0AQPfScQAol44DQNkG03IdB4DOpOMAUC4dB4By+Rk5AJSr0zvuTuIAdLz+ZiP9zUbl5xyq6dOn59BDD81OO+2UnXfeOaeddloWLFiQww8/PElyyCGHZKONNsqMGTOSJPvss09OPfXU7LDDDtlll13y+9//Pp/4xCeyzz77LA02AHSDqluu4wDQPjoOAOXqhLV1HQeAlaPjAFAuHQeAcnVCxxMtB4CV0c0dt0kcAAbpbW97Wx599NF88pOfzOzZs/PSl740l19+eSZNmpQkeeCBBwZcveXjH/94Go1GPv7xj+fBBx/Meuutl3322Scnn3xyXW8BALqWjgNAuXQcAMql4wBQLh0HgHLpOACUTcsBoFx1dLzRHOw9xws1b968TJgwIdtd/IGMWm35t3FvteZl69QybpKsd8aNtY0NdJdnm4tzdf49c+fOzfjx4ys553N/hk+7bv/0rrFKJed8zsL5i/PVV15S6Xyp3nP/DvzrLbtl7Br1XNvm0kP/oZZxk6R5y69rGxvoLq3oeNK6lut4GZ7757/x105Mz9hVa5nDqrPG1DJukmxy4g21jQ10Fx2nFZ775/+Cj3w2o3rr6fgzmy2sZdwk2fLwW2sbG+gupXU80fISPPfPf7OTTk7PqvV0fPH4vlrGTZItj7y5trGB7qLjtMpz/w6c94uXZLVx9dzt7ez931DLuEnS95u7ahsb6B46Tqss/Z78hBq/J1+7xu/Jj/A9OdB6Ok6rPPfvwAs/UOPPyLf9cy3jJskW7/jf2sYGuou9Z63R87efUq9rr702++yzTzbccMM0Go1ceumldU8JgDbrazZactB6Og5A0pqW03o6DkCi46XScQASa+ul0nEAEh0vlY4DkOh4ybQcAB0vl44D0M0d7/hN4gsWLMhLXvKSfO1rX6t7KgDAEOk4AJRLxwGgXDoOAOXScQAol44DQNm0HADKpeMAdLPRdU/gb3nDG96QN7zhDXVPA4Aa9Tcb6a/46itVn4/l03EAkupbruPtoeMAJDpeKh0HILG2XiodByDR8VLpOACJjpdMywHQ8XLpOADd3PGO3yQ+VAsXLszChQuXfjxv3rwaZwMADIWOA0C5dBwAyqXjAFAuHQeAsmk5AJRLxwGgXDoOwEjSU/cEqjZjxoxMmDBh6TF58uS6pwTAMDWbPemv+Gg2R1wCRwQdBxiZqm65jncmHQcYmXS8O+g4wMhkbb076DjAyKTj3UPLAUYeHe8eOg4w8uh499BxgJGnmztexiyH4Pjjj8/cuXOXHrNmzap7SgDAIOk4AJRLxwGgXDoOAOXScQAom5YDQLl0HADKpeMAjCSj655A1Xp7e9Pb21v3NACoUF8a6Uuj8nPSeXQcYGSquuU63pl0HGBk0vHuoOMAI5O19e6g4wAjk453Dy0HGHl0vHvoOMDIo+PdQ8cBRp5u7viIu5M4AAAAAAAAAAAAAAAAAADASNbxdxKfP39+fv/73y/9+N57781tt92WtddeO5tsskmNMwOgXfqbSX+z2quv9DcrPR0roOMAJNW3XMfbQ8cBSHS8VDoOQGJtvVQ6DkCi46XScQASHS+ZlgOg4+XScQC6ueMdv0n85z//eV772tcu/Xj69OlJkkMPPTTnnXdeTbMCoJ36mz3pb/ZUfk5aT8cBSKpvuY63h44DkOh4qXQcgMTaeql0HIBEx0ul4wAkOl4yLQdAx8ul4wB0c8c7fpP4a17zmjSbhWy5BwAG0HEAKJeOA0C5dBwAyqXjAFAuHQeAsmk5AJRLxwHoZh2/SRwA+tNIfxqVnxMAaI+qW67jANA+Og4A5bK2DgDl0nEAKJeOA0C5dBwAytXNHS/jfucAAAAAAAAAAAAAAAAAAAAkcSdxAArQ12ykr1nt1VeqPh8AsGJVt1zHAaB9dBwAymVtHQDKpeMAUC4dB4By6TgAlKubO+5O4gAAAAAAAAAAAAAAAAAAAAVxJ3EAOl5/syf9zWqva1L1+QCAFau65ToOAO2j4wBQLmvrAFAuHQeAcuk4AJRLxwGgXN3c8TJmCQAAAAAAAAAAAAAAAAAAQBJ3EgegAP1ppL/ZqPycAEB7VN1yHQeA9tFxACiXtXUAKJeOA0C5dBwAyqXjAFCubu64TeIAdLxmGpWHtVlIqAFgJKi65ToOAO2j4wBQLmvrAFAuHQeAcuk4AJRLxwGgXN3c8a7ZJL7KD9bKqDGr1jL2wjXr+5fhkSNfUdvYSTLx9BtqHR+AkeGn79glo0f11jL2o69eo5Zxk+Txd7+8trGTZMt/vqXW8QEYGSZeOzqjxtSz/NDo669l3CSZ9fF6vx+f/BnfjwMwfGvd1ZfRq/TVMvZDG/fUMm6S9L9qh9rGTpKe//7fWscHYGRY6zfNjBrTrGXspzap79cQnjx419rGTpI1v31jreMDMHJ87py3ZVRvPb/rltfXM2ySrD2l3p+R9/7Ez8gBGL7NL36itt91e/qLC2sZN7G2DsDIMGZ+MmpRPWNv+ql59Qyc5Ldn7Fzb2Emy5fturnV8gNJ1zSZxAMrV32ykv1ntBTeqPh8AsGJVt1zHAaB9dBwAymVtHQDKpeMAUC4dB4By6TgAlKubO17frTgAAAAAAAAAAAAAAAAAAAAYMncSB6Dj9Td70t+s9romVZ8PAFixqluu4wDQPjoOAOWytg4A5dJxACiXjgNAuXQcAMrVzR0vY5YAAAAAAAAAAAAAAAAAAAAkcSdxAArQ32ykv9mo/JwAQHtU3XIdB4D20XEAKJe1dQAol44DQLl0HADKpeMAUK5u7rhN4gB0vP400p+KQ13x+QCAFau65ToOAO2j4wBQLmvrAFAuHQeAcuk4AJRLxwGgXN3c8Z66JwAAAAAAAAAAAAAAAAAAAMDguZM4AB2vv9lIf7Piq7lUfD4AYMWqbrmOA0D76DgAlMvaOgCUS8cBoFw6DgDl0nEAKFc3d9ydxAEAAAAAAAAAAAAAAAAAAAriTuIAdLxuvpoLAIwE7kAKAOXScQAol7V1ACiXjgNAuXQcAMql4wBQrm7uuDuJAwAAAAAAAAAAAAAAAAAAFKSjN4nPmDEjL3/5yzNu3LhMnDgx++23X+666666pwVAmz13NZeqD1pPywFIWtNyWk/HAUh0vFQ6DkBibb1UOg5AouOl0nEAEh0vlY4DkOh4qXQcgKS7O97Rm8SvueaaHHXUUbnpppty5ZVXZvHixXnd616XBQsW1D01AGAQtBwAyqXjAFAuHQeAcuk4AJRLxwGgXDoOAOXScQC63ei6J/B8Lr/88gEfn3feeZk4cWJuvfXWvPrVr65pVgC0WyuuvlLK1VxKp+UAJNW3XMfbQ8cBSHS8VDoOQGJtvVQ6DkCi46XScQASHS+VjgOQ6HipdByApLs73tGbxP+vuXPnJknWXnvtmmcCQDs1k/Sn2rA2Kz0bg6XlAN2p6pbreD10HKA76fjIoOMA3cna+sig4wDdScdHBh0H6E46PjLoOEB30vGRQccBulM3d7yYTeL9/f059thjs9tuu+XFL37xCp+3cOHCLFy4cOnH8+bNa8f0AIC/YTAt13EA6Ew6DgDl0nEAKJeOA0C5/K4bAJRLxwGgXDoOQDfqqXsCg3XUUUfl9ttvz3e/+93nfd6MGTMyYcKEpcfkyZPbNEMAWqW/2WjJQXsNpuU6DjAy6Xj5dByge+l4+XQcoHtZWy+fjgN0Lx0vn991A+heOl4+HQfoXjpePh0H6F7d3PEiNolPmzYtP/7xj3PVVVdl4403ft7nHn/88Zk7d+7SY9asWW2aJQCwIoNtuY4DQOfRcQAol44DQLl0HADK5XfdAKBcOg4A5dJxALrV6Lon8HyazWbe//7355JLLsnVV1+dzTbb7G++pre3N729vW2YHQDt0oqrr5RyNZfSDbXlOg4wMlXdch1vDx0HINHxUuk4AIm19VLpOACJjpfK77oBkOh4qXQcgETHS6XjACTd3fGO3iR+1FFH5cILL8y///u/Z9y4cZk9e3aSZMKECRk7dmzNswMA/hYtB4By6TgAlEvHAaBcOg4A5dJxACiXjgNAuXQcgG7X0ZvEzzjjjCTJa17zmgGPn3vuuTnssMPaPyEAatHNV3MpnZYDkLgDaal0HIBEx0ul4wAk1tZLpeMAJDpeKh0HINHxUuk4AImOl0rHAUi6u+MdvUm82WzWPQUAOkA3h7p0Wg5AYnNZqXQcgETHS6XjACTW1kul4wAkOl4qHQcg0fFS6TgAiY6XSscBSLq74z11TwAAAAAAAAAAAAAAAAAAAIDB6+g7iQNAkjSbjTQrvvpK1ecDAFas6pbrOAC0j44DQLmsrQNAuXQcAMql4wBQLh0HgHJ1c8fdSRwAAAAAAAAAAAAAAAAAAKAg7iQOQMfrTyP9qfbqK1WfDwBYsapbruMA0D46DgDlsrYOAOXScQAol44DQLl0HADK1c0ddydxAAAAAAAAAAAAAAAAAACAgriTOAAdr7/ZSH+z4qu5VHw+AGDFqm65jgNA++g4AJTL2joAlEvHAaBcOg4A5dJxAChXN3fcncQBAAAAAAAAAAAAAAAAAAAK4k7iAHS8ZrORZsVXX6n6fADAilXdch0HgPbRcQAol7V1ACiXjgNAuXQcAMql4wBQrm7uuE3iAHS8/mYj/RWHterzAQArVnXLdRwA2kfHAaBc1tYBoFw6DgDl0nEAKJeOA0C5urnjXbNJvNnTSLOnnn8oG37/nlrGTZInXzWltrGTZM77X1Hr+JO+ckOt4wNQkTmPJo0xtQw94Z7xtYybJAv3eqa2sZNk1Iu2qHX8vrt+X+v4AFRjrV8+kdGjeusZvNmsZ9wkfWPWrW3sJLnv07vWOv6UT9xY6/gAVGPsY4szevSoWsbe8MpVahk3SR58zdjaxk6SKXNeUOv4fb+r72caAFRnzR/fntF1rau/uL6WPfKxxbWNnSS5a7t6x7/51/WOD0BlJt7254weXc8a99MT6/k7RJL88R/qWYd4zpY3rFXr+H1PPFHr+ABUo/HEvDR66unp7CfXq2XcJNl4VL2bJ0Zts2Wt4/fd8btaxwegGmvf8UxG17TTbv7W69QzcJLNv9dX29iJvWcAw9U1m8QBKFez2Uiz4quvVH0+AGDFqm65jgNA++g4AJTL2joAlEvHAaBcOg4A5dJxAChXN3e8p+4JAAAAAAAAAAAAAAAAAAAAMHjuJA5Ax2s2G+nv0qu5AMBIUHXLdRwA2kfHAaBc1tYBoFw6DgDl0nEAKJeOA0C5urnj7iQOAAAAAAAAAAAAAAAAAABQEHcSB6DjNZM0m9WfEwBoj6pbruMA0D46DgDlsrYOAOXScQAol44DQLl0HADK1c0dt0kcgI7Xn0YaaVR+TgCgPapuuY4DQPvoOACUy9o6AJRLxwGgXDoOAOXScQAoVzd3vKfuCQAAAAAAAAAAAAAAAAAAADB47iQOQMdrNhtpNqu9+krV5wMAVqzqlus4ALSPjgNAuaytA0C5dBwAyqXjAFAuHQeAcnVzx91JHAAAAAAAAAAAAAAAAAAAoCDuJA5Ax+tvNtKo+Oor/YVczQUARoKqW67jANA+Og4A5bK2DgDl0nEAKJeOA0C5dBwAytXNHXcncQAAAAAAAAAAAAAAAAAAgIJ09CbxM844I9tvv33Gjx+f8ePHZ9ddd81Pf/rTuqcFQJs1m605aD0tByDR8VLpOACJjpdKxwFIrK2XSscBSHS8VDoOQKLjpdJxABIdL5WOA5B0d8c7epP4xhtvnM997nO59dZb8/Of/zz/8A//kDe/+c35zW9+U/fUAIBB0HIAKJeOA0C5dBwAyqXjAFAuHQeAcuk4AJRLxwHodqPrnsDz2WeffQZ8fPLJJ+eMM87ITTfdlG233bamWQHQbs1mI81mo/Jz0npaDkBSfct1vD10HIBEx0ul4wAk1tZLpeMAJDpeKh0HINHxUuk4AImOl0rHAUi6u+MdvUn8r/X19eV73/teFixYkF133XWFz1u4cGEWLly49ON58+a1Y3oAtFA3h3okGUzLdRxgZLK5rHw6DtC9dLx8Og7Qvaytl0/HAbqXjpfP77oBdC8dL5+OA3QvHS+fjgN0r27ueE/dE/hbfv3rX2eNNdZIb29vjjjiiFxyySXZZpttVvj8GTNmZMKECUuPyZMnt3G2AMD/NZSW6zgAdBYdB4By6TgAlEvHAaBcftcNAMql4wBQLh0HoJt1/CbxF73oRbntttvyP//zP3nf+96XQw89NHfccccKn3/88cdn7ty5S49Zs2a1cbYAtEJ/s9GSg/YYSst1HGBk0vFy6TgAOl4uHQfA2nq5dBwAHS+X33UDQMfLpeMA6Hi5dByAbu746Lon8LeMGTMmW2yxRZJkxx13zC233JIvfelLOeuss5b7/N7e3vT29rZzigDA8xhKy3UcADqLjgNAuXQcAMql4wBQLr/rBgDl0nEAKJeOA9DNOn6T+P/V39+fhQsX1j0NANqo2VxyVH1O6qHlAN2n6pbreH10HKD76PjIoeMA3cfa+sih4wDdR8dHDh0H6D46PnLoOED30fGRQ8cBuk83d7yjN4kff/zxecMb3pBNNtkkTz31VC688MJcffXVueKKK+qeGgAwCFoOAOXScQAol44DQLl0HADKpeMAUC4dB4By6TgA3a6jN4k/8sgjOeSQQ/Lwww9nwoQJ2X777XPFFVdkzz33rHtqALTRkqu5NCo/J62n5QAk1bdcx9tDxwFIdLxUOg5AYm29VDoOQKLjpdJxABIdL5WOA5DoeKl0HICkuzve0ZvEzz777LqnAAAMg5YDQLl0HADKpeMAUC4dB4By6TgAlEvHAaBcOg5At+voTeIAkCy5kkv1V3Op9nwAwIpV3XIdB4D20XEAKJe1dQAol44DQLl0HADKpeMAUK5u7rhN4gB0vOZfjqrPCQC0R9Ut13EAaB8dB4ByWVsHgHLpOACUS8cBoFw6DgDl6uaO99Q9AQAAAAAAAAAAAAAAAAAAAAbPncQB6HjNZiPNZqPycwIA7VF1y3UcANpHxwGgXNbWAaBcOg4A5dJxACiXjgNAubq54+4kDgAAAAAAAAAAAAAAAAAAUBB3Egeg8zX/clR9TgCgPapuuY4DQPvoOACUy9o6AJRLxwGgXDoOAOXScQAoVxd33J3EAWAIvva1r2XKlClZddVVs8suu+Tmm29+3uc/+eSTOeqoo7LBBhukt7c3W265ZS677LI2zRYA+Gs6DgDl0nEAKJeOA0C5dBwAyqXjAFA2LQeAcrW74+4kDkDnazbSbDYqP+dQXXTRRZk+fXrOPPPM7LLLLjnttNOy11575a677srEiROXef6iRYuy5557ZuLEifn+97+fjTbaKPfff3/WXHPNCt4AABSk6pbrOAC0j44DQLk6YG1dxwFgJek4AJRLxwGgXB3Q8UTLAWCldHHHV2qT+JNPPpmbb745jzzySPr7+wd87pBDDlmZU7bcOtc/mNE9vfUM3qj4X64hGPeH+bWNnSSPHjCq1vFHX7pxbWM/O+uPtY0NI02zueSo+pxDdeqpp+Y973lPDj/88CTJmWeemZ/85Cc555xz8pGPfGSZ559zzjl5/PHHc8MNN2SVVVZJkkyZMmU4065EiR1/dN+tMmrMqrWMPeny+2sZN0k2PvBPtY2dJLOO2bHW8de/YY3axu657rbaxoaRqOqW63hZHf/9v6yWntXq6fiW0+6rZdwkWfXJtWobO0nWO/2BWsdvrlXf++974onaxoaRSMerU2LHe//wSG3r6r0PrFLLuEky9tG1axs7SX77wXrH3+bEP9c29rMPPlTb2DASdcLauo7XZ/FOW6Y5up7vx8fMqu/7smf/e4Paxk6SZyY9W+v4a2ywfm1jP/vw7NrGhpFIx6tVYstXmf1URo9aVMvYa95Xz7hJMu7eCbWNnST3/MtWtY6/yX8+U9vYPdf8b21jw0ij49UqseNz/25yRq9Sz/fkU6bW9+f5/H13qG3sJHl8q3VqHX/95gtrG7vvt3fXNjaMNJ3Q8WTktLzEjo95eF5Gj1pYz9i/mVfLuEmStcbXN3aSvpdNqnX8P71719rGXuebN9Y2Now03dzxIW8S/4//+I9MnTo18+fPz/jx49P4qw3QjUajY0MNAMOxaNGi3HrrrTn++OOXPtbT05M99tgjN964/L+Y/+hHP8quu+6ao446Kv/+7/+e9dZbLwcddFA+/OEPZ9Soei6ioeMAdCMdB4By6TgAlEvHAaBcI6XjiZYD0H10HADKNlJaruMAdKO6Oj7kTeIf+MAH8s53vjOf/exns9pqqw315QAwZM1mI81m428/cYjnTJJ58wZecau3tze9vcveIeuxxx5LX19fJk0aeJWqSZMm5c4771zuGH/4wx/yX//1X5k6dWouu+yy/P73v8+RRx6ZxYsX54QTTqjonQyNjgNQh6pbruM6DkD76Hg1dByAOtS9tq7jALDydLw6Wg5Au+l4dXQcgHaru+PJyGm5jgPQbt3c8Z5BPeuvPPjggzn66KNFGoARYfLkyZkwYcLSY8aMGZWdu7+/PxMnTszXv/717Ljjjnnb296Wj33sYznzzDMrG2OodByAkUTHAaBcOg4AZWtVy3UcAFqvmzqeaDkAI4uOA0C5/IwcAMrV6R0f8p3E99prr/z85z/P5ptvPtSXAsDKaTaWHFWfM8msWbMyfvz4pQ8v70ouSbLuuutm1KhRmTNnzoDH58yZk/XXX3+5r9lggw2yyiqrZNSoUUsf23rrrTN79uwsWrQoY8aMGe67GDIdB6AWVbdcx9s+NgBdTMcroeMA1KLmtXUdB4Bh0PHKaDkAbafjldFxANrO76xXRscBaLsu7viQN4nvvffe+eAHP5g77rgj2223XVZZZZUBn993332HekoAqM348eMHhHpFxowZkx133DEzZ87Mfvvtl2TJ1VpmzpyZadOmLfc1u+22Wy688ML09/enp6cnSfK73/0uG2ywQW0L5zoOwEii4zoOQLl0XMcBKNtgWq7jANCZuqnjiZYDMLLouI4DUC4/I9dxAMrV6R0f8ibx97znPUmST33qU8t8rtFopK+vb6inBIDn1WwuOao+51BNnz49hx56aHbaaafsvPPOOe2007JgwYIcfvjhSZJDDjkkG220UWbMmJEked/73pevfvWrOeaYY/L+978/d999dz772c/m6KOPrvKtDImOA1CHqluu4zoOQPvoeDV0HIA6dMLauo4DwMrR8epoOQDtpuPV0XEA2q0TOp6MjJbrOADt1s0dH/Im8f7+/qG+BABGhLe97W159NFH88lPfjKzZ8/OS1/60lx++eWZNGlSkuSBBx5YetWWJJk8eXKuuOKKHHfccdl+++2z0UYb5ZhjjsmHP/zhut6CjgPQtXQcAMql4wBQLh0HgHKNhI4nWg5Ad9JxACjbSGi5jgPQrero+JA3iQNA2zX/clR9zpUwbdq0TJs2bbmfu/rqq5d5bNddd81NN920coMBwEhRdct1HADaR8cBoFwdsrau4wCwEnQcAMql4wBQrg7peKLlADBkXdzxnr/9lGVdc8012WeffbLFFltkiy22yL777pv//u//XulJAMDzaTYbLTm6lY4D0G46Xh0dB6DddLw6Og5Au1lbr46OA9BuOl4tLQegnXS8WjoOQDvpeLV0HIB26uaOD3mT+Pnnn5899tgjq622Wo4++ugcffTRGTt2bHbfffdceOGFrZgjAFARHQeAcuk4AJRLxwGgXDoOAGXTcgAol44DQLl0HADaZ/RQX3DyySfnC1/4Qo477riljx199NE59dRT8+lPfzoHHXRQpRMEgCRJs+4JjAw6DkBttHzYdByA2uj4sOk4ALXR8WHTcQBqo+OV0HIAaqHjldBxAGqh45XQcQBq0aUdH/KdxP/whz9kn332WebxfffdN/fee28lk1qRz33uc2k0Gjn22GNbOg4AjFQ6DgDl0nEAKJeOA0C56ux4ouUAMFy+JweAcuk4AJRLxwGgfYa8SXzy5MmZOXPmMo//7Gc/y+TJkyuZ1PLccsstOeuss7L99tu3bAwAOlOz2WjJ0Y10HIA66Hg1dByAOuh4NXQcgDpYW69GXR1PtBygm+l4dXxPDkC76Xh1dByAdtPx6ug4AO3WzR0fPdQXfOADH8jRRx+d2267La94xSuSJNdff33OO++8fOlLX6p8gkkyf/78TJ06Nd/4xjfymc98piVjAEA30HEAKJeOA0C5dBwAylVHxxMtB4Cq+J4cAMql4wBQLh0HgPYZ8ibx973vfVl//fVzyimn5OKLL06SbL311rnooovy5je/ufIJJslRRx2VvffeO3vssYdQA3Sj5l+Oqs/ZhXQcgFpU3XId13EA2kfHK6HjANTC2nol6uh4ouUAXU/HK+N7cgDaTscro+MAtJ2OV0bHAWi7Lu74kDeJJ8n++++f/fffv+q5LNd3v/vd/OIXv8gtt9wyqOcvXLgwCxcuXPrxvHnzWjU1ANqm8Zej6nN2Jx0HoP2qbrmOt4OOA7CEjldFxwFoP2vrVWlnx5OhtVzHAUYqHa+S78kBaC8dr5KOA9BeOl4lHQegvbq34z11T+D5zJo1K8ccc0wuuOCCrLrqqoN6zYwZMzJhwoSlx+TJk1s8SwBgeXQcAMql4wBQLh0HgLINteU6DgCdw/fkAFAuHQeAcuk4AN1uUJvE11577Tz22GNJkrXWWitrr732Co8q3XrrrXnkkUfyspe9LKNHj87o0aNzzTXX5Mtf/nJGjx6dvr6+ZV5z/PHHZ+7cuUuPWbNmVTonAGrQbNHRJXQcgNrp+ErTcQBqp+MrTccBqJ219ZVWV8eTobdcxwFGKB0fFt+TA1ArHR8WHQegVjo+LDoOQK26uOOjB/OkL37xixk3btzS/99otOc26bvvvnt+/etfD3js8MMPz1ZbbZUPf/jDGTVq1DKv6e3tTW9vb1vmBwAl0HEAKJeOA0C5dBwAylVXx5Oht1zHAWBZvicHgHLpOACUS8cBoB6D2iR+6KGHLv3/hx12WKvmsoxx48blxS9+8YDHVl999ayzzjrLPA7ACNaKq68UcjWXKug4ALWruuU63nI6DsBSOr7SdByA2llbX2l1dTzRcgD+QseHxffkANRKx4dFxwGolY4Pi44DUKsu7njPUF8watSoPPLII8s8/qc//Wm5V1cBADqHjgNAuXQcAMql4wBQLh0HgLJpOQCUS8cBoFw6DgDtM6g7if+1ZnP5298XLlyYMWPGDHtCf8vVV1/d8jEA6DDNxpKj6nN2IR0HoBZVt1zHB9BxAFpKxyuh4wDUwtp6JerueKLlAF1JxytTd8t1HKAL6XhldByAttPxyug4AG3XxR0f9CbxL3/5y0mSRqORb37zm1ljjTWWfq6vry/XXnttttpqq+pnCAAMm44DQLl0HADKpeMAUC4dB4CyaTkAlEvHAaBcOg4A7TfoTeJf/OIXkyy5msuZZ56ZUaNGLf3cmDFjMmXKlJx55pnVzxCArtdsLjmqPmc30XEA6lR1y3VcxwFoHx0fHh0HoE7W1odHxwGok44Pn5YDUBcdHz4dB6AuOj58Og5AXbq544PeJH7vvfcmSV772tfmhz/8YdZaa62WTQoABmj+5aj6nF1ExwGoVdUt1/GaZwRAV9HxYdFxAGplbX1YdByAWun4sGk5ALXR8WHTcQBqo+PDpuMA1KaLOz7oTeLPueqqq1oxDwCgDXQcAMql4wBQLh0HgHLpOACUTcsBoFw6DgDl0nEAaJ9BbRKfPn16Pv3pT2f11VfP9OnTn/e5p556aiUTA4Clmo0lR9Xn7BI6DkDtqm65ji+XjgPQEjq+0nQcgNpZW19pOg5A7XR8WLQcgFrp+LDoOAC10vFh0XEAatXFHR/UJvH//d//zeLFi5f+/xVpNMp40wDQTXQcAMql4wBQLh0HgHLpOACUTcsBoFw6DgDl0nEAqMegNolfddVVy/3/ANAOjeaSo+pzdgsdB6BuVbdcxwGgfXR85ek4AHWztr7ydByAuun48Gg5AHXS8eHRcQDqpOPDo+MA1KmbO94z3BPMmzcvl156ae68884q5gMAtJGOA0C5dBwAyqXjAFAuHQeAsmk5AJRLxwGgXDoOAK0z5E3ib33rW/PVr341SfLnP/85O+20U9761rdmu+22yw9+8IPKJwgAabbo6EI6DkAtdLwSOg5ALXS8EjoOQC2srVdCxwGohY5XRssBaDsdr4yOA9B2Ol4ZHQeg7bq446OH+oJrr702H/vYx5Ikl1xySZrNZp588sn827/9Wz7zmc/kgAMOqHySVeifsEb6R/XWM/hd99YzbpLG/AW1jZ0kL/zoOrWO/8iek2sbe+Gam9Q2dpJscOoNtY4PlWo2lhxVn7MLldrx1R7ty+hV+moZu2/OI7WMmyQ966xd29hJst4vFtY6/h93X622sTe7fUJtYydJ35Nzax0fKld1y3W8qI6vf+kqGb3KKrWM3dxk/VrGTZJxtz1c29hJ0r/OmrWO3zdh1drGfnb1F9Q2dpKs8p8/r3V8qJyOV6LUjj+580YZvUo9f6aved39tYybJGN+M6u2sZNk6/9vfK3j3/PPm9Y29mb/31O1jZ0k/U/VOz5Uztp6JUrt+Co//11GN8bUM/jqq9czbpKNZta7tjrq8Xm1jv/b4+vr+AvPX6+2sZMkN/+63vGhajpemVJb3n//g+lv1LO2XqvZ9f18Pkle8OcptY5/53vXqm3sdafsWtvYSbLWv91Y6/hQKR2vTKkdH3flHbV9T37/R3aqZdwk2exb9a6tj5tQ33pEkix4QX0dX2P+xrWNnSTPzvpjreNDpXS8MqV2/PGXr5dRY+r5Gfk6lz1Zy7hJ0j+hvt/ZTpINrq9371t/76jaxh619QtrGztJ+n57d63jQ6W6uONDvpP43Llzs/baSzYsXX755TnggAOy2mqrZe+9987dd/uDAQA6mY4DQLl0HADKpeMAUC4dB4CyaTkAlEvHAaBcOg4A7TPkTeKTJ0/OjTfemAULFuTyyy/P6173uiTJE088kVVXre8uUQCMYM0WHV1IxwGohY5XQscBqIWOV0LHAaiFtfVK6DgAtdDxymg5AG2n45XRcQDaTscro+MAtF0Xd3z0UF9w7LHHZurUqVljjTWy6aab5jWveU2S5Nprr812221X9fwAgArpOACUS8cBoFw6DgDl0nEAKJuWA0C5dBwAyqXjANA+Q94kfuSRR2bnnXfOrFmzsueee6anZ8nNyDfffPN85jOfqXyCANCSq68UcjWXquk4ALWouuU6ruMAtI+OV0LHAaiFtfVK6DgAtdDxymg5AG2n45XRcQDaTscro+MAtF0Xd3zIm8STZKeddspOO+2UZrOZZrOZRqORvffeu+q5AQAtoOMAUC4dB4By6TgAlEvHAaBsWg4A5dJxACiXjgNAe/SszIu+9a1vZbvttsvYsWMzduzYbL/99vn2t79d9dwAYIlmi44upeMAtJ2OV0bHAWg7Ha+MjgPQdtbWK6PjALSdjldKywFoKx2vlI4D0FY6XikdB6CturjjQ76T+KmnnppPfOITmTZtWnbbbbckyXXXXZcjjjgijz32WI477rjKJwkAVEPHAaBcOg4A5dJxACiXjgNA2bQcAMql4wBQLh0HgPYZ8ibxr3zlKznjjDNyyCGHLH1s3333zbbbbpsTTzxRqAGoXrOx5Kj6nF1IxwGoRdUt1/Glj+k4AC2n45XQcQBqYW29EjoOQC10vDJaDkDb6XhldByAttPxyug4AG3XxR0f8ibxhx9+OK94xSuWefwVr3hFHn744UomBQB/rdFcclR9zm6k4wDUoeqW6/hAOg5AK+l4NXQcgDpYW6+GjgNQBx2vjpYD0G46Xh0dB6DddLw6Og5Au3Vzx3uG+oItttgiF1988TKPX3TRRXnhC19YyaQAgNbQcQAol44DQLl0HADKpeMAUDYtB4By6TgAlEvHAaB9hnwn8ZNOOilve9vbcu2112a33XZLklx//fWZOXPmcgMOAMPW/MtR9Tm7kI4DUIuqW67jOg5A++h4JXQcgFpYW6+EjgNQCx2vjJYD0HY6XhkdB6DtdLwyOg5A23Vxx4d8J/EDDjggN998c9Zdd91ceumlufTSS7Puuuvm5ptvzv7771/p5E488cQ0Go0Bx1ZbbVXpGADQTdrZ8UTLAaBKOg4A5dJxACiXjgNA2fyuGwCUS8cBoFw6DgDtM6Q7ic+bNy//8z//k0WLFuWLX/xi1ltvvVbNa6ltt902P/vZz5Z+PHr0kG9+DgCkno4nWg4AVdBxACiXjgNAuXQcAMrmd90AoFw6DgDl0nEAaK9BV++2227LG9/4xsyZMyfNZjPjxo3LxRdfnL322quV88vo0aOz/vrrt3QMABjp6up4ouUAMFw6DgDl0nEAKJeOA0DZ/K4bAJRLxwGgXDoOAO3XM9gnfvjDH85mm22W6667Lrfeemt23333TJs2rZVzS5Lcfffd2XDDDbP55ptn6tSpeeCBB1o+JgCdpZGk0az4qPtNtVldHU+0HIAWtLzuN9RmOg5AnXR8eHQcgDpZWx+eUjq+cOHCzJs3b8ABQPl0fPhK+V03LQcYeXR8+HQcgLro+PDpOAB16eaOD/pO4rfeemv+8z//My972cuSJOecc07WXnvtzJs3L+PHj2/J5HbZZZecd955edGLXpSHH344J510Ul71qlfl9ttvz7hx45b7moULF2bhwoVLPxZqAKin48nQW67jALAsHQeAcuk4AJSrlI7PmDEjJ510UsvmAwClKuV33bQcAJal4wBQLh0HgPYb9J3EH3/88Wy88cZLP15zzTWz+uqr509/+lNLJpYkb3jDG/KWt7wl22+/ffbaa69cdtllefLJJ3PxxRev8DUzZszIhAkTlh6TJ09u2fwAaJNmozVHF6mj48nQW67jACOUjg+LjgNQKx0fFh0HoFbW1oellI4ff/zxmTt37tJj1qxZLZ0fAG2i48NWyu+6aTnACKTjw6bjANRGx4dNxwGoTRd3fNB3Ek+SO+64I7Nnz176cbPZzG9/+9s89dRTSx/bfvvtq5vd/7Hmmmtmyy23zO9///sVPuf444/P9OnTl348b948v9AGULrmX46qz9ll6u548rdbruMAI1TVLddxHQegfXR82HQcgNpYWx+2Ejre29ub3t7els4BgBroeCXqbvlgftdNywFGIB2vhI4DUAsdr4SOA1CLLu74kDaJ77777mk2B76zN73pTWk0Gmk2m2k0Gunr66t0gn9t/vz5ueeee3LwwQev8DlCDQDLV3fHk7/dch0HgOXTcQAol44DQLlK6DgAsGJ1t1zHAWDl6TgAlEvHAaC9Br1J/N57723lPJbrX/7lX7LPPvtk0003zUMPPZQTTjgho0aNyoEHHtj2uQBQoy6+mktV6uh4ouUA/IU7kA6LjgNQKx0fFh0HoFbW1odFxwGolY4Pm991A6A2Oj5sOg5AbXR82HQcgNp0cccHvUl80003beU8luuPf/xjDjzwwPzpT3/Keuutl1e+8pW56aabst5667V9LgBQsjo6nmg5AFRBxwGgXDoOAOXScQAom991A4By6TgAlEvHAaD9Br1JvA7f/e53654CAB2g0VxyVH1OWk/LAUiqb7mOt4eOA5DoeKl0HIDE2nqpdByARMdLpeMAJDpeKh0HINHxUuk4AEl3d7yn7gkAAAAAAAAAAAAAAAAAAAAweB19J3EASJI0/3JUfU4AoD2qbrmOA0D76DgAlMvaOgCUS8cBoFw6DgDl0nEAKFcXd9wmcQA6XxeHGgBGBJvLAKBcOg4A5bK2DgDl0nEAKJeOA0C5dBwAytXFHe8Z6gtOOOGE3H///a2YCwDQYjoOAOXScQAol44DQLl0HADKpuUAUC4dB4By6TgAtM+QN4n/+7//e17wghdk9913z4UXXpiFCxe2Yl4AsFSj2ZqjG+k4AHXQ8WroOAB10PFq6DgAdbC2Xg0dB6AOOl4dLQeg3XS8OjoOQLvpeHV0HIB26+aOD3mT+G233ZZbbrkl2267bY455pisv/76ed/73pdbbrmlFfMDACqk4wBQLh0HgHLpOACUS8cBoGxaDgDl0nEAKJeOA0D7DHmTeJLssMMO+fKXv5yHHnooZ599dv74xz9mt912y/bbb58vfelLmTt3btXzBKCbNRutObqUjgPQdjpeGR0HoO10vDI6DkDbWVuvjI4D0HY6XiktB6CtdLxSOg5AW+l4pXQcgLbq4o6v1Cbx5zSbzSxevDiLFi1Ks9nMWmutla9+9auZPHlyLrrooqrmCAC0gI4DQLl0HADKpeMAUC4dB4CyaTkAlEvHAaBcOg4ArbVSm8RvvfXWTJs2LRtssEGOO+647LDDDvntb3+ba665JnfffXdOPvnkHH300VXPFYBu1WzR0aV0HIC20/HK6DgAbafjldFxANrO2npldByAttPxSmk5AG2l45XScQDaSscrpeMAtFUXd3z0UF+w3Xbb5c4778zrXve6nH322dlnn30yatSoAc858MADc8wxx1Q2yUrcfV/SGFP3LNqu+ec/1zuBxc/WOvx6P7mntrHv+teNahs7SZ7dfcfaxh4989baxgaeX6kdX+MXszK6p56OP/Pql9QybpKsetfDtY2dJKMX1Nvxzc6cVdvYD0/dtraxk2TDH/6htrGffXh2bWMDz6/Ujvc+uTijR4/6209shWZ9qzPNNVarbewkafT11Tr+Kn+oryeLXzK5trGTpOclW9c2dv8vf1vb2MDzK7Xja1zy84xurFLL2ItetUMt4ybJqBt/XdvYSTJq1d5ax9/0hJtqG/vOb9S3rp0kLzqjvp+pNG/9TW1jA8+v1I43+/rTbNTzvWGjv77vSXsW1buu3Xxibq3jv+j4x2sbe/Zh9f08JUn6X/GK2sZe/7Qbahsb+NtKbXlj1TFp1PS7bo1VV61l3CRJjX+PSJL+399X6/hbnVXfzzUe+Ew9a0DPWe9nG9Y29rMPPlTb2MDzK7Xj6etLavqefMyTtQybJGmOqbcljYf/VOv4vavXt7b/563Xr23sJFl10aLaxu6b80htYwPPr9SOj//D0xk9ur+ewUfV9Dt2SUbNfqK2sZNkVH9NX/O/eGi/KbWNvcGjC2obO0lGbbNlbWP33fG72saGkWbIm8Tf+ta35p3vfGc22mjFG2DXXXfd9Nf8BzQAI0ejueSo+pzdSMcBqEPVLddxHQegfXS8GjoOQB2srVdDxwGog45XR8sBaDcdr46OA9BuOl4dHQeg3bq54z1DefLixYtz3nnnZd68ea2aDwAsq9mio8voOAC10fFh03EAaqPjw6bjANTG2vqw6TgAtdHxSmg5ALXQ8UroOAC10PFK6DgAtejijg9pk/gqq6ySZ555plVzAQBaSMcBoFw6DgDl0nEAKJeOA0DZtBwAyqXjAFAuHQeA9hrSJvEkOeqoo/L5z38+zz77bCvmAwDLaiaNio9SruZSNR0HoBY6XgkdB6AWOl4JHQegFtbWK6HjANRCxyuj5QC0nY5XRscBaDsdr4yOA9B2Xdzx0UN9wS233JKZM2fmP//zP7Pddttl9dVXH/D5H/7wh5VNDgColo4DQLl0HADKpeMAUC4dB4CyaTkAlEvHAaBcOg4A7TPkTeJrrrlmDjjggFbMBQCWrxVXXynkai5V03EAalF1y3UcANpHxyuh4wDUwtp6JXQcgFroeGW0HIC20/HK6DgAbafjldFxANquizs+5E3i5557bivmAQC0gY4DQLl0HADKpeMAUC4dB4CyaTkAlEvHAaBcOg4A7dOzMi969tln87Of/SxnnXVWnnrqqSTJQw89lPnz51c6OQBI8v+u5lL10aV0HIC20/HK6DgAbafjldFxANrO2npldByAttPxSmk5AG2l45XScQDaSscrpeMAtFUXd3zIdxK///778/rXvz4PPPBAFi5cmD333DPjxo3L5z//+SxcuDBnnnlmK+YJQBdrNJccVZ+zG+k4AHWouuU6ruMAtI+OV0PHAaiDtfVq6DgAddDx6mg5AO2m49XRcQDaTcero+MAtFs3d3zIdxI/5phjstNOO+WJJ57I2LFjlz6+//77Z+bMmZVODgColo4DQLl0HADKpeMAUC4dB4CyaTkAlEvHAaBcOg4A7TPkO4n/93//d2644YaMGTNmwONTpkzJgw8+WNnEAIDq6TgAlEvHAaBcOg4A5dJxACiblgNAuXQcAMql4wDQPkO+k3h/f3/6+vqWefyPf/xjxo0bV8mk/tqDDz6Yd7zjHVlnnXUyduzYbLfddvn5z39e+TgA0A10HADK1e6OJ1oOAFXRcQAol44DQNn8jBwAyqXjAFAuHQeA9hnyJvHXve51Oe2005Z+3Gg0Mn/+/Jxwwgl54xvfWOXc8sQTT2S33XbLKquskp/+9Ke54447csopp2SttdaqdBwAOlyzRUcX0nEAaqHjlWhnxxMtB+AvdLwSOg5ALaytV0LHAaiFjlfGz8gBaDsdr4yOA9B2Ol4ZHQeg7bq446OH+oJTTjkle+21V7bZZps888wzOeigg3L33Xdn3XXXzXe+851KJ/f5z38+kydPzrnnnrv0sc0226zSMQCgm+g4AJSrnR1PtBwAqqTjAFAuHQeAsvkZOQCUS8cBoFw6DgDtM+RN4htvvHF++ctf5rvf/W5+9atfZf78+XnXu96VqVOnZuzYsZVO7kc/+lH22muvvOUtb8k111yTjTbaKEceeWTe8573rPA1CxcuzMKFC5d+PG/evErnBED7NZpLjqrP2Y10HIA6VN1yHW99x5Oht1zHAUYmHa+GjgNQB2vr1dBxAOqg49XxM3IA2k3Hq6PjALSbjldHxwFot27u+JA3iSfJ6NGj8453vKPquSzjD3/4Q84444xMnz49H/3oR3PLLbfk6KOPzpgxY3LooYcu9zUzZszISSed1PK5AUCpdBwAytWujidDb7mOA8Dz03EAKJeOA0DZ/IwcAMql4wBQLh0HgPYY8ibxb33rW8/7+UMOOWSlJ/N/9ff3Z6eddspnP/vZJMkOO+yQ22+/PWeeeeYKQ3388cdn+vTpSz+eN29eJk+eXNmcAKhJIVdf6XQ6DkBttHzY2tnxZOgt13GAEUzHh03HAaiNjg+bjgNQGx2vhJ+RA1ALHa+EjgNQCx2vhI4DUIsu7fiQN4kfc8wxAz5evHhxnn766YwZMyarrbZapaHeYIMNss022wx4bOutt84PfvCDFb6mt7c3vb29lc0BgA7QTPWh7tLw6zgAtai65TqepLUdT4bech0HGKF0vBI6DkAtrK1XQscBqIWOV8bPyAFoOx2vjI4D0HY6XhkdB6DturjjPUN9wRNPPDHgmD9/fu6666688pWvzHe+851KJ7fbbrvlrrvuGvDY7373u2y66aaVjgMA3ULHAaBc7ex4ouUAUCUdB4By6TgAlM3PyAGgXDoOAOXScQBonyFvEl+eF77whfnc5z63zJVehuu4447LTTfdlM9+9rP5/e9/nwsvvDBf//rXc9RRR1U6DgCdrdFszcESOg5Aq+l467Sq44mWA7CEjreOjgPQatbWW0fHAWg1HW8tPyMHoJV0vLV0HIBW0vHW0nEAWqmbO17JJvEkGT16dB566KGqTpckefnLX55LLrkk3/nOd/LiF784n/70p3Paaadl6tSplY4DAN1OxwGgXK3oeKLlANAOOg4A5dJxACibn5EDQLl0HADKpeMAUL3RQ33Bj370owEfN5vNPPzww/nqV7+a3XbbrbKJPedNb3pT3vSmN1V+XgAK0vzLUfU5u5COA1CLqluu40la3/FEywGIjldExwGohbX1Sug4ALXQ8cr4GTkAbafjldFxANpOxyuj4wC0XRd3fMibxPfbb78BHzcajay33nr5h3/4h5xyyilVzQsAaAEdB4By6TgAlEvHAaBcOg4AZdNyACiXjgNAuXQcANpnyJvE+/v7WzEPAFihRnPJUfU5u5GOA1CHqluu4wDQPjpeDR0HoA7W1quh4wDUQcero+UAtJuOV0fHAWg3Ha+OjgPQbt3c8SFvEn/OY489ljFjxmT8+PFVzgcAltX8y1H1ObuYjgPQVlW3XMd1HID20fFK6TgAbWVtvVI6DkBb6XjltByAttHxyuk4AG2j45XTcQDapos73jOUJz/55JM56qijsu6662bSpElZa621sv766+f444/P008/3ao5AkDH+NrXvpYpU6Zk1VVXzS677JKbb755UK/77ne/m0ajkf3226+1E3weOg5At9NxACiXjgNAuXQcAMpVcscTLQegu+k4AJSt5JbrOADdrt0dH/SdxB9//PHsuuuuefDBBzN16tRsvfXWSZI77rgjX/nKV3LllVfmuuuuy69+9avcdNNNOfroo4c0EQBYoQ65mstFF12U6dOn58wzz8wuu+yS0047LXvttVfuuuuuTJw4cYWvu++++/Iv//IvedWrXjWMCQ+PjgNQqw64A6mOA8BK0vFh0XEAatUBa+s6DgArSceHTcsBqI2OD5uOA1CbDuh4UnbLdRyA2nRxxwd9J/FPfepTGTNmTO65556cddZZOfbYY3Psscfm61//en7/+99n0aJFOfjgg7PnnntmwoQJQ54IAHS6U089Ne95z3ty+OGHZ5tttsmZZ56Z1VZbLeecc84KX9PX15epU6fmpJNOyuabb97G2Q6k4wB0Ox0HgHLpOACUS8cBoFwldzzRcgC6m44DQNlKbrmOA9Dt6uj4oDeJX3rppfnXf/3XTJo0aZnPrb/++vnCF76QH/zgB5k+fXoOPfTQIU8EAFak0WzNkSTz5s0bcCxcuHC5c1i0aFFuvfXW7LHHHksf6+npyR577JEbb7xxhXP/1Kc+lYkTJ+Zd73pXpV+TodJxAOqk48Oj4wDUSceHR8cBqFPda+s6DgArT8eHT8sBqIuOD5+OA1CXujuelN9yHQegLt3c8UFvEn/44Yez7bbbrvDzL37xi9PT05MTTjhhpSYCAHWYPHlyJkyYsPSYMWPGcp/32GOPpa+vb5lvWCdNmpTZs2cv9zXXXXddzj777HzjG9+ofN5DpeMAjEQ6voSOA1AiHV9CxwEo1WBaruMA0Jm6oeOJlgMwMun4EjoOQIn8jHwJHQegRJ3e8dGDfeK6666b++67LxtvvPFyP3/vvfdm4sSJKz2RVutfuCj9z23db7fGoPfit2DoRm1jJ0nf7EdqHT81vv+tPjqmtrGT5K5jlv/fajuM2/oVtY2dJBO/ekOt49MCzb8cVZ8zyaxZszJ+/PilD/f29lZy+qeeeioHH3xwvvGNb2Tdddet5JzDUXrHm4sXp1nTn+mj/+vWWsZNkmcb9XZ81BNP1jp+Y+21aht7/bN/UdvYSXLf9JfVNnbP4s1rGztJNvz/dHxEqrrlOj5Ap3d8zO/nZHRPPd8fNRc8Xcu4SfLM321Z29hJMvY3D9U6fv/cebWNPfam39U2dpI88M8r/kFXq22yuN5/7/ruqPdrT4vo+LCU3vGe1VdLT6Oejo+aU19LmqMH/aOT1ow/tpr/HlbW6PWXvap/u2x9ytzaxk6SedusXdvYzc13qW3sJFnje/9T6/i0SGFr6zpercboUWk0amra4mfrGTfJ4rXG1jZ2koz6/fLvGtAuPX/132W7rX/N47WNnSSz/76+jve/8qW1jZ0kPdfdVuv4tIiOD1vpLa9T/7z6vidvbFXvzypzxz31jt+s6fcbk2zyofp+ppIkD715Sm1jr33XBrWNnSSjZ9b3eym0iI4PW+kdb2y4fhqj6lnn3eCcX9YybpIs3uGFtY2dJKs8Ue/68ug/PFzb2It23LS2sZOkuV5935M/u+3k2sZO6v39UlqksI4nndfy0js++p7Ztf2uW/r76hk3ScauWt/YSa17v5Jkg4vvrm3sua99QW1jJ8maN/6xtrHnTv272sZOkgkX3FTr+LRAF3d80D8V3muvvfKxj30sV155ZcaMGRi8hQsX5hOf+ERe//rXr/REAKAO48ePHxDqFVl33XUzatSozJkzZ8Djc+bMyfrrr7/M8++5557cd9992WeffZY+1t/fnyQZPXp07rrrrrzgBe37C72OAzAS6biOA1AuHddxAMo2mJbrOAB0pm7oeKLlAIxMOq7jAJTLz8h1HIBydXrHB71J/FOf+lR22mmnvPCFL8xRRx2VrbbaKs1mM7/97W9z+umnZ+HChfnWt7412NMBwOC18GougzVmzJjsuOOOmTlzZvbbb78kS8I7c+bMTJs2bZnnb7XVVvn1r3894LGPf/zjeeqpp/KlL30pkye39+qFOg5ArVp0B9LB0nEAGAYdHxYdB6BWNa+t6zgADIOOD5uWA1AbHR82HQegNn5nfdh0HIDadHHHB71JfOONN86NN96YI488Mscff3yazSXvsNFoZM8998xXv/rVbLLJJoM9HQAMWqO55Kj6nEM1ffr0HHroodlpp52y884757TTTsuCBQty+OGHJ0kOOeSQbLTRRpkxY0ZWXXXVvPjFLx7w+jXXXDNJlnm8HXQcgDpV3XId13EA2kfHh0fHAahTJ6yt6zgArBwdHz4tB6AuOj58Og5AXTqh40nZLddxAOrSzR0f9CbxJNlss83y05/+NE888UTuvvvuJMkWW2yRtddeeyinAYAive1tb8ujjz6aT37yk5k9e3Ze+tKX5vLLL8+kSZOSJA888EB6enpqnuWK6TgA3UzHAaBcOg4A5dJxAChX6R1PtByA7qXjAFC20luu4wB0szo6PqRN4s9Za621svPOO1c6EQBYoeZfjqrPuRKmTZuWadOmLfdzV1999fO+9rzzzlu5QSum4wC0XdUt1/G6pwFAN9Hxyug4AG3XIWvrOg4AK0HHK6XlALSVjldKxwFoqw7peDIyWq7jALRVF3e8cy8dAwAAAAAAAAAAAAAAAAAAwDJW6k7iANBOjeaSo+pzAgDtUXXLdRwA2kfHAaBc1tYBoFw6DgDl0nEAKJeOA0C5urnj7iQOAAAAAAAAAAAAAAAAAABQEHcSB6DzNf9yVH1OAKA9qm65jgNA++g4AJTL2joAlEvHAaBcOg4A5dJxAChXF3fcncQBAAAAAAAAAAAAAAAAAAAK4k7iAHS+Lr6aCwCMCO5ACgDl0nEAKJe1dQAol44DQLl0HADKpeMAUK4u7njH30l8ypQpaTQayxxHHXVU3VMDoE0aLTpoPR0HINHxUuk4AImOl0rHAUisrZdKxwFIdLxUOg5AouOl0nEAEh0vlY4DkHR3xzv+TuK33HJL+vr6ln58++23Z88998xb3vKWGmcFAAyGjgNAuXQcAMql4wBQLh0HgP+/vXuPsquu7///OpOQC5AEQUgIBBJQQRGICsaAWm1TKQuptNYLi+/XCKJ+f15p1AptuYk0whcs3gpo/QYrUrS1oLIqFFKhXqLcjAUviBUlIgnQagLhEjJzfn8MGQgGmIRzzud8Zj8ea+21yMlkv/cekvOc+czZZ9dLxwGgXjoOAPXScQCaru8vEt9xxx03+vVHPvKR7Lnnnvm93/u9QkcEQM+1H9k6vU+6TscBSNL5lut4T+g4AEl0vFI6DkASa+uV0nEAkuh4pXQcgCQ6XikdByCJjldKxwFI0uiOD5Q+gM2xbt26XHjhhTnmmGPSatVys3YAINFxAKiZjgNAvXQcAOql4wBQLx0HgHrpOADUS8cBaKK+v5P4Y1166aX57W9/mze/+c1P+DEPPfRQHnrooZFfr1mzpgdHBkA3tdrDW6f3SW/pOEBzdbrlOt57Og7QXDpePx0HaC5r6/XTcYDm0vH6jabjiZYDjEU6Xj8dB2guHa+fjgM0V5M7XtWdxD/72c/m0EMPzcyZM5/wYxYvXpxp06aNbLNmzerhEQIAT0THAaBeOg4A9dJxAKiXjgNAvUbT8UTLAaAf6TgA1EvHAWiiai4S/+Uvf5mrrroqxx577JN+3AknnJDVq1ePbCtWrOjREQLQNe0ubfSMjgM0nI5XTccBGk7Hq6bjAA1nbb1qOg7QcDpetdF2PNFygDFJx6um4wANp+NV03GAhmtwx8eXPoDRWrJkSXbaaaccdthhT/pxEydOzMSJE3t0VAD0TCVhZdN0HAAtr5eOA6Dj9dJxAHS8XjoOgI7Xa7QdT7QcYMzS8WrpOAA6Xi8dB6CpHa/iTuJDQ0NZsmRJFi5cmPHjq7muHQCIjgNAzXQcAOql4wBQLx0HgHrpOADUS8cBoF46DkCTVVG+q666KrfffnuOOeaY0ocCQAGt9vDW6X3SGzoOQKdbruO9o+MA6Hi9dBwAa+v10nEAdLxeOg6AjtdLxwHQ8XrpOABN7ngVF4m/6lWvSrtdyWcUANiIjgNAvXQcAOql4wBQLx0HgHrpOADUS8cBoF46DkCTVXGROAAN135k6/Q+AYDe6HTLdRwAekfHAaBe1tYBoF46DgD10nEAqJeOA0C9GtzxgdIHAAAAAAAAAAAAAAAAAAAAwOi5kzgAfa/VHt46vU8AoDc63XIdB4De0XEAqJe1dQCol44DQL10HADqpeMAUK8md9ydxAEAAAAAAAAAAAAAAAAAACriTuIA9L/2I1un9wkA9EanW67jANA7Og4A9bK2DgD10nEAqJeOA0C9dBwA6tXgjrtIHIC+12oPb53eJwDQG51uuY4DQO/oOADUy9o6ANRLxwGgXjoOAPXScQCoV5M7PlD6AAAAAAAAAAAAAAAAAAAAABg9dxIHoP+1H9k6vU8AoDc63XIdB4De0XEAqJe1dQCol44DQL10HADqpeMAUK8Gd9ydxAEAAAAAAAAAAAAAAAAAACrSmDuJD0yckIHWhCKz2+vXF5mbJK3xhf8XjxtXdn673Ns1DP3Pb4rNTpI5lz6z2Ozb/2hysdlJsv73X1R0/vh/v6Ho/DGpwe/mwrChNfdmqLVVkdkDkyYVmZskQw8+WGx2kgw98EDZ+b9+qNjs1lZlv4ba7WM/KDZ7z6vLfe2aJD//6rOKzh+85WdF549Z7kDaaO31g2kPDJYZPnFimblJJt+yqtjsJMmEMl87bdDadedysx9aV2x2kuz2LyuLzV6z/47FZifJ1Dyn6PzBH/206PwxS8cp5a57io1ubbtNsdlJktX3Fh1/34Gzi83e9qY7i81Okin/9qNisx88eO9is5Nk3R8dWHT+hMuvKzp/zLK23mhDa+/PUOvh0ofRcwPfuano/PZQoTWQRwzefXe54SVnJ9nph61isz/7y28Wm50kb33OgqLzS/88a8zS8cZrP/Bg2q0yXSn5WreBO+4qNjtJhgbLtnzo57cXm136dYY7X/Q/xWbf+blyP9NIkh3v37/o/Naycq9PGLN0vPGGVtxZ7LVu7fXl1gK2+k3Z15oN/ne5liTJuGlTi82edFfZz31uW1Fs9M/f+7xis5PkuTeV/Rl90bWgsUrHG6/9wP1pt8p8X9wqef1V4ddbPTxnetH5JW33zV8UnT+0w3bFZpd6WenI/K23Ljp/6P77i84fkxrccXcSBwAAAAAAAAAAAAAAAAAAqEhj7iQOQL1a7eGt0/sEAHqj0y3XcQDoHR0HgHpZWweAeuk4ANRLxwGgXjoOAPVqcsddJA5A/2s/snV6nwBAb3S65ToOAL2j4wBQL2vrAFAvHQeAeuk4ANRLxwGgXg3u+EDpAwAAAAAAAAAAAAAAAAAAAGD03EkcgL7XarfTanf27Vc6vT8A4Il1uuU6DgC9o+MAUC9r6wBQLx0HgHrpOADUS8cBoF5N7rg7iQMAAAAAAAAAAAAAAAAAAFTEncQB6H/tR7ZO7xMA6I1Ot1zHAaB3dBwA6mVtHQDqpeMAUC8dB4B66TgA1KvBHXcncQAAAAAAAAAAAAAAAAAAgIq4kzgAfa/VHt46vU8AoDc63XIdB4De0XEAqJe1dQCol44DQL10HADqpeMAUK8md9ydxAEAAAAAAAAAAAAAAAAAACriTuIA9L/2I1un9wkA9EanW67jANA7Og4A9bK2DgD10nEAqJeOA0C9dBwA6tXgjvf1ncQHBwdz4oknZs6cOZk8eXL23HPPnHbaaWm3K/nsAtARrXZ3NrpLxwHYQMfrpOUAJDpeKx0HILG2XisdByDR8VrpOACJjtdKxwFIdLxWOg5A0uyO9/WdxM8444yce+65+dznPpd99tkn119/fY4++uhMmzYt73nPe0ofHgDwJHQcAOqm5QBQLx0HgHrpOADUS8cBoF46DgD10nEAmq6vLxL/zne+k9e85jU57LDDkiSzZ8/OP/7jP+baa68tfGQA9FT7ka3T+6SrdByAEZ1uuY73hJYDkETHK6XjACSxtl4pHQcgiY5XSscBSKLjldJxAJLoeKV0HIAkje74QOkDeDIHHXRQli5dmp/+9KdJkh/84Af51re+lUMPPfQJ/8xDDz2UNWvWbLQBAL2n4wBQt81tuY4DQP/QcQCol44DQL38jBwA6qXjAFAvHQeg6fr6TuLHH3981qxZk7333jvjxo3L4OBgTj/99Bx11FFP+GcWL16cU089tYdHCUC3tdrDW6f3SXfpOAAbdLrlOt4bm9tyHQcYm3S8TjoOQGJtvVY6DkCi47XyM3IAEh2vlY4DkOh4rXQcgKTZHe/rO4l/6Utfyhe+8IVcdNFFufHGG/O5z30uZ511Vj73uc894Z854YQTsnr16pFtxYoVPTxiAGADHQeAum1uy3UcAPqHjgNAvXQcAOrlZ+QAUC8dB4B66TgATdfXdxL/wAc+kOOPPz5vfOMbkyT77rtvfvnLX2bx4sVZuHDhJv/MxIkTM3HixF4eJgDd1n5k6/Q+6SodB2BEp1uu4z2xuS3XcYAxSserpOMAJLG2XikdByCJjlfKz8gBSKLjldJxAJLoeKV0HIAkje54X18kfv/992dgYOObnY8bNy5DQ0OFjgiAUlqVhJVH6TgAj6Xl9dFyADbQ8froOAAb6Hh9dByADXS8PjoOwAY6Xh8dB2ADHa+PjgOwQVM73tcXiR9++OE5/fTTs9tuu2WfffbJ97///Xz0ox/NMcccU/rQAICnoOMAUDctB4B66TgA1EvHAaBeOg4A9dJxAKiXjgPQdH19kfgnPvGJnHjiiXnHO96Ru+66KzNnzszb3/72nHTSSaUPDYBeareHt07vk67ScQBGdLrlOt4TWg5AEh2vlI4DkMTaeqV0HIAkOl4pHQcgiY5XSscBSKLjldJxAJI0uuN9fZH4lClTcs455+Scc84pfSgAwGbScQCom5YDQL10HADqpeMAUC8dB4B66TgA1EvHAWi6vr5IHACSpNUe3jq9TwCgNzrdch0HgN7RcQCol7V1AKiXjgNAvXQcAOql4wBQryZ3fKD0AQAAAAAAAAAAAAAAAAAAADB67iQOQP9rP7J1ep8AQG90uuU6DgC9o+MAUC9r6wBQLx0HgHrpOADUS8cBoF4N7rg7iQMAAAAAAAAAAAAAAAAAAFTEncQB6HutoeGt0/sEAHqj0y3XcQDoHR0HgHpZWweAeuk4ANRLxwGgXjoOAPVqcsddJA5A/2s/snV6nwBAb3S65ToOAL2j4wBQL2vrAFAvHQeAeuk4ANRLxwGgXg3u+EDpAwAAAAAAAAAAAAAAAAAAAGD03EkcgL7Xag9vnd4nANAbnW65jgNA7+g4ANTL2joA1EvHAaBeOg4A9dJxAKhXkzvuTuIAAAAAAAAAAAAAAAAAAAAVacydxIceWpehUpfut8u9ZUB7cLDY7MYr+P89SSbcdlex2etmziw2O0nGPbC+6Py8ZL9ys7/7n+Vmd1O73fl/U4X/jbJ5xu0yI+MGJhaZvf72O4rMTZIMjCs3O0lrXOH5WxX8UnVoqNzsJK0JE4rN/skH9io2O0lu+z/lzj1J9j7j3mKz169cVWx213W65TpeldbWE9Mq1vFfFZmbJOP2nF1sdpK0V91TdH4KrkcMPvhQsdlJMjBhq2KzJ+z+jGKzk2RoYrlzT5K7/8/8YrN3PG9Zsdldp+ONNrDdtAyU6vivyn0/Pm6H7YvNTpI88GDR8ZMvv7HY7MFW4fc2HmgVG/3wcf9dbHaSTD3yN0XnZ7tpxUYP/nZ1sdldZ2290cbPmJ7xA2XW2gb/p9xzysDEMl+7bNBeX/jnlK1yLSu5rp0kg6vXFJt96Cf/otjsJJl6eNnXhWz3nRXFZq+/49fFZnedjjdea8JWabXKPLcWfb3ZDmXXOHNP2e/NMliu5e2hss8RA1O2LTZ7xl8VG50kueUvyr42Y6+bpxSbPXRvuZ/Pd5WOs++eybhJZWZff3OZuUlaax8oNjtJxs/erej8oVV3F5vderjs94XrX/DsYrN3+2q5r5+SZPDucv/fk2T8zjOKzV5/58pis7tKxxtvYNrUYj8jb997X5G5SZJJZdfWt7q97GvdHnr29HLDCz9HtB4u93ONaTf/ttjsvuDas85rcMfdSRwAAAAAAAAAAAAAAAAAAKAijbmTOAD1arWHt07vEwDojU63XMcBoHd0HADqZW0dAOql4wBQLx0HgHrpOADUq8kddydxAAAAAAAAAAAAAAAAAACAiriTOAD9r/3I1ul9AgC90emW6zgA9I6OA0C9rK0DQL10HADqpeMAUC8dB4B6NbjjLhIHoO+12sNbp/cJAPRGp1uu4wDQOzoOAPWytg4A9dJxAKiXjgNAvXQcAOrV5I4PlD4AAAAAAAAAAAAAAAAAAAAARs+dxAHof+328NbpfQIAvdHplus4APSOjgNAvaytA0C9dBwA6qXjAFAvHQeAejW44+4kDgAAAAAAAAAAAAAAAAAAUBF3Egeg77Xaw1un9wkA9EanW67jANA7Og4A9bK2DgD10nEAqJeOA0C9dBwA6tXkjruTOAAAAAAAAAAAAAAAAAAAQEX6/iLxe++9N8cdd1x23333TJ48OQcddFCuu+660ocFQC+1u7TRdToOQBIdr5SOA5BExyum5QBYW6+XjgOg4/XScQB0vF46DoCO10vHAWhyx/v+IvFjjz02V155ZT7/+c/npptuyqte9aosWLAgd9xxR+lDA6BHWu3ubHSfjgOQ6HitdByARMdrpuUAWFuvl44DoOP10nEAdLxeOg6AjtdLxwFocsf7+iLxBx54IF/+8pdz5pln5uUvf3me9axn5ZRTTsmznvWsnHvuuaUPDwB4EjoOAPXScQCom5YDQL10HADqpeMAUC8dB4B66TgATTe+9AE8mfXr12dwcDCTJk3a6PHJkyfnW9/6VqGjAqDnhtrDW6f3SVfpOAAjOt1yHe86HQdghI5XScsBSGJtvVI6DkASHa+UjgOQRMcrpeMAJNHxSuk4AEka3fG+vpP4lClTMn/+/Jx22mn59a9/ncHBwVx44YVZtmxZ7rzzzk3+mYceeihr1qzZaAMAek/HAaBeOg4Addvclus4APQPHQeAellbB4B66TgA1EvHAWi6vr5IPEk+//nPp91uZ5dddsnEiRPz8Y9/PEceeWQGBjZ96IsXL860adNGtlmzZvX4iAHouHaXNrpOxwFIouOV0nEAkuh4xTan5ToOMEZZW6+WjgOg4/Wytg6AjtdLxwHQ8XrpOABN7njfXyS+55575pprrsl9992XFStW5Nprr83DDz+cPfbYY5Mff8IJJ2T16tUj24oVK3p8xADABjoOAPXScQCo2+a0XMcBoL/oOADUy9o6ANRLxwGgXjoOQJONL30Ao7XNNttkm222yW9+85tcccUVOfPMMzf5cRMnTszEiRN7fHQAdFMrSavD777S6uzueAo6DtBsnW65jveWjgM0m47XbzQt13GAscnaev10HKC5dLx+1tYBmkvH66fjAM2l4/XTcYDmanLH+/4i8SuuuCLtdjt77bVXfvazn+UDH/hA9t577xx99NGlDw0AeAo6DgD10nEAqJuWA0C9dBwA6qXjAFAvHQeAeuk4AE3W9xeJr169OieccEJ+9atfZfvtt89rX/vanH766dlqq61KHxoAvdJuD2+d3iddp+MAJOl8y3W8J3QcgCQ6XjEtB8Daer10HAAdr5eOA6Dj9dJxAHS8XjoOQJM73vcXib/+9a/P61//+tKHAUBBrfbw1ul90n06DkDS+ZbreG/oOACJjtdMywGwtl4vHQdAx+ul4wDoeL10HAAdr5eOA9Dkjg+UPgAAqMmnPvWpzJ49O5MmTcq8efNy7bXXPuHHfuYzn8nLXvayPOMZz8gznvGMLFiw4Ek/HgDoLh0HgHrpOADUS8cBoF46DgD10nEAqJuWA0C9et1xF4kD0P/aXdo20xe/+MUsWrQoJ598cm688cbsv//+OeSQQ3LXXXdt8uOvvvrqHHnkkfnGN76RZcuWZdasWXnVq16VO+64Y/OHA0DNdBwA6qXjAFCvPlhb13EA2EI6DgD10nEAqFcfdDzRcgDYIg3uuIvEAWCUPvrRj+atb31rjj766Dzvec/Leeedl6233jr/7//9v01+/Be+8IW84x3vyNy5c7P33nvn7//+7zM0NJSlS5f2+MgBAB0HgHrpOADUS8cBoF46DgD10nEAqJuWA0C9SnR8fKcOHgC6pdVup9XegrdfeYp9JsmaNWs2enzixImZOHHi73z8unXrcsMNN+SEE04YeWxgYCALFizIsmXLRjXz/vvvz8MPP5ztt9/+aRw5ANSn0y3XcQDoHR0HgHqVXlvXcQDYcjoOAPXScQCoV+mOJ1oOAFuqyR13J3EAGm3WrFmZNm3ayLZ48eJNftw999yTwcHBTJ8+faPHp0+fnpUrV45q1gc/+MHMnDkzCxYseNrHDQDoOADUTMcBoG6jabmOA0B/0nEAqJeOA0C9/IwcAOrV7x13J3EA+t/QI1un95lkxYoVmTp16sjDm3onl074yEc+kosvvjhXX311Jk2a1JUZANC3Ot1yHQeA3tFxAKhX5WvrOg5Ao+k4ANRLxwGgXpV3PNFyABqswR13kTgAfa/VbqfVbnd8n0kyderUjUL9RJ75zGdm3LhxWbVq1UaPr1q1KjNmzHjSP3vWWWflIx/5SK666qrst99+W37QAFCpTrdcxwGgd3QcAOpVem1dxwFgy+k4ANRLxwGgXqU7nmg5AGypJnd8YLM+GgAaasKECXnRi16UpUuXjjw2NDSUpUuXZv78+U/4584888ycdtppufzyy3PAAQf04lABgMfRcQCol44DQL10HADqpeMAUC8dB4C6aTkA1KtUx91JHID+135k6/Q+N9OiRYuycOHCHHDAAXnxi1+cc845J2vXrs3RRx+dJHnTm96UXXbZJYsXL06SnHHGGTnppJNy0UUXZfbs2Vm5cmWSZNttt822227bsVMBgL7X6ZbrOAD0jo4DQL36YG1dxwFgC+k4ANRLxwGgXn3Q8UTLAWCLNLjjzblIvDUwvBWZXWZskrQGCg5P0po4sej8oQceLDa7Na7s5749udznfrsbJxSbnSTj7/7vovNXv3B6sdnbrZhZbHaGHkp+XW58L7zhDW/I3XffnZNOOikrV67M3Llzc/nll2f69OH/57fffnsGBh5tzbnnnpt169blz/7szzbaz8knn5xTTjmll4devwfXJYUynqHBQoPLa22zddH57QcfKjd7/cPFZidJ1pWbP/G/7io2O0n2+si6ovNXnL9Dsdmz/r+CXz8OrUtWlhvfCzpOr7V/dWfR+a1pU4vOH7zr7qLzS2qvX19s9uRby3Z88I6yf+8nnD672OzWknLrMK32QFLuS+ee0PFyBu/5n7RaWxWZPW67aUXmJsng//ym2OwkGSi8rt4+4Hnlhn/vpnKzk4zbacdis6e8ruzXT61ttyk6/0cn7VZs9l7H/aDYbB3X8a6aMD4ZKNPx9sPlvi9K4eez9v33F51f8ufzra0nF5udJAMPPFBs9i4fvbbY7CTJ/nsVHf/T9+5ebPazzyj3mpD20Lrkf4qN7wkdL6s1fnxarTIv7WtNKPe6n8Fbbys2O0laW5V9zVPRn1O3C34Nl2T9ylXlhq8qu7b+nLeU+bp9g598bG6x2dv9sMzz3OC6B5NPf6XI7F7R8bIGt94qrfFl/m0PDIwrMjdJsr7w6+xahV+3PVju/AfuKNuyrbYr+PqE1nblZifF/96teUm578m3/kqhn2u0h5KhMqN7ScvLaa8fTHugzPdHg/etLTI3ScZPKfxmAuMLfg2TZOKP7yg3vHBLMlTuSfXhZ5a9VmH8T8q+Zn3dduV+prP1rF2Lzc7QQ8mvyo3vhRIdb85F4gDUq90e3jq9zy3wrne9K+9617s2+XtXX331Rr/+xS9+sUUzAGDM6XTLdRwAekfHAaBefbK2ruMAsAV0HADqpeMAUK8+6Xii5QCw2Rrc8VL35AQAAAAAAAAAAAAAAAAAAGALuJM4AH2v1R7eOr1PAKA3Ot1yHQeA3tFxAKiXtXUAqJeOA0C9dBwA6qXjAFCvJnfcncQBAAAAAAAAAAAAAAAAAAAq4k7iAPS/dnt46/Q+AYDe6HTLdRwAekfHAaBe1tYBoF46DgD10nEAqJeOA0C9GtxxF4kD0PdaQ8Nbp/cJAPRGp1uu4wDQOzoOAPWytg4A9dJxAKiXjgNAvXQcAOrV5I4PlD4AAAAAAAAAAAAAAAAAAAAARs+dxAHof+328NbpfQIAvdHplus4APSOjgNAvaytA0C9dBwA6qXjAFAvHQeAejW44+4kDgAAAAAAAAAAAAAAAAAAUBF3Egeg/7Uf2Tq9TwCgNzrdch0HgN7RcQCol7V1AKiXjgNAvXQcAOql4wBQrwZ33J3EAQAAAAAAAAAAAAAAAAAAKlL0IvH/+I//yOGHH56ZM2em1Wrl0ksv3ej32+12TjrppOy8886ZPHlyFixYkFtvvbXMwQJQTKvd7srG06PjAIyWjvcfHQdgtHS8/+g4AKNlbb0/aTkAo6Hj/UnHARgNHe9POg7AaOh4f9JxAEajyR0vepH42rVrs//+++dTn/rUJn//zDPPzMc//vGcd955+d73vpdtttkmhxxySB588MEeHykARbXb3dl4WnQcgFHT8b6j4wCMmo73HR0HYNSsrfclLQdgVHS8L+k4AKOi431JxwEYFR3vSzoOwKg0uOPjSw4/9NBDc+ihh27y99rtds4555z89V//dV7zmtckSf7hH/4h06dPz6WXXpo3vvGNvTxUAOBxdBwA6qXjAFAvHQeAumk5ANRLxwGgXjoOAPXScQB4ckXvJP5kbrvttqxcuTILFiwYeWzatGmZN29eli1bVvDIAOi5dpKhDm91vJlLtXQcgI10uuU63lU6DsBGdLwqOg7ARqytV0fLARih49XRcQBG6Hh1dByAETpeHR0HYESDO170TuJPZuXKlUmS6dOnb/T49OnTR35vUx566KE89NBDI79es2ZNdw4QAHhCOg4A9dJxAKiXjgNA3bak5ToOAP3B9+QAUC8dB4B66TgA9PGdxLfU4sWLM23atJFt1qxZpQ8JgKep1W53ZaP/6DjA2KTjzaDjAGOTjjeDjgOMTdbWm0HHAcYmHW8OLQcYe3S8OXQcYOzR8ebQcYCxp8kd79uLxGfMmJEkWbVq1UaPr1q1auT3NuWEE07I6tWrR7YVK1Z09TgBgN+l4wBQLx0HgHrpOADUbUtaruMA0B98Tw4A9dJxAKiXjgNAH18kPmfOnMyYMSNLly4deWzNmjX53ve+l/nz5z/hn5s4cWKmTp260QZA5dpJ2u0Ob6VPamzTcQA20vGWlz6hsU3HAdiIjldFxwHYiLX16mxJy3UcYIzS8er4nhyAETpeHR0HYISOV0fHARjR4I6PLzn8vvvuy89+9rORX992221Zvnx5tt9+++y222457rjj8uEPfzjPfvazM2fOnJx44omZOXNmjjjiiHIHDQAk0XEAqJmOA0C9dBwA6qblAFAvHQeAeuk4ANRLxwHgyRW9SPz666/PK1/5ypFfL1q0KEmycOHCXHDBBfmLv/iLrF27Nm9729vy29/+Ni996Utz+eWXZ9KkSaUOGYASNrwDS6f3ydOi4wCMWqdbruNPm44DMGo63nd0HIBRs7bel7QcgFHR8b6k4wCMio73JR0HYFR0vC/pOACj0uCOF71I/BWveEXaT/KJarVa+dCHPpQPfehDPTwqAPrOUJJWF/bJ06LjAIxap1uu40+bjgMwajred3QcgFGztt6XtByAUdHxvqTjAIyKjvclHQdgVHS8L+k4AKPS4I4PlD4AAAAAAAAAAAAAAAAAAAAARq/oncQBYDRa7XZaT/LuX1u6TwCgNzrdch0HgN7RcQCol7V1AKiXjgNAvXQcAOql4wBQryZ33J3EAQAAAAAAAAAAAAAAAAAAKuJO4gD0v3Z7eOv0PgGA3uh0y3UcAHpHxwGgXtbWAaBeOg4A9dJxAKiXjgNAvRrccXcSBwAAAAAAAAAAAAAAAAAAqIg7iQPQ/xr8bi4AMCa4AykA1EvHAaBe1tYBoF46DgD10nEAqJeOA0C9GtxxdxIHAAAAAAAAAAAAAAAAAACoiDuJA9D/GvxuLgAwJrgDKQDUS8cBoF7W1gGgXjoOAPXScQCol44DQL0a3PExf5F4+5H/EevbDxc+kjJa7Vaj5w8V/P9e+twHBh8qNntw3YPFZifJ+oLnniTrHy53/uuHyp37+qF1SR593u2ooSSd/ic11OH90RUjHX/k71cJTf0aIkkG2uU+70nSLvi5Lzl72EC50QVbkiTtobKf+8H7y7e05OyudDzpfMt1vApN7/hA6e/HC37ek2SweEvLabXLPUm1C3e89P/3wbUFO17w3DfM1nE6qR/W1Qfa5b4vKv18VvrriKH1Bdd3C3/u2wW/hmoXXocZGNqq6PyhBwquq+v45u+Tvtb078dLPpcnZX8+nZT9GfVA4e9Jhwq2tN0eLDY7SVL45+NDD5b8+XjJ57rK1tU37JO+9+j35OX+fpfsWbu9vtjspOz6blL459SVvOC1O0q/xrLo+KLfkw+uK/MS5g2vb9RxOm2k4+vLfY0+ULIlhb8vTKvs83nJny0MFF4PKfl96fqSP9NI4X9zKfya9ULnbl2dbumHtfWiP6cu3fGhcYXnF/zcF/4apj1Y7nNfuuOlX5/g2jPXnnXSmL9I/N57702SfKv9taSJ65il/yKWXbcvq/Tn/ucFZ59fcHaSH5YdX/Zz3wfuvffeTJs2rfRhMEZs6PjVd3+u8JE01L2lD6DBSn7d+quCs/vBkeVG/6Tc6BE6TieNdPxXf1/4SAopvH5ZfH6TlVwLub3g7H7wZ6UPoCwdp5M2dPyb6y4pdxCFfwZdVOmOX1d4fkl3lT6AgkqvA/15udH9sBSi43RS478f/5/SB1BYye9J1xac3XTfb+78X5QbPULH6bQNLb/m3i8VPpKGKv16L8oo/brS0u+7u+ifio0u/T25jtNpGzr+ne+eWfhICrmj9AE0WOmfqfx3wdkNf812vnZp6SMoRsfptJHvx+/5h8JHUsivSx8AjfRfpQ+gsKu+XPoIitLyzhrzF4nPnDkzK1asyJQpU9LagnfXWLNmTWbNmpUVK1Zk6tSpXTjC/pzd9PnOvZnnXnp+7efebrdz7733ZubMmR0/tla7nVaH3yWm0/ujO3Tc/NpmN32+c6/33LvZ8aTzLdfxOtTc8dLznXszz730/Cafe+n5Ok4/0vE6Zzd9vnNv5rmXnt+0jm/YJ/1Nx+uc3fT5TT730vOdu47Tf55Oy5v8b7r0fOfezHMvPd+56zj9R8frnN/kcy8937k389yf7nwdp1tqXluv+d90zbObPr/J5156fu3n7tqz7hjzF4kPDAxk1113fdr7mTp1apF/OKVnN32+c2/muZeeX/O5excXOk3Hza91dtPnO/c6z13H6bSx0PHS8517M8+99Pwmn3vp+TpOP9Hxumc3fb5zb+a5l56v4/QTHa97dtPnN/ncS8937jpO/+hEy5v8b7r0fOfezHMvPd+56zj9Q8frnt/kcy8937k389yfznwdpxvGwtp6rf+ma5/d9PlNPvfS82s+dy3vvDF/kTgAY0C7Pbx1ep8AQG90uuU6DgC9o+MAUC9r6wBQLx0HgHrpOADUS8cBoF4N7vhA6QMAAAAAAAAAAAAAAAAAAABg9NxJ/ClMnDgxJ598ciZOnNio2U2f79ybee6l5zf53J/SUDtpdfjdV4bqeDcXnh7/pps5v8nnXnq+c2/muY9Kp1uu441Q+u+15xTn3rT5TT730vNLn/tT0nG2QOm/103+N93k+c69medeen7pc39K1tbZAqX/Xjf533ST5zf53EvPd+46zthS+u91k+c792aee+n5zl3HGVtK/71u8vwmn3vp+c69mefeD/OflI6zhTynOPemzW/yuZee3+Rzf0oN7nir3a7knucANM6aNWsybdq0LNjjvRk/rrNfQKwffChX/fxjWb16daZOndrRfQMAw7rVch0HgO7TcQCol7V1AKiXjgNAvXQcAOql4wBQLx1PBkofAAAAAAAAAAAAAAAAAAAAAKM3vvQBAMBTayftduf3CQD0SKdbruMA0Ds6DgD1srYOAPXScQCol44DQL10HADq1dyOu5M4AAAAAAAAAAAAAAAAAABARdxJHID+1+7Cu7l0/N1hAIAn1OmW6zgA9I6OA0C9rK0DQL10HADqpeMAUC8dB4B6Nbjj7iT+JD71qU9l9uzZmTRpUubNm5drr722J3P/4z/+I4cffnhmzpyZVquVSy+9tCdzN1i8eHEOPPDATJkyJTvttFOOOOKI3HLLLT2Zfe6552a//fbL1KlTM3Xq1MyfPz9f//rXezL78T7ykY+k1WrluOOO68m8U045Ja1Wa6Nt77337snsDe644478r//1v7LDDjtk8uTJ2XfffXP99df3ZPbs2bN/5/xbrVbe+c53dn324OBgTjzxxMyZMyeTJ0/OnnvumdNOOy3tHj6R33vvvTnuuOOy++67Z/LkyTnooINy3XXXdWXWUz3HtNvtnHTSSdl5550zefLkLFiwILfeemtXjgW6qVTHk7It1/FHNa3lOq7jiY4zdui4juu4jveKjkN3NHFtvWTHk/5quY43o+NJ+ZbrOHSHjuu4jut4L+g4dIeO63iTOp6Ua7mO6zh0g47ruI4343tyHX+UjjOW6LiO67iO90qvWq7j9XGR+BP44he/mEWLFuXkk0/OjTfemP333z+HHHJI7rrrrq7PXrt2bfbff/986lOf6vqsTbnmmmvyzne+M9/97ndz5ZVX5uGHH86rXvWqrF27tuuzd91113zkIx/JDTfckOuvvz6///u/n9e85jX54Q9/2PXZj3Xdddfl/PPPz3777dfTufvss0/uvPPOke1b3/pWz2b/5je/ycEHH5ytttoqX//61/OjH/0oZ599dp7xjGf0ZP5111230blfeeWVSZLXve51XZ99xhln5Nxzz80nP/nJ/PjHP84ZZ5yRM888M5/4xCe6PnuDY489NldeeWU+//nP56abbsqrXvWqLFiwIHfccUfHZz3Vc8yZZ56Zj3/84znvvPPyve99L9tss00OOeSQPPjggx0/llEbandnY8wq2fGkbMt1fFjTWq7jOr5BX3Y80XE2i47ruI7ruI7rOHVr6tp6yY4n/dNyHW9Ox5PyLdfxUbC2zmbScR3XcR3XcR2nXjqu403qeFK25Tqu409Jx9lMOq7jOt6c78l1/FE6zlih4zqu4zo+Fl/rpuP1dbzV7uXbFVRk3rx5OfDAA/PJT34ySTI0NJRZs2bl3e9+d44//vieHUer1coll1ySI444omczH+/uu+/OTjvtlGuuuSYvf/nLez5/++23z//9v/83b3nLW3oy77777ssLX/jC/N3f/V0+/OEPZ+7cuTnnnHO6PveUU07JpZdemuXLl3d91qYcf/zx+fa3v51vfvObReY/3nHHHZfLLrsst956a1qtVldnvfrVr8706dPz2c9+duSx1772tZk8eXIuvPDCrs5OkgceeCBTpkzJV77ylRx22GEjj7/oRS/KoYcemg9/+MNdm/3455h2u52ZM2fmfe97X97//vcnSVavXp3p06fnggsuyBvf+MauHcumrFmzJtOmTcuC3d+V8QMTO7rv9UMP5apffjKrV6/O1KlTO7pvyuuXjiflW960jifNbLmO63jSfx1PutdyHR/bdPxROq7jJei4jm+g42ypfml50zueWFvvhSZ3PCnbch1/ctbW2VI6PkzHdbwEHdfxDXScLaXjw3S8GR1P+qvlOq7jG+g4W0rHh+m4jpfSlJ+R6/iT03G2lI4P03EdL6UpHU/KtVzH6+i4O4lvwrp163LDDTdkwYIFI48NDAxkwYIFWbZsWcEjK2P16tVJhoPZS4ODg7n44ouzdu3azJ8/v2dz3/nOd+awww7b6P9/r9x6662ZOXNm9thjjxx11FG5/fbbezb7q1/9ag444IC87nWvy0477ZQXvOAF+cxnPtOz+Y+1bt26XHjhhTnmmGN6snB+0EEHZenSpfnpT3+aJPnBD36Qb33rWzn00EO7PjtJ1q9fn8HBwUyaNGmjxydPntzTd/RJkttuuy0rV67c6O//tGnTMm/evLLPf+2h7myMSTq+saZ1PGlmy3Vcx5M+7nii44yajm9Mx3tLx3V8Ax1/HB1nM2j5o0p1PLG2ruO96XhStuU6PkrW1tkMOv4oHe8tHdfxDXT8cXSczaDjj9Lx3vJaNx3fQMcfR8fZDDr+KB3vLR0f1qSfkev4KOk4m0HHH6XjvaXjw5rU8aR/Wq7j/Wl86QPoR/fcc08GBwczffr0jR6fPn16fvKTnxQ6qjKGhoZy3HHH5eCDD87zn//8nsy86aabMn/+/Dz44IPZdtttc8kll+R5z3teT2ZffPHFufHGG3Pdddf1ZN5jzZs3LxdccEH22muv3HnnnTn11FPzspe9LDfffHOmTJnS9fk///nPc+6552bRokX5y7/8y1x33XV5z3vekwkTJmThwoVdn/9Yl156aX7729/mzW9+c0/mHX/88VmzZk323nvvjBs3LoODgzn99NNz1FFH9WT+lClTMn/+/Jx22ml57nOfm+nTp+cf//Efs2zZsjzrWc/qyTFssHLlyiTZ5PPfht8rot0e3jq9T8YkHX9U0zqeNLflOq7jSR93POl8y3V8zNLxR+l4b+n4MB3X8U3ScTaDlg8r0fHE2rqO97bjSdmW6/goWVtnM+j4MB3vLR0fpuM6vkk6zmbQ8WE63lte6zZMx3V8k3SczaDjw3S8t3T8UU36GbmOj5KOsxl0fJiO95aOP6pJHU/6p+U63p9cJM6Teuc735mbb765p+8osddee2X58uVZvXp1/vmf/zkLFy7MNddc0/VYr1ixIu9973tz5ZVX/s67avTCY985ZL/99su8efOy++6750tf+lLe8pa3dH3+0NBQDjjggPzN3/xNkuQFL3hBbr755px33nk9D/VnP/vZHHrooZk5c2ZP5n3pS1/KF77whVx00UXZZ599snz58hx33HGZOXNmz87985//fI455pjssssuGTduXF74whfmyCOPzA033NCT+cDY1KSOJ81uuY7rODD26Hhv6fgwHddxoDNKdDyxtp7oeC87npRvuY4D3aDjvaXjw3Rcx4HO0PHe8lq3YTqu40Bn6Hhv6fijmvYzch0HukHHe0vHH9W0jidazhMbKH0A/eiZz3xmxo0bl1WrVm30+KpVqzJjxoxCR9V773rXu3LZZZflG9/4RnbdddeezZ0wYUKe9axn5UUvelEWL16c/fffPx/72Me6PveGG27IXXfdlRe+8IUZP358xo8fn2uuuSYf//jHM378+AwODnb9GB5ru+22y3Oe85z87Gc/68m8nXfe+Xe+GHruc5+b22+/vSfzN/jlL3+Zq666Kscee2zPZn7gAx/I8ccfnze+8Y3Zd99987//9//On//5n2fx4sU9O4Y999wz11xzTe67776sWLEi1157bR5++OHssccePTuGJCPPcX33/DfU7s7GmKTjw5rW8aTZLddxHU/6uOOJjjNqOj5Mx3Vcx3V8g754/tNxNoOWl+t4Ym19Ax3vndIt1/FRsLbOZtBxHddxHdfxR/XFc5+Osxl0XMeb1vGkP1qu4zr+hHSczaDjOq7jw5ryPbmOD9Nxxgod13EdH6bjzXqtm473JxeJb8KECRPyohe9KEuXLh15bGhoKEuXLs38+fMLHllvtNvtvOtd78oll1ySf//3f8+cOXOKHs/Q0FAeeuihrs/5gz/4g9x0001Zvnz5yHbAAQfkqKOOyvLlyzNu3LiuH8Nj3Xffffmv//qv7Lzzzj2Zd/DBB+eWW27Z6LGf/vSn2X333Xsyf4MlS5Zkp512ymGHHdazmffff38GBjZ+Ohw3blyGhoZ6dgwbbLPNNtl5553zm9/8JldccUVe85rX9HT+nDlzMmPGjI2e/9asWZPvfe97jXj+Y2zQ8WZ2PGl2y3VcxxMdZ2zQcR3X8WE6ruOJjlOnJre83zqeWFvX8e7rl5brOHSGjuu4juu4jg/TcWqk4zretI4n/dFyHddx6AQd13EdH9aU78l1fJiOM1bouI7r+DAdb9Zr3XS8P40vfQD9atGiRVm4cGEOOOCAvPjFL84555yTtWvX5uijj+767Pvuu2+jd/C47bbbsnz58my//fbZbbfduj7/ne98Zy666KJ85StfyZQpU7Jy5cokybRp0zJ58uSuzj7hhBNy6KGHZrfddsu9996biy66KFdffXWuuOKKrs5NkilTpuT5z3/+Ro9ts8022WGHHX7n8W54//vfn8MPPzy77757fv3rX+fkk0/OuHHjcuSRR3Z9dpL8+Z//eQ466KD8zd/8TV7/+tfn2muvzac//el8+tOf7sn8ZPiLsiVLlmThwoUZP753T0+HH354Tj/99Oy2227ZZ5998v3vfz8f/ehHc8wxx/TsGK644oq02+3stdde+dnPfpYPfOAD2XvvvbvynPNUzzHHHXdcPvzhD+fZz3525syZkxNPPDEzZ87MEUcc0fFjGbV2e3jr9D4Zs0p2PCnb8qZ2PGl2y3Vcx/u640nnW67jY5qO6/gGOq7jvaDjo6DjbKamrq2X7HhibV3He9/xpHzLdXwUrK2zmXRcxxMd13Ed13FqpeM6njSn40n5luu4jj8pHWcz6biOJzrelO/JdVzHGXt0XMcTHdfxsfdaNx1/3D4r4CLxJ/CGN7whd999d0466aSsXLkyc+fOzeWXX57p06d3ffb111+fV77ylSO/XrRoUZJk4cKFueCCC7o+/9xzz02SvOIVr9jo8SVLluTNb35zV2ffddddedOb3pQ777wz06ZNy3777Zcrrrgif/iHf9jVuf3gV7/6VY488sj893//d3bccce89KUvzXe/+93suOOOPZl/4IEH5pJLLskJJ5yQD33oQ5kzZ07OOeecHHXUUT2ZnyRXXXVVbr/99p4GMkk+8YlP5MQTT8w73vGO3HXXXZk5c2be/va356STTurZMaxevTonnHBCfvWrX2X77bfPa1/72px++unZaqutOj7rqZ5j/uIv/iJr167N2972tvz2t7/NS1/60lx++eWZNGlSx48FuqVkx5OyLdfxckq2XMd1XMcZS3Rcx0vQcR3Xceicpq6tl+x40uyW63iZjiflW67j0Hk6/oqNHtfx7tNxHddx6Bwdf8VGj+t49zX9tW46ruPQSTr+io0e1/Hua3rHk+b+jFzHofN0/BUbPa7j3afjze140ruW63h9Wu12JZezA9A4a9asybRp07Jg57dn/MCEju57/dC6XHXn+Vm9enWmTp3a0X0DAMO61XIdB4Du03EAqJe1dQCol44DQL10HADqpeMAUC8ddydxAGrQbg9vnd4nANAbnW65jgNA7+g4ANTL2joA1EvHAaBeOg4A9dJxAKhXgzs+UPoAAAAAAAAAAAAAAAAAAAAAGD13Egeg/w0NJRnqwj4BgJ7odMt1HAB6R8cBoF7W1gGgXjoOAPXScQCol44DQL0a3HF3EgcAAAAAAAAAAAAAAAAAAKiIO4kD0P/a7eGt0/sEAHqj0y3XcQDoHR0HgHpZWweAeuk4ANRLxwGgXjoOAPVqcMfdSRwAAAAAAAAAAAAAAAAAAKAi7iQOQP9r8Lu5AMCY4A6kAFAvHQeAellbB4B66TgA1EvHAaBeOg4A9Wpwx91JHAAAAAAAAAAAAAAAAAAAoCIuEocxYvbs2TnnnHOe9GNOOeWUzJ07tyfHAx011O7OBtAndJwxT8eBMUzHGfN0HBjDdJwxz9o6MMZpOWOajgNjnI4zpuk4MMbpOGOajgNjnI4zpjW44y4Sp5He/OY354gjjtjosX/+53/OpEmTcvbZZ3dl5tVXX51WqzWyTZ8+Pa997Wvz85//vCP7v+666/K2t71t5NetViuXXnrpRh/z/ve/P0uXLu3IPOildnuoKxtQJx2H+ug4sIGOQ310HNhAx6E+1taBx9JyqIuOA4+l41AXHQceS8ehLjoOPJaOQ12a3HEXiUOSv//7v89RRx2Vc889N+973/u6OuuWW27Jr3/96/zTP/1TfvjDH+bwww/P4ODg097vjjvumK233vpJP2bbbbfNDjvs8LRnAUA/0XEAqJeOA0C9dBwA6qblAFAvHQeAeuk4ANRLx4F+5SJxGu/MM8/Mu9/97lx88cU5+uijRx7/yle+khe+8IWZNGlS9thjj5x66qlZv359kuSYY47Jq1/96o328/DDD2ennXbKZz/72Sedt9NOO2XnnXfOy1/+8px00kn50Y9+lJ/97GdJknPPPTd77rlnJkyYkL322iuf//znR/5cu93OKaeckt122y0TJ07MzJkz8573vGfk92fPnp1zzjln5L+T5E/+5E/SarVGfn3KKadk7ty5I39maGgoH/rQh7Lrrrtm4sSJmTt3bi6//PKR3//FL36RVquVf/mXf8krX/nKbL311tl///2zbNmy0X1yoVPa7WSow1u7XfqsgA7QcR2nEp1uuY7DmKDjOk4ldBzYBB3XcSphbR14Alqu5VRAx4EnoOM6TgV0HHgCOq7jVEDHgSeg4zpOBRrccReJ02gf/OAHc9ppp+Wyyy7Ln/zJn4w8/s1vfjNvetOb8t73vjc/+tGPcv755+eCCy7I6aefniQ59thjc/nll+fOO+8c+TOXXXZZ7r///rzhDW8Y9fzJkycnSdatW5dLLrkk733ve/O+970vN998c97+9rfn6KOPzje+8Y0kyZe//OX87d/+bc4///zceuutufTSS7Pvvvtucr/XXXddkmTJkiW58847R379eB/72Mdy9tln56yzzsp//ud/5pBDDskf//Ef59Zbb93o4/7qr/4q73//+7N8+fI85znPyZFHHjnyRQsAlKLjOg5AvXRcxwGol47rOAB103ItB6BeOq7jANRLx3UcgHrpuI5Dv3OROI319a9/PWeeeWa+8pWv5A/+4A82+r1TTz01xx9/fBYuXJg99tgjf/iHf5jTTjst559/fpLkoIMO+p13W1myZEle97rXZdtttx3V/DvvvDNnnXVWdtlll+y1114566yz8uY3vznveMc78pznPCeLFi3Kn/7pn+ass85Kktx+++2ZMWNGFixYkN122y0vfvGL89a3vnWT+95xxx2TJNttt11mzJgx8uvHO+uss/LBD34wb3zjG7PXXnvljDPOyNy5c0feFWaD97///TnssMPynOc8J6eeemp++ctfjrwDDfREu92dDaiWjus4ldFx4DF0XMepjI4Dj6HjOk5lrK0Dj6PlWk5FdBx4HB3XcSqi48Dj6LiOUxEdBx5Hx3WcijS44y4Sp7H222+/zJ49OyeffHLuu+++jX7vBz/4QT70oQ9l2223Hdne+ta35s4778z999+fZPgdXZYsWZIkWbVqVb7+9a/nmGOOecq5u+66a7bZZpvMnDkza9euzZe//OVMmDAhP/7xj3PwwQdv9LEHH3xwfvzjHydJXve61+WBBx7IHnvskbe+9a255JJLntY7qqxZsya//vWvn3TmBvvtt9/If++8885JkrvuumuLZwPA06XjOg5AvXRcxwGol47rOAB103ItB6BeOq7jANRLx3UcgHrpuI5DDVwkTmPtsssuufrqq3PHHXfkj/7oj3LvvfeO/N59992XU089NcuXLx/Zbrrpptx6662ZNGlSkuRNb3pTfv7zn2fZsmW58MILM2fOnLzsZS97yrnf/OY385//+Z9Zs2ZNli9fnnnz5o3qeGfNmpVbbrklf/d3f5fJkyfnHe94R17+8pfn4Ycf3rJPwGbYaqutRv671WolSYaGhro+F0YMDXVnA6ql46On4/QFHQceQ8dHT8fpCzoOPIaOj56O0xesrQOPo+Wjp+UUp+PA4+j46Ok4xek48Dg6Pno6TnE6DjyOjo+ejlNcgzvuInEabffdd88111yTlStXbhTrF77whbnlllvyrGc963e2gYHhfzY77LBDjjjiiCxZsiQXXHBBjj766FHNnDNnTvbcc89MmTJlo8ef+9zn5tvf/vZGj33729/O8573vJFfT548OYcffng+/vGP5+qrr86yZcty0003bXLOVlttlcHBwSc8jqlTp2bmzJlPORP6QrvdnQ2omo7rOBXRceBxdFzHqYiOA4+j4zpORaytA5ug5VpOJXQc2AQd13EqoePAJui4jlMJHQc2Qcd1nEo0uOPjSx8AlDZr1qxcffXVeeUrX5lDDjkkl19+eU466aS8+tWvzm677ZY/+7M/y8DAQH7wgx/k5ptvzoc//OGRP3vsscfm1a9+dQYHB7Nw4cKndRwf+MAH8vrXvz4veMELsmDBgnzta1/Lv/zLv+Sqq65KklxwwQUZHBzMvHnzsvXWW+fCCy/M5MmTs/vuu29yf7Nnz87SpUtz8MEHZ+LEiXnGM56xyZknn3xy9txzz8ydOzdLlizJ8uXL84UvfOFpnQsA9IqO6zgA9dJxHQegXjqu4wDUTcu1HIB66biOA1AvHddxAOql4zoO/cydxCHJrrvumquvvjr33HNPDjnkkMyfPz+XXXZZ/u3f/i0HHnhgXvKSl+Rv//ZvfyeKCxYsyM4775xDDjkkM2fOfFrHcMQRR+RjH/tYzjrrrOyzzz45//zzs2TJkrziFa9Ikmy33Xb5zGc+k4MPPjj77bdfrrrqqnzta1/LDjvssMn9nX322bnyyisza9asvOAFL9jkx7znPe/JokWL8r73vS/77rtvLr/88nz1q1/Ns5/97Kd1LtBp7aGhrmzA2KDjOk7/03Hgiei4jtP/dBx4Ijqu4/Q/a+vAk9FyLae/6TjwZHRcx+lvOg48GR3XcfqbjgNPRsd1nP7W5I632u1K7nkOfei+++7LLrvskiVLluRP//RPSx8OjDlr1qzJtGnT8vtbvzHjWxM6uu/17XX59/svzurVqzN16tSO7huog45D93Wr5ToO6Dh0n44D3aLj0H3W1oFu0nLoLh0HuknHobt0HOgmHYfu0nGgm3QcukvHk/GlDwBqNDQ0lHvuuSdnn312tttuu/zxH/9x6UOCsa3dTtLh9zTxHinQWDoOBXS65ToOjaXjUICOAx2i41CAtXWgg7QcekzHgQ7ScegxHQc6SMehx3Qc6CAdhx5rcMddJA5b4Pbbb8+cOXOy66675oILLsj48f4pAUAtdBwA6qXjAFAvHQeAumk5ANRLxwGgXjoOAPXScaBXPLvAFpg9e3balbwTBIwJQ+2k1cx3cwE6T8ehgE633L9haCwdhwJ0HOgQHYcCrK0DHaTl0GM6DnSQjkOP6TjQQToOPabjQAfpOPRYgzs+UPoAAAAAAAAAAAAAAAAAAAAAGD13Egeg/7XbSYa6sE8AoCc63XIdB4De0XEAqJe1dQCol44DQL10HADqpeMAUK8Gd9xF4gD0vfZQO+1WZ8PariTUADAWdLrlOg4AvaPjAFAva+sAUC8dB4B66TgA1EvHAaBeTe74QOkDAAAAAAAAAAAAAAAAAAAAYPTcSRyA/tceSjLUhX0CAD3R6ZbrOAD0jo4DQL2srQNAvXQcAOql4wBQLx0HgHo1uOPuJA4Am+FTn/pUZs+enUmTJmXevHm59tprn/Tj/+mf/il77713Jk2alH333Tf/+q//2qMjBQAeT8cBoF46DgD10nEAqJeOA0C9dBwA6qblAFCvXnfcReIA9L32ULsr2+b64he/mEWLFuXkk0/OjTfemP333z+HHHJI7rrrrk1+/He+850ceeSRectb3pLvf//7OeKII3LEEUfk5ptvfrqfEgCoio4DQL10HADq1Q9r6zoOAFtGxwGgXjoOAPXqh44nWg4AW6LJHW+12+3NP1IA6IE1a9Zk2rRpeUXrTzK+tVVH972+/XCubl+S1atXZ+rUqaP6M/PmzcuBBx6YT37yk0mSoaGhzJo1K+9+97tz/PHH/87Hv+ENb8jatWtz2WWXjTz2kpe8JHPnzs15553XmRMBgD7WrZbrOAB0n44DQL36aW1dxwFg8+g4ANRLxwGgXv3U8UTLAWBz6Lg7iQNQg/ZQd7bNsG7dutxwww1ZsGDByGMDAwNZsGBBli1btsk/s2zZso0+PkkOOeSQJ/x4ABizdBwA6qXjAFCvwmvrOg4AT4OOA0C9dBwA6lW444mWA8AWa3DHx2/WUQJAAevzcNLuwj4z/I4xjzVx4sRMnDjxdz7+nnvuyeDgYKZPn77R49OnT89PfvKTTc5YuXLlJj9+5cqVT+fQAaA6nW65jgNA7+g4ANSr9Nq6jgPAltNxAKiXjgNAvUp3PNFyANhSTe64i8QB6FsTJkzIjBkz8q2V/9qV/W+77baZNWvWRo+dfPLJOeWUU7oyDwCappst13EA6C4dB4B6WVsHgHrpOADUS8cBoF46DgD10nEXiQPQxyZNmpTbbrst69at68r+2+12Wq3WRo9t6p1ckuSZz3xmxo0bl1WrVm30+KpVqzJjxoxN/pkZM2Zs1scDwFjTzZbrOAB0l44DQL36ZW1dxwFg8+k4ANRLxwGgXv3S8UTLAWBz6biLxAHoc5MmTcqkSZNKH0YmTJiQF73oRVm6dGmOOOKIJMnQ0FCWLl2ad73rXZv8M/Pnz8/SpUtz3HHHjTx25ZVXZv78+T04YgDoD/3Qch0HgC2j4wBQLx0HgHrpOADUS8cBoF790PFEywFgSzS94y4SB4BRWrRoURYuXJgDDjggL37xi3POOedk7dq1Ofroo5Mkb3rTm7LLLrtk8eLFSZL3vve9+b3f+72cffbZOeyww3LxxRfn+uuvz6c//emSpwEAjaTjAFAvHQeAeuk4ANRLxwGgXjoOAHXTcgCoV4mOu0gcAEbpDW94Q+6+++6cdNJJWblyZebOnZvLL78806dPT5LcfvvtGRgYGPn4gw46KBdddFH++q//On/5l3+ZZz/72bn00kvz/Oc/v9QpAEBj6TgA1EvHAaBeOg4A9dJxAKiXjgNA3bQcAOpVouOtdrvd7viZAAAAAAAAAAAAAAAAAAAA0BUDT/0hAAAAAAAAAAAAAAAAAAAA9AsXiQMAAAAAAAAAAAAAAAAAAFTEReIAAAAAAAAAAAAAAAAAAAAVcZE4AAAAAAAAAAAAAAAAAABARVwkDgAAAAAAAAAAAAAAAAAAUBEXiQMAAAAAAAAAAAAAAAAAAFTEReIAAAAAAAAAAAAAAAAAAAAVcZE4AAAAAAAAAAAAAAAAAABARVwkDgAAAAAAAAAAAAAAAAAAUBEXiQMAAAAAAAAAAAAAAAAAAFTEReIAAAAAAAAAAAAAAAAAAAAVcZE4AAAAAAAAAAAAAAAAAABARf5/SlIxyxONuKIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 4000x500 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x500 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"How is your\"\n",
    "visualize_attention(model_moe, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chtIERWFlLQR",
   "metadata": {
    "id": "chtIERWFlLQR"
   },
   "source": [
    "## Definición: MoE + Greedy decoding, Temperature and top_K/top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7bd7a",
   "metadata": {
    "id": "a6d7bd7a"
   },
   "outputs": [],
   "source": [
    "# TODO Implement Greedy decoding, Temperature and top_k/top_p\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_V3(\n",
    "    prompt: str,\n",
    "    max_new_tokens: int = 100,\n",
    "    use_cache: bool = True,\n",
    "    strategy: str = 'temperature', # 'greedy', 'temperature', 'top-k', 'top-p'\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int = None,\n",
    "    top_p: float = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera texto a partir de un prompt inicial utilizando diferentes estrategias de muestreo.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): El texto inicial para comenzar la generación.\n",
    "        max_new_tokens (int): El número máximo de nuevos tokens a generar.\n",
    "        use_cache (bool): Si se debe usar el caché KV para acelerar la inferencia.\n",
    "        strategy (str): La estrategia de muestreo a utilizar. Opciones:\n",
    "                        'greedy': Selecciona el token con la probabilidad más alta.\n",
    "                        'temperature': Muestreo con ajuste de temperatura.\n",
    "                        'top-k': Muestreo de los k tokens más probables.\n",
    "                        'top-p': Muestreo de los tokens dentro de una masa de probabilidad 'p'.\n",
    "        temperature (float): Factor de temperatura para el muestreo. Solo relevante para 'temperature', 'top-k', 'top-p'.\n",
    "                             Valores > 1.0 hacen el muestreo más aleatorio.\n",
    "                             Valores < 1.0 hacen el muestreo más determinista.\n",
    "        top_k (int): Número de tokens a considerar para el muestreo Top-K. Solo relevante para 'top-k'.\n",
    "                     Debe ser un entero positivo.\n",
    "        top_p (float): Masa de probabilidad acumulada para el muestreo Top-P. Solo relevante para 'top-p'.\n",
    "                       Debe ser un valor entre 0.0 y 1.0.\n",
    "    \"\"\"\n",
    "    model_moe.eval() # Asegura que el modelo esté en modo evaluación (desactiva dropout, etc.)\n",
    "    idx = torch.tensor(encode(prompt), dtype=torch.long)[None, :].to(device)\n",
    "    kv_cache = None\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Preparar la entrada para el modelo, usando el último token si hay caché\n",
    "        if use_cache and kv_cache is not None:\n",
    "            idx_cond = idx[:, -1:] # Solo el último token para la siguiente predicción\n",
    "        else:\n",
    "            # Si no hay caché o es la primera iteración, usar el bloque completo\n",
    "            idx_cond = idx[:, -config.block_size:]\n",
    "\n",
    "        # Realizar una pasada hacia adelante a través del modelo\n",
    "        out = model_moe(idx_cond, kv_cache=kv_cache) if use_cache else model_moe(idx_cond)\n",
    "\n",
    "        # Desempaquetar la salida: logits y (opcionalmente) el nuevo caché KV\n",
    "        if isinstance(out, tuple):\n",
    "            logits, kv_cache = out\n",
    "        else:\n",
    "            logits = out\n",
    "            kv_cache = None\n",
    "\n",
    "        # Obtener los logits del último token predicho\n",
    "        logits = logits[:, -1, :] # logit para el último token en la secuencia\n",
    "\n",
    "        # Aplicar temperatura si es diferente de 1.0\n",
    "        if temperature != 1.0 and temperature != 0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "        # Aplicar el muestreo según la estrategia\n",
    "        if strategy == 'greedy':\n",
    "            next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        elif strategy == 'temperature':\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        elif strategy == 'top-k':\n",
    "            if top_k is None or top_k <= 0:\n",
    "                raise ValueError(\"top_k debe ser un entero positivo para la estrategia 'top-k'.\")\n",
    "\n",
    "            # Filtrar los k valores más grandes\n",
    "            v, i = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            out = logits.clone().fill_(-float('inf')) # Copia y rellena con -inf\n",
    "            out.scatter_(1, i, v) # Vuelve a colocar los valores top-k\n",
    "            probs = F.softmax(out, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        elif strategy == 'top-p':\n",
    "            if top_p is None or not (0.0 < top_p <= 1.0):\n",
    "                raise ValueError(\"top_p debe ser un float entre 0.0 y 1.0 para la estrategia 'top-p'.\")\n",
    "\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "            # Remover tokens cuya probabilidad acumulada excede top_p\n",
    "            # Considerar también el token actual para no eliminarlo\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            # Retroceder un paso para incluir el último token que contribuyó a 'top_p'\n",
    "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "            sorted_indices_to_remove[..., 0] = False # Asegurar que al menos el primer token no se elimine\n",
    "\n",
    "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "            logits[:, indices_to_remove] = -float('inf') # Establecer sus logits a -inf\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Estrategia de muestreo no reconocida: {strategy}\")\n",
    "\n",
    "        # Añadir el token generado a la secuencia\n",
    "        idx = torch.cat((idx, next_token), dim=1)\n",
    "\n",
    "    return decode(idx[0].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b_dLEfM2lbtZ",
   "metadata": {
    "id": "b_dLEfM2lbtZ"
   },
   "source": [
    "### PRUEBAS COMPARATIVAS ENTRE MODELOS Simple/MoE CON DISTINTOS PARAMETROS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "56f8eee1",
   "metadata": {
    "id": "56f8eee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== EXPERIMENTO 1 ==========\n",
      "Params: {'strategy': 'greedy', 'temperature': 0.7, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "GenerateV3: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "========== EXPERIMENTO 2 ==========\n",
      "Params: {'strategy': 'greedy', 'temperature': 1.0, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "GenerateV3: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "========== EXPERIMENTO 3 ==========\n",
      "Params: {'strategy': 'greedy', 'temperature': 1.3, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "GenerateV3: How is your the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "========== EXPERIMENTO 4 ==========\n",
      "Params: {'strategy': 'temperature', 'temperature': 0.7, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is your I chis che the at his is thend on be buthe ang ace now ate you\n",
      "SId wiorer the then git theag thit a\n",
      "\n",
      "GenerateV3: How is your the hin pous en with theeas the ble macit cone the you car\n",
      "You she do on wor pre, wathe byou to the\n",
      "\n",
      "========== EXPERIMENTO 5 ==========\n",
      "Params: {'strategy': 'temperature', 'temperature': 1.0, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is yours have art fithe plicoll I bees,\n",
      "Ur cown ther\n",
      "Thit gararnd stir havit youp: you you therf Couk, ave \n",
      "\n",
      "GenerateV3: How is your sthin the bean haong thead shom'd pecugct bin\n",
      "'d thalUS: it:\n",
      "Mawousimal men, an then age'scerck ais\n",
      "\n",
      "========== EXPERIMENTO 6 ==========\n",
      "Params: {'strategy': 'temperature', 'temperature': 1.3, 'top_k': None, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is your ut\n",
      "Led hais, fiverund hort alirt'dia;--t VI\n",
      "I'd covedil hourt. Com y shouYou,\n",
      "mant That mur gedmrvi\n",
      "\n",
      "GenerateV3: How is youryy gad you manth.\n",
      "\n",
      "Wecectllshoo'se cobe, Must wiad:\n",
      "Sieiur day a\n",
      "andy to sornen andiune fimyx fith\n",
      "I\n",
      "\n",
      "========== EXPERIMENTO 7 ==========\n",
      "Params: {'strategy': 'top-k', 'temperature': 1.0, 'top_k': 3, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is your hate his to se wer thand wall,\n",
      "Ther the the than athe thande the are ang theate thate tore an the s\n",
      "\n",
      "GenerateV3: How is your the ands,\n",
      "What sour that he the wit he ther whe the wis to to the the a the and to the stonere thin\n",
      "\n",
      "========== EXPERIMENTO 8 ==========\n",
      "Params: {'strategy': 'top-k', 'temperature': 1.0, 'top_k': 5, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is your ar and ars, won hart are weld hom whe wold.\n",
      "\n",
      "\n",
      "MENIUTUS:\n",
      "Senghar sat the to then the thant ale wore \n",
      "\n",
      "GenerateV3: How is your the asend a hend, hereall tir, and an and anthitite tine, antr seesties tors har sen arter tins whe\n",
      "\n",
      "========== EXPERIMENTO 9 ==========\n",
      "Params: {'strategy': 'top-k', 'temperature': 1.0, 'top_k': 9, 'top_p': None}\n",
      "\n",
      "GenerateV2: How is yours sourt theme o wor bre, waith his.\n",
      "\n",
      "\n",
      "MINIUS:\n",
      "Whe theme atll theat as, artinst\n",
      "The omave shill tiend\n",
      "\n",
      "GenerateV3: How is your for whe henoure ther,\n",
      "Onos andst arst ing an bumed, heat,\n",
      "Houly the mat thee, you hou you baiurs wn\n",
      "\n",
      "========== EXPERIMENTO 10 ==========\n",
      "Params: {'strategy': 'top-p', 'temperature': 1.0, 'top_k': None, 'top_p': 0.3}\n",
      "\n",
      "GenerateV2: How is your the whe at the an the the wist the athe she at st she wis store the the the wis there and athe the \n",
      "\n",
      "GenerateV3: How is your and the a the so sear and the so a the the the the so sto the a the sear a sear the and the the the\n",
      "\n",
      "========== EXPERIMENTO 11 ==========\n",
      "Params: {'strategy': 'top-p', 'temperature': 1.0, 'top_k': None, 'top_p': 0.6}\n",
      "\n",
      "GenerateV2: How is yours wharsel ath and, art your and theald ther with he at wor thean ofe hear hare the alle my the you h\n",
      "\n",
      "GenerateV3: How is your heath the of will the hall strant we wit he herat as the serown there the are\n",
      "That four we here tha\n",
      "\n",
      "========== EXPERIMENTO 12 ==========\n",
      "Params: {'strategy': 'top-p', 'temperature': 1.0, 'top_k': None, 'top_p': 0.9}\n",
      "\n",
      "GenerateV2: How is yourt hirin and acked thand\n",
      "RCOLARCIUTIOLAANUS:\n",
      "Iciter nof nay, of ow ser note\n",
      "Fake thing win you,\n",
      "So me\n",
      "\n",
      "GenerateV3: How is your not, hingtre the bustart, you, now mem watat,\n",
      "I'she do thers to the manst.\n",
      "\n",
      "Busto Seseadstill gas, \n"
     ]
    }
   ],
   "source": [
    "Text_ = \"How is your\"\n",
    "\n",
    "# Lista de configuraciones a probar\n",
    "param_grid = [\n",
    "    {\"strategy\": \"greedy\", \"temperature\": 0.7, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"greedy\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"greedy\", \"temperature\": 1.3, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"temperature\", \"temperature\": 0.7, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"temperature\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"temperature\", \"temperature\": 1.3, \"top_k\": None, \"top_p\": None},\n",
    "    {\"strategy\": \"top-k\", \"temperature\": 1.0, \"top_k\": 3, \"top_p\": None},\n",
    "    {\"strategy\": \"top-k\", \"temperature\": 1.0, \"top_k\": 5, \"top_p\": None},\n",
    "    {\"strategy\": \"top-k\", \"temperature\": 1.0, \"top_k\": 9, \"top_p\": None},\n",
    "    {\"strategy\": \"top-p\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": 0.3},\n",
    "    {\"strategy\": \"top-p\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": 0.6},\n",
    "    {\"strategy\": \"top-p\", \"temperature\": 1.0, \"top_k\": None, \"top_p\": 0.9},\n",
    "]\n",
    "\n",
    "# Loop de experimentación\n",
    "for i, params in enumerate(param_grid, 1):\n",
    "    print(f\"\\n========== EXPERIMENTO {i} ==========\")\n",
    "    print(f\"Params: {params}\")\n",
    "\n",
    "    # Generación con el modelo base SIMPLE (SIN MOE) y los parametros actuales\n",
    "    result_2 = generate_V2(\n",
    "        Text_,\n",
    "        max_new_tokens=100,\n",
    "        use_cache=True,\n",
    "        strategy=params[\"strategy\"],\n",
    "        temperature=params[\"temperature\"],\n",
    "        top_k=params[\"top_k\"],\n",
    "        top_p=params[\"top_p\"]\n",
    "    )\n",
    "\n",
    "    # Generación con generate_V3 que implementa MOE y los parámetros actuales\n",
    "    result_3 = generate_V3(\n",
    "        Text_,\n",
    "        max_new_tokens=100,\n",
    "        use_cache=True,\n",
    "        strategy=params[\"strategy\"],\n",
    "        temperature=params[\"temperature\"],\n",
    "        top_k=params[\"top_k\"],\n",
    "        top_p=params[\"top_p\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nGenerateV2:\", result_2)\n",
    "    print(\"\\nGenerateV3:\", result_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a620a",
   "metadata": {
    "id": "9d6a620a"
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "### Comparación Generate_V2 vs Generate_V3 (Con MOE):\n",
    "\n",
    "### Greedy (Experimentos 1–3)\n",
    "\n",
    "V2 y V3: ambos caen en bucles de repetición (the the the…).\n",
    "\n",
    "Conclusión: el comportamiento es prácticamente idéntico → el greedy search sin restricciones provoca colapso repetitivo en ambas versiones.\n",
    "\n",
    "No existen diferencias entre versiones apreciables.\n",
    "\n",
    "### Temperature sampling (Experimentos 4–6)\n",
    "\n",
    "V2: genera frases más caóticas, con errores ortográficos pero cierta variedad.\n",
    "\n",
    "V3: mantiene el caos, pero tiende a introducir algo de estructura.\n",
    "\n",
    "Conclusión: V3 parece tener un sesgo hacia estructuras más coherentes/contextuales, aunque no correctas.\n",
    "\n",
    "### Top-k (Experimentos 7–9)\n",
    "\n",
    "V2: mantiene repeticiones (\"the the the…\"), con frases menos cohesionadas.\n",
    "\n",
    "V3: produce texto con flujo más narrativo, aunque con alucinaciones de palabras.\n",
    "\n",
    "Ej: V3 en Exp.9 introduce algunas frases con cierto sentido.\n",
    "\n",
    "Conclusión: V3 explora más creativamente el espacio que V2, menos repeticiones, aunque ambas pierden coherencia semántica.\n",
    "\n",
    "### Top-p (Experimentos 10–12)\n",
    "\n",
    "V2: se queda en redundancia (\"the the the…\"), aunque un poco más variado que greedy.\n",
    "\n",
    "V3: genera salidas más largas y articuladas, aunque con muchos errores.\n",
    "\n",
    "Exp.12 es un buen ejemplo: V2 genera incoherencia, V3 arma frases con cierta cadencia.\n",
    "\n",
    "Conclusión: V3 (Modelo MoE) pareciera funcionar algo mejor mostrando mayor diversidad y cierto ritmo con pseudo-coherencia, pero carente de sentido.\n",
    "\n",
    "## Conclusiones generales\n",
    "\n",
    "Al pasar de 4 a 8 Multi-heads, corpus de 120.000 caracteres (+20%) y de 5 a 20 epochs se aprecia cierta mejora semantica y sintáctica, aunque lejos del rendimiento pretendido.\n",
    "\n",
    "En modo greedy, ambas versiones probadas fallan igual (colapso repetitivo).\n",
    "\n",
    "## Diferencias clave:\n",
    "\n",
    "V2 → Es más caótico y fragmentado, con mas repeticiones.\n",
    "\n",
    "V3 → Tiende a generar salidas con cierta estructura aunque en general incorrectas.\n",
    "\n",
    "Mejor rendimiento relativo:\n",
    "\n",
    "V3 se comporta mejor en top-k / top-p, mostrando creatividad y menos loops.\n",
    "\n",
    "V2 se queda más limitado en ese sentido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b22f1",
   "metadata": {
    "id": "050b22f1"
   },
   "source": [
    "# Congratulations! 🎉\n",
    "\n",
    "After completing the tasks you've successfully pretrained for first GPT, remember to add your conclusions and findings! And you can now brag to your friend on how LLMs and GPTs work!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CEIA-IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
